Go语言精进之路：从新手到高手的编程思想、方法和技巧2
白明
1035个笔记


◆ 前言

>> 本书特色
本书的特色可以概括为以下几点。
◦  进阶必备：精心总结的编程箴言助你掌握高效Go程序设计之道。
◦  高屋建瓴：Go设计哲学与编程思想先行。
◦  深入浅出：原理深入，例子简明，讲解透彻。
◦  图文并茂：大量图表辅助学习，重点、难点轻松掌控。
如何阅读本书
本书内容共分为十部分，限于篇幅，分为两册出版，即《Go语言精进之路：从新手到高手的编程思想、方法和技巧1》和《Go语言精进之路：从新手到高手的编程思想、方法和技巧2》。其中，第1册包含第一～七部分，第2册包含第八～十部分。
◦  第一部分　熟知Go语言的一切
本部分将带领读者穿越时空，回顾历史，详细了解Go语言的诞生、演进以及发展现状。通过归纳总结Go语言的设计哲学和原生编程思维，让读者站在语言设计者的高度理解Go语言与众不同的设计，认同Go语言的设计理念。
◦  第二部分　项目结构、代码风格与标识符命名
每种编程语言都有自己惯用的代码风格，而遵循语言惯用风格是编写高质量Go代码的必要条件。本部分详细介绍了得到公认且广泛使用的Go项目的结构布局、代码风格标准、标识符命名惯例等。

>> ◦  第三部分　声明、类型、语句与控制结构
本部分详述基础语法层面高质量Go代码的惯用法和有效实践，涵盖无类型常量的作用、定义Go的枚举常量、零值可用类型的意义、切片原理以及高效的原因、Go包导入路径的真正含义等。
◦  第四部分　函数与方法
函数和方法是Go程序的基本组成单元。本部分聚焦于函数与方法的设计和实现，涵盖init函数的使用、跻身“一等公民”行列的函数有何不同、Go方法的本质等。
◦  第五部分　接口
接口是Go语言中的“魔法师”。本部分聚焦于接口，涵盖接口的设计惯例、使用接口类型的注意事项以及接口类型对代码可测试性的影响等。
◦  第六部分　并发编程
Go以其轻量级的并发模型而闻名。本部分详细介绍Go基本执行单元——goroutine的调度原理、Go并发模型以及常见并发模式、Go支持并发的原生类型——channel的惯用模式等内容。
◦  第七部分　错误处理
Go语言十分重视错误处理，它有着相对保守的设计和显式处理错误的惯例。本部分涵盖Go错误处理的哲学以及在这套哲学下一些常见错误处理问题的优秀实践。
◦  第八部分　测试、性能剖析与调试
Go自带强大且为人所称道的工具链。本部分详细介绍Go在单元测试、性能基准测试与性能剖析以及代码调试方面的最佳实践。

>> ◦  第九部分　标准库、反射与cgo
Go拥有功能强大且质量上乘的标准库，在多数情况下仅使用标准库即可实现应用的大部分功能，这大幅降低了学习成本以及代码依赖的管理成本。本部分详细说明高频使用的标准库包（如net/http、strings、bytes、time等）的正确使用方式，以及在使用reflect包、cgo时的注意事项。
◦  第十部分　工具链与工程实践
本部分涵盖在使用Go语言进行大型软件项目开发的过程中，我们很有可能会遇到的一些工程问题的解决方法，包括使用go module进行Go包依赖管理、Go程序容器镜像、Go相关工具使用以及Go语言的避“坑”指南。

>> 书中的源文件可以从https://github.com/bigwhite/GoProgrammingFromBeginnerToMaster下载。


◆ 第八部分 测试、性能剖析与调试

>> 第八部分测试、性能剖析与调试

>> Go语言推崇“面向工程”的设计哲学并自带强大且为人所称道的工具链

>> 第40条理解包内测试与包外测试的差别

>> go test将所有包目录下的*_test.go文件编译成一个临时二进制文件（可以通过go test -c显式编译出该文件），并执行该文件，后者将执行各个测试源文件中名字格式为TestXxx的函数所代表的测试用例并输出测试执行结果。

>> 40.1　官方文档的“自相矛盾”

>> 我们把将测试代码放在与被测包同名的包中的测试方法称为“包内测试”。可以通过下面的命令查看哪些测试源文件使用了包内测试：$go list -f={{.TestGoFiles}} .我们把将测试代码放在名为被测包包名+"_test"的包中的测试方法称为“包外测试”。可以通过下面的命令查看哪些测试源文件使用了包外测试：$go list -f={{.XTestGoFiles}} .那么我们究竟是选择包内测试还是包外测试呢？在给出结论之前，我们将分别对这两种方法做一个详细分析。[1]https://github.com/golang/go/issues/25223

>> 40.2　包内测试与包外测试

>> 1. Go标准库中包内测试和包外测试的使用情况Go标准库是Go代码风格和惯用法一贯的风向标。我们先来看看标准库中包内测试和包外测试各自的比重。在$GOROOT/src目录下（Go 1.14版本），执行下面的命令组合：// 统计标准库中采用包内测试的测试文件数量$find . -name "*_test.go" |xargs grep package |grep ':package'|grep -v "_test$"|wc -l     691// 统计标准库中采用包外测试的测试文件数量$find . -name "*_test.go" |xargs grep package |grep ':package'|grep "_test$"  |wc -l     448

>> 再以net/http这个被广泛使用的明星级的包为例，看看包内测试和包外测试在该包测试中的应用。进入$GOROOT/src/net/http目录下，分别执行下面命令：$go list -f={{.XTestGoFiles}}

>> $go list -f={{.TestGoFiles}}

>> 在针对net/http的测试代码中，对包内测试和包外测试的使用仍然不分伯仲。

>> 2. 包内测试的优势与不足

>> 包内测试这种方法本质上是一种白盒测试方法。由于测试代码与被测包源码在同一包名下，测试代码可以访问该包下的所有符号，无论是导出符号还是未导出符号；并且由于包的内部实现逻辑对测试代码是透明的，包内测试可以更为直接地构造测试数据和实施测试逻辑，可以很容易地达到较高的测试覆盖率。因此对于追求高测试覆盖率的项目而言，包内测试是不二之选。

>> 但在实践中，实施包内测试也经常会遇到如下问题。（1）测试代码自身需要经常性的维护包内测试的白盒测试本质意味着它是一种面向实现的测试。测试代码的测试数据构造和测试逻辑通常与被测包的特定数据结构设计和函数/方法的具体实现逻辑是紧耦合的。这样一旦被测包的数据结构设计出现调整或函数/方法的实现逻辑出现变动，那么对应的测试代码也要随之同步调整，否则整个包将无法通过测试甚至测试代码本身的构建都会失败。而包的内部实现逻辑又是易变的，其优化调整是一种经常性行为，这就意味着采用包内测试的测试代码也需要经常性的维护。（2）硬伤：包循环引用采用包内测试可能会遇到一个绕不过去的硬伤：包循环引用。

>> 如果Go标准库对strings包的测试采用包内测试会遭遇什么呢？见图40-2。[插图]图40-2　对标准库strings进行包内测试将遭遇“包循环引用”从图40-2中我们看到，Go测试代码必须导入并引用的testing包引用了strings包，这样如果strings包仍然使用包内测试方法，就必然会在测试代码中出现strings包与testing包循环引用的情况。

>> 标准库strings包并未采用包内测试的方法

>> 3. 包外测试（仅针对导出API的测试）

>> 因为“包循环引用”的事实存在，Go标准库无法针对strings包实施包内测试，而解决这一问题的自然就是包外测试了：// 在$GOROOT/src/strings目录下$go list -f {{.XTestGoFiles}} .[builder_test.go compare_test.go example_test.go reader_test.go replace_test.go search_test.go strings_test.go]与包内测试本质是面向实现的白盒测试不同，包外测试的本质是一种面向接口的黑盒测试。这里的“接口”指的就是被测试包对外导出的API，这些API是被测包与外部交互的契约。契约一旦确定就会长期保持稳定，无论被测包的内部实现逻辑和数据结构设计如何调整与优化，一般都不会影响这些契约。这一本质让包外测试代码与被测试包充分解耦，使得针对这些导出API进行测试的包外测试代码表现出十分健壮的特性，即很少随着被测代码内部实现逻辑的调整而进行调整和维护。

>> 包外测试将测试代码放入不同于被测试包的独立包的同时，也使得包外测试不再像包内测试那样存在“包循环引用”的硬伤。

>> [插图]图40-3　标准库strings包采用包外测试后解决了“包循环引用”问题

>> 包外测试这种纯黑盒的测试还有一个功能域之外的好处，那就是可以更加聚焦地从用户视角验证被测试包导出API的设计的合理性和易用性。不过包外测试的不足也是显而易见的，那就是存在测试盲区。由于测试代码与被测试目标并不在同一包名下，测试代码仅有权访问被测包的导出符号，并且仅能通过导出API这一有限的“窗口”并结合构造特定数据来验证被测包行为。在这样的约束下，很容易出现对被测试包的测试覆盖不足的情况。

>> Go标准库的实现者们提供了一个解决这个问题的惯用法：安插后门。这个后门就是前面曾提到过的export_test.go文件。该文件中的代码位于被测包名下，但它既不会被包含在正式产品代码中（因为位于_test.go文件中），又不包含任何测试代码，而仅用于将被测包的内部符号在测试阶段暴露给包外测试代码：// $GOROOT/src/fmt/export_test.gopackage fmtvar IsSpace = isSpacevar Parsenum = parsenum或者定义一些辅助包外测试的代码，比如扩展被测包的方法集合：// $GOROOT/src/strings/export_test.gopackage stringsfunc (r *Replacer) Replacer() interface{} {    r.once.Do(r.buildOnce)    return r.r}func (r *Replacer) PrintTrie() string {    r.once.Do(r.buildOnce)    gen := r.r.(*genericReplacer)    return gen.printNode(&gen.root, 0)}...我们可以用图40-4来直观展示export_test.go这个后门在不同阶段的角色（以fmt包为例）。[插图]图40-4　export_test.go为包外测试充当“后门”从图40-4中可以看到，export_test.go仅在go test阶段与被测试包（fmt）一并被构建入最终的测试二进制文件中。在这个过程中，包外测试代码（fmt_test）可以通过导入被测试包（fmt）来访问export_test.go中的导出符号（如IsSpace或对fmt包的扩展）。而export_test.go相当于在测试阶段扩展了包外测试代码的视野，让很多本来很难覆盖到的测试路径变得容易了，进而让包外测试覆盖更多被测试包中的执行路径。

>> 4. 优先使用包外测试

>> 。基于在实践中开发人员对编写测试代码的热情和投入时间，笔者更倾向于优先选择包外测试，理由如下。包外测试可以：优先保证被测试包导出API的正确性；可从用户角度验证导出API的有效性；保持测试代码的健壮性，尽可能地降低对测试代码维护的投入；不失灵活！可通过export_test.go这个“后门”来导出我们需要的内部符号，满足窥探包内实现逻辑的需求。

>> 当然go test也完全支持对被测包同时运用包内测试和包外测试两种测试方法，就像标准库net/http包那样。在这种情况下，包外测试由于将测试代码放入独立的包中，它更适合编写偏向集成测试的用例，它可以任意导入外部包，并测试与外部多个组件的交互。比如：net/http包的serve_test.go中就利用httptest包构建的模拟Server来测试相关接口。而包内测试更聚焦于内部逻辑的测试，通过给函数/方法传入一些特意构造的数据的方式来验证内部逻辑的正确性，比如net/http包的response_test.go。

>> 我们还可以通过测试代码的文件名来区分所属测试类别，比如：net/http包就使用transport_internal_test.go这个名字来明确该测试文件采用包内测试的方法，而对应的transport_test.go则是一个采用包外测试的源文件。

>> 小结在这一条中，我们了解了go test的执行原理，对比了包内测试和包外测试各自的优点和不足，并给出了在实际开发过程中选择测试类型的建议。本条要点：go test执行测试的原理；理解包内测试的优点与不足；理解包外测试的优点与不足；掌握通过export_test.go为包外测试添加“后门”的惯用法；优先使用包外测试；当运用包外测试与包内测试共存的方式时，可考虑让包外测试和包内测试聚焦于不同的测试类别。

>> 第41条 有层次地组织测试代码

>> 聚焦位于测试包内的测试代码该如何组织。

>> 41.1　经典模式——平铺

>> 以strings包的Compare函数为例，与之对应的测试函数有三个：TestCompare、TestCompareIdenticalString和TestCompareStrings。这些测试函数各自独立，测试函数之间没有层级关系，所有测试平铺在顶层。测试函数名称既用来区分测试，又用来关联测试。我们通过测试函数名的前缀才会知道，TestCompare、TestCompareIdenticalString和TestCompareStrings三个函数是针对strings包Compare函数的测试。

>> 在go test命令中，我们还可以通过给命令行选项-run提供正则表达式来匹配并选择执行哪些测试函数。

>> 仅执行测试函数名字中包含TestCompare前缀的测试：# go test -run=TestCompare -v .

>> 平铺模式的测试代码组织方式的优点是显而易见的。简单：没有额外的抽象，上手容易。独立：每个测试函数都是独立的，互不关联，避免相互干扰。

>> 41.2　xUnit家族模式

>> Go 1.7中加入的对subtest的支持让我们在Go中也可以使用上面这种方式组织Go测试代码。还以上面标准库strings包的测试代码为例，这里将其部分测试代码的组织形式改造一下（代码较多，这里仅摘录能体现代码组织形式的必要代码）：

>> 改造前后测试代码的组织结构对比如图41-2所示。[插图]图41-2　strings测试代码组织形式对比从图41-2中我们看到，改造后的名字形如TestXxx的测试函数对应着测试套件，一般针对被测包的一个导出函数或方法的所有测试都放入一个测试套件中。平铺模式下的测试函数TestXxx都改名为testXxx，并作为测试套件对应的测试函数内部的子测试（subtest）。上面的代码中，原先的TestBuilderString变为了testBuilderString。这样的一个子测试等价于一个测试用例。通过对比，我们看到，仅通过查看测试套件内的子测试（测试用例）即可全面了解到究竟对被测函数/方法进行了哪些测试。仅仅增加了一个层次，测试代码的组织就更加清晰了。

>> go test的输出也更有层次感了，我们可以一眼看出对哪些函数/方法进行了测试、这些被测对象对应的测试套件以及套件中的每个测试用例。

>> 41.3　测试固件

>> 我们一般使用setUp和tearDown来代表测试固件的创建/设置与拆除/销毁的动作。

>> 。在传统的平铺模式下，由于每个测试函数都是相互独立的，因此一旦有对测试固件的需求，我们需要为每个TestXxx测试函数单独创建和销毁测试固件。

>> // chapter8/sources/classic_testfixture_test.gopackage demo_test...func setUp(testName string) func() {    fmt.Printf("\tsetUp fixture for %s\n", testName)    return func() {        fmt.Printf("\ttearDown fixture for %s\n", testName)    }}func TestFunc1(t *testing.T) {    defer setUp(t.Name())()    fmt.Printf("\tExecute test: %s\n", t.Name())}func TestFunc2(t *testing.T) {    defer setUp(t.Name())()    fmt.Printf("\tExecute test: %s\n", t.Name())}func TestFunc3(t *testing.T) {    defer setUp(t.Name())()    fmt.Printf("\tExecute test: %s\n", t.Name())}运行该示例：$go test -v classic_testfixture_test.go=== RUN   TestFunc1    setUp fixture for TestFunc1    Execute test: TestFunc1    tearDown fixture for TestFunc1--- PASS: TestFunc1 (0.00s)=== RUN   TestFunc2    setUp fixture for TestFunc2    Execute test: TestFunc2    tearDown fixture for TestFunc2--- PASS: TestFunc2 (0.00s)=== RUN   TestFunc3    setUp fixture for TestFunc3    Execute test: TestFunc3    tearDown fixture for TestFunc3--- PASS: TestFunc3 (0.00s)PASSok         command-line-arguments 0.005s

>> 上面的示例在运行每个测试函数TestXxx时，都会先通过setUp函数建立测试固件，并在defer函数中注册测试固件的销毁函数，以保证在每个TestXxx执行完毕时为之建立的测试固件会被销毁，使得各个测试函数之间的测试执行互不干扰。

>> Go 1.14版本testing包增加了testing.Cleanup方法，为测试固件的销毁提供了包级原生的支持：func setUp() func(){    ...    return func() {    }}func TestXxx(t *testing.T) {    t.Cleanup(setUp())    ...}

>> Go 1.4版本引入了TestMain，使得包级别测试固件的创建和销毁终于有了正式的施展舞台。

>> // chapter8/sources/classic_package_level_testfixture_test.gopackage demo_test...func setUp(testName string) func() {    fmt.Printf("\tsetUp fixture for %s\n", testName)    return func() {        fmt.Printf("\ttearDown fixture for %s\n", testName)    }}func TestFunc1(t *testing.T) {    t.Cleanup(setUp(t.Name()))    fmt.Printf("\tExecute test: %s\n", t.Name())}func TestFunc2(t *testing.T) {    t.Cleanup(setUp(t.Name()))    fmt.Printf("\tExecute test: %s\n", t.Name())}func TestFunc3(t *testing.T) {    t.Cleanup(setUp(t.Name()))    fmt.Printf("\tExecute test: %s\n", t.Name())}func pkgSetUp(pkgName string) func() {    fmt.Printf("package SetUp fixture for

>> %s\n", pkgName)    return func() {        fmt.Printf("package TearDown fixture for %s\n", pkgName)    }}func TestMain(m *testing.M) {    defer pkgSetUp("package demo_test")()    m.Run()}运行该示例：$go test -v classic_package_level_testfixture_test.gopackage SetUp fixture for package demo_test=== RUN   TestFunc1    setUp fixture for TestFunc1    Execute test: TestFunc1    tearDown fixture for TestFunc1--- PASS: TestFunc1 (0.00s)=== RUN   TestFunc2    setUp fixture for TestFunc2    Execute test: TestFunc2    tearDown fixture for TestFunc2--- PASS: TestFunc2 (0.00s)=== RUN   TestFunc3    setUp fixture for TestFunc3    Execute test: TestFunc3    tearDown fixture for TestFunc3--- PASS: TestFunc3 (0.00s)PASSpackage TearDown fixture for package demo_testok    command-line-arguments   0.008s我们看到，在所有测试函数运行之前，包级别测试固件被创建；在所有测试函数运行完毕后，包级别测试固件被销毁。

>> [插图]图41-3　平铺模式下的测试执行流有些时候，一些测试函数所需的测试固件是相同的，在平铺模式下为每个测试函数都单独创建/销毁一次测试固件就显得有些重复和冗余。在这样的情况下，我们可以尝试采用测试套件来减少测试固件的重复创建。

>> // chapter8/sources/xunit_suite_level_testfixture_test.gopackage demo_test...func suiteSetUp(suiteName string) func() {    fmt.Printf("\tsetUp fixture for suite %s\n", suiteName)    return func() {        fmt.Printf("\ttearDown fixture for suite %s\n", suiteName)    }}func func1TestCase1(t *testing.T) {    fmt.Printf("\t\tExecute test: %s\n", t.Name())}func func1TestCase2(t *testing.T) {    fmt.Printf("\t\tExecute test: %s\n", t.Name())}func func1TestCase3(t *testing.T) {    fmt.Printf("\t\tExecute test: %s\n", t.Name())}func TestFunc1(t *testing.T) {    t.Cleanup(suiteSetUp(t.Name()))    t.Run("testcase1", func1TestCase1)    t.Run("testcase2", func1TestCase2)    t.Run("testcase3", func1TestCase3)}func func2TestCase1(t *testing.T) {    fmt.Printf("\t\tExecute test: %s\n", t.Name())}func func2TestCase2(t *testing.T) {    fmt.Printf("\t\tExecute test: %s\n", t.Name())}func func2TestCase3(t *testing.T) {    fmt.Printf("\t\tExecute test: %s\n", t.Name())}func TestFunc2(t *testing.T) {    t.Cleanup(suiteSetUp(t.Name()))    t.Run("testcase1", func2TestCase1)    t.Run("testcase2", func2TestCase2)    t.Run("testcase3", func2TestCase3)}func pkgSetUp(pkgName string) func() {    fmt.Printf("package SetUp fixture for

>> %s\n", pkgName)    return func() {        fmt.Printf("package TearDown fixture for %s\n", pkgName)    }}func TestMain(m *testing.M) {    defer pkgSetUp("package demo_test")()    m.Run()}这个示例采用了xUnit实践的测试代码组织方式，将对测试固件需求相同的一组测试用例放在一个测试套件中，这样就可以针对测试套件创建和销毁测试固件了。运行一下该示例：$go test -v xunit_suite_level_testfixture_test.gopackage SetUp fixture for package demo_test=== RUN   TestFunc1   setUp fixture for suite TestFunc1=== RUN   TestFunc1/testcase1           Execute test: TestFunc1/testcase1=== RUN   TestFunc1/testcase2           Execute test: TestFunc1/testcase2=== RUN   TestFunc1/testcase3           Execute test: TestFunc1/testcase3   tearDown fixture for suite TestFunc1--- PASS: TestFunc1 (0.00s)    --- PASS: TestFunc1/testcase1 (0.00s)    --- PASS: TestFunc1/testcase2 (0.00s)    --- PASS: TestFunc1/testcase3 (0.00s)=== RUN   TestFunc2   setUp fixture for suite TestFunc2=== RUN   TestFunc2/testcase1           Execute test: TestFunc2/testcase1=== RUN   TestFunc2/testcase2           Execute test: TestFunc2/testcase2=== RUN   TestFunc2/testcase3           Execute test: TestFunc2/testcase3   tearDown fixture for suite TestFunc2--- PASS: TestFunc2 (0.00s)    --- PASS: TestFunc2/testcase1 (0.00s)    --- PASS: TestFunc2/testcase2 (0.00s)    --- PASS: TestFunc2/testcase3 (0.00s)PASSpackage TearDown fixture for package demo_testok    command-line-arguments   0.005s当然在这样的测试代码组织方式下，我们仍然可以单独为每个测试用例创建和销毁测试固件，从而形成一种多层次的、更灵活的测试固件设置体系。可以用图41-4总结一下这种模式下的测试执行流。

>> [插图]图41-4　xUnit实践模式下的测试执行流小结在确定了将测试代码放入包内测试还是包外测试之后，我们在编写测试前，还要做好测试包内部测试代码的组织规划，建立起适合自己项目规模的测试代码层次体系。简单的测试可采用平铺模式，复杂的测试可借鉴xUnit的最佳实践，利用subtest建立包、测试套件、测试用例三级的测试代码组织形式，并利用TestMain和testing.Cleanup方法为各层次的测试代码建立测试固件。

>> 第42条 优先编写表驱动的测试

>> 聚焦于测试函数的内部代码该如何编写

>> 测试函数的内部代码该如何编写。

>> 42.1　Go测试代码的一般逻辑

>> 对测试失败与否的判断在于测试代码逻辑是否进入了包含Error/Errorf、Fatal/Fatalf等方法调用的代码分支。一旦进入这些分支，即代表该测试失败。不同的是Error/Errorf并不会立刻终止当前goroutine的执行，还会继续执行该goroutine后续的测试，而Fatal/Fatalf则会立刻停止当前goroutine的测试执行。

>>     a, b = "a", ""    i = 1    cmp = strings.Compare(a, b)    if cmp != i {        t.Errorf(`want %v, but Compare(%q, %q) = %v`, i, a, b, cmp)    }

>> Go测试代码的一般逻辑，那就是针对给定的输入数据，比较被测函数/方法返回的实际结果值与预期值，如有差异，则通过testing包提供的相关函数输出差异信息。

>> 42.2　表驱动的测试实践

>> 上面仅有三组预置输入数据的示例的测试代码已显得十分冗长，如果为测试预置的数据组数增多，测试函数本身就将变得十分庞大。并且，我们看到上述示例的测试逻辑中存在很多重复的代码，显得十分烦琐。我们来尝试对上述示例做一些改进：
// chapter8/sources/table_driven_strings_test.gofunc TestCompare(t *testing.T) {    compareTests := []struct {        a, b string        i    int    }{        {"", "", 0},        {"a", "", 1},        {"", "a", -1},    }    for _, tt := range compareTests {        cmp := strings.Compare(tt.a, tt.b)        if cmp != tt.i {            t.Errorf(`want %v, but Compare(%q, %q) = %v`, tt.i, tt.a, tt.b, cmp)        }    }}
在上面这个改进的示例中，我们将之前示例中重复的测试逻辑合并为一个，并将预置的输入数据放入一个自定义结构体类型的切片中。这个示例的长度看似并没有比之前的实例缩减多少，但它却是一个可扩展的测试设计。

>> 无须改动后面的测试逻辑，只需在切片中增加数据条目即可。在这种测试设计中，这个自定义结构体类型的切片（上述示例中的compareTests）就是一个表（自定义结构体类型的字段就是列），而基于这个数据表的测试设计和实现则被称为“表驱动的测试”。

>> 42.3　表驱动测试的优点

>> 表驱动测试本身是编程语言无关的。

>> 表驱动测试有着诸多优点。
（1）简单和紧凑

>> （2）数据即测试

>> （3）结合子测试后，可单独运行某个数据项的测试

>> 我们将表驱动测试与子测试（subtest）结合来改造一下上面的strings_test示例：
// chapter8/sources/table_driven_strings_with_subtest_test.gofunc TestCompare(t *testing.T) {    compareTests := []struct {        name, a, b string        i          int    }{        {`compareTwoEmptyString`, "", "", 0},        {`compareSecondParamIsEmpty`, "a", "", 1},        {`compareFirstParamIsEmpty`, "", "a", -1},    }    for _, tt := range compareTests {        t.Run(tt.name, func(t *testing.T) {            cmp := strings.Compare(tt.a, tt.b)            if cmp != tt.i {                t.Errorf(`want %v, but Compare(%q, %q) = %v`, tt.i, tt.a, tt.b, cmp)            }        })    }}
在示例中，我们将测试结果的判定逻辑放入一个单独的子测试中，这样可以单独执行表中某项数据的测试。比如：我们单独执行表中第一个数据项对应的测试：
$go test -v  -run /TwoEmptyString table_driven_strings_with_subtest_test.go=== RUN   TestCompare=== RUN   TestCompare/compareTwoEmptyString--- PASS: TestCompare (0.00s)    --- PASS: TestCompare/compareTwoEmptyString (0.00s)PASSok     command-line-arguments   0.005s
综上，建议在编写Go测试代码时优先编写基于表驱动的测试。

>> 42.4　表驱动测试实践中的注意事项

>> 1. 表的实现方式

>> 在上面的示例中，测试中使用的表是用自定义结构体的切片实现的，表也可以使用基于自定义结构体的其他集合类型（如map）来实现。我们将上面的例子改造为采用map来实现测试数据表

>> // chapter8/sources/table_driven_strings_with_map_test.gofunc TestCompare(t *testing.T) {    compareTests := map[string]struct {        a, b string        i    int    }{        `compareTwoEmptyString`:     {"", "", 0},        `compareSecondParamIsEmpty`: {"a", "", 1},        `compareFirstParamIsEmpty`:  {"", "a", -1},    }    for name, tt := range compareTests {        t.Run(name, func(t *testing.T) {            cmp := strings.Compare(tt.a, tt.b)            if cmp != tt.i {                t.Errorf(`want %v, but Compare(%q, %q) = %v`, tt.i, tt.a, tt.b, cmp)            }        })    }}

>> 不过使用map作为数据表时要注意，表内数据项的测试先后顺序是不确定的。

>> 2. 测试失败时的数据项的定位

>> 无论是表中哪一项导致的测试失败，失败结果中输出的引发错误的行号都是相同的

>> 为了在表测试驱动的测试中快速从输出的结果中定位导致测试失败的表项，我们需要在测试失败的输出结果中输出数据表项的唯一标识。
最简单的方法是通过输出数据表项在数据表中的偏移量来辅助定位“元凶”

>> 另一个更直观的方式是使用名字来区分不同的数据项

>> if cmp != tt.i {            t.Errorf(`[%s] want %v, but Compare(%q, %q) = %v`, tt.name, tt.i, tt.a, tt.b, cmp)        }

>> 3. Errorf还是Fatalf

>> 一般而言，如果一个数据项导致的测试失败不会对后续数据项的测试结果造成影响，那么推荐Errorf，这样可以通过执行一次测试看到所有导致测试失败的数据项；否则，如果数据项导致的测试失败会直接影响到后续数据项的测试结果，那么可以使用Fatalf让测试尽快结束，因为继续执行的测试的意义已经不大了。

>> 第43条使用testdata管理测试依赖的外部数据文件

>> 测试固件是Go测试执行所需的上下文环境，其中测试依赖的外部数据文件就是一种常见的测试固件（可以理解为静态测试固件，因为无须在测试代码中为其单独编写固件的创建和清理辅助函数）。

>> 43.1　testdata目录

>> Go语言规定：Go工具链将忽略名为testdata的目录。这样开发者在编写测试时，就可以在名为testdata的目录下存放和管理测试代码依赖的数据文件。而go test命令在执行时会将被测试程序包源码所在目录设置为其工作目录，这样如果要使用testdata目录下的某个数据文件，我们无须再处理各种恼人的路径问题，而可以直接在测试代码中像下面这样定位到充当测试固件的数据文件：
f, err := os.Open("testdata/data-001.txt")

>> 差别（Windows下使用反斜线“\”，Linux/macOS下使用斜线“/”），使用下面的方式可以使测试代码更具可移植性：
f, err := os.Open(filepath.Join("testdata", "data-001.txt"))

>> 我们还经常将预期结果数据保存在文件中并放置在testdata下，然后在测试代码中将被测对象输出的数据与这些预置在文件中的数据进行比较，一致则测试通过；反之，测试失败。

>> 43.2　golden文件惯用法

>> Go标准库为我们提供了一种惯用法：golden文件

>> // chapter8/sources/testdata-demo2/attendee_test.go...var update = flag.Bool("update", false, "update .golden files")func TestAttendeeMarshal(t *testing.T) {    tests := []struct {        fileName string        a        Attendee    }{        {            fileName: "attendee1.golden",            a: Attendee{                Name:  "robpike",                Age:   60,                Phone: "13912345678",            },        },    }    for _, tt := range tests {        got, err := xml.MarshalIndent(&tt.a, "", "  ")        if err != nil {            t.Fatalf("want nil, got %v", err)        }        golden := filepath.Join("testdata", tt.fileName)        if *update {            ioutil.WriteFile(golden, got, 0644)        }        want, err := ioutil.ReadFile(golden)        if err != nil {            t.Fatalf("open file %s failed: %v", tt.fileName, err)        }        if !bytes.Equal(got, want) {            t.Errorf("want %s, got %s", string(want), string(got))        }    }}

>> 在改造后的测试代码中，我们看到新增了一个名为update的变量以及它所控制的golden文件的预期结果数据采集过程：
if *update {    ioutil.WriteFile(golden, got, 0644)}
这样，当我们执行下面的命令时，测试代码会先将最新的预期结果写入testdata目录下的golden文件中，然后将该结果与从golden文件中读出的结果做比较。
$go test -v . -update=== RUN   TestAttendeeMarshal--- PASS: TestAttendeeMarshal (0.00s)PASSok     sources/testdata-demo2   0.006s
显然这样执行的测试是一定会通过的，因为在此次执行中，预期结果数据文件的内容就是通过被测函数刚刚生成的。
但带有-update命令参数的go test命令仅在需要进行预期结果数据采集时才会执行，尤其是在因数据生成逻辑或类型结构定义发生变化，需要重新采集预期结果数据时。比如：我们给上面的Attendee结构体类型增加一个新字段topic，如果不重新采集预期结果数据，那么测试一定是无法通过的。
采用golden文件惯用法后，要格外注意在每次重新采集预期结果后，对golden文件中的数据进行正确性检查，否则很容易出现预期结果数据不正确，但测试依然通过的情况。

>> 小结
在这一条中，我们了解到面向工程的Go语言对测试依赖的外部数据文件的存放位置进行了规范，统一使用testdata目录，开发人员可以采用将预期数据文件放在testdata下的方式为测试提供静态测试固件。而Go golden文件的惯用法实现了testdata目录下测试依赖的预期结果数据文件的数据采集与测试代码的融合。

>> 第44条正确运用fake、stub和mock等辅助单元测试

>> 替身的概念是在测试驱动编程[1]理论中被提出的。作为测试驱动编程理论的最佳实践，xUnit家族框架将替身的概念在单元测试中应用得淋漓尽致，并总结出多种替身，比如fake、stub、mock等。这些概念及其应用模式被汇集在xUnit Test Patterns[2]一书中，该书已成为测试驱动开发和xUnit框架拥趸人手一册的“圣经”。

>> 44.1　fake：真实组件或服务的简化实现版替身

>> fake测试就是指采用真实组件或服务的简化版实现作为替身，以满足被测代码的外部依赖需求。

>> 比如：当被测代码需要连接数据库进行相关操作时，虽然我们在开发测试环境中无法提供一个真实的关系数据库来满足测试需求，但是可以基于哈希表实现一个内存版数据库来满足测试代码要求，我们用这样一个伪数据库作为真实数据库的替身，使得测试顺利进行下去。

>> Go标准库中的$GOROOT/src/database/sql/fakedb_test.go就是一个sql.Driver接口的简化版实现，它可以用来打开一个基于内存的数据库（sql.fakeDB）的连接并操作该内存数据库：
// $GOROOT/src/database/sql/fakedb_test.go...type fakeDriver struct {    mu         sync.Mutex    openCount  int    closeCount int    waitCh     chan struct{}    waitingCh  chan struct{}    dbs        map[string]*fakeDB}...var fdriver driver.Driver = &fakeDriver{}func init() {    Register("test", fdriver) //将自己作为driver进行了注册}...

>> 在sql_test.go中，标准库利用上面的fakeDriver进行相关测试：
// $GOROOT/src/database/sql/sql_test.go

>> 在这个例子中，被测代码为包mailclient中结构体类型mailClient的方法：ComposeAndSend：
// chapter8/sources/faketest1/mailclient.gotype mailClient struct {    mlr mailer.Mailer}func New(mlr mailer.Mailer) *mailClient {    return &mailClient{        mlr: mlr,    }}// 被测方法func (c *mailClient) ComposeAndSend(subject string,    destinations []string, body string) (string, error) {    signTxt := sign.Get()    newBody := body + "\n" + signTxt    for _, dest := range destinations {        err := c.mlr.SendMail(subject, dest, newBody)        if err != nil {            return "", err        }    }    return newBody, nil}

>> 可以看到在创建mailClient实例的时候，需要传入一个mailer.Mailer接口变量，该接口定义如下：
// chapter8/sources/faketest1/mailer/mailer.gotype Mailer interface {    SendMail(subject, destination, body string) error}
ComposeAndSend方法将传入的电子邮件内容（body）与签名（signTxt）编排合并后传给Mailer接口实现者的SendMail方法，由其将邮件发送出去。在生产环境中，mailer.Mailer接口的实现者是要与远程邮件服务器建立连接并通过特定的电子邮件协议（如SMTP）将邮件内容发送出去的。但在单元测试中，我们无法满足被测代码的这个要求，于是我们为mailClient实例提供了两个简化版的实现：fakeOkMailer和fakeFailMailer，前者代表发送成功，后者代表发送失败。代码如下：
// chapter8/sources/faketest1/mailclient_test.gotype fakeOkMailer struct{}func (m *fakeOkMailer) SendMail(subject string, dest string, body string) error {    return nil}type fakeFailMailer struct{}func (m *fakeFailMailer) SendMail(subject string, dest string, body string) error {    return fmt.Errorf("can not reach the mail server of dest [%s]", dest)}
下面就是这两个替身在测试中的使用方法：

>> // chapter8/sources/faketest1/mailclient_test.gofunc TestComposeAndSendOk(t *testing.T) {    m := &fakeOkMailer{}    mc := mailclient.New(m)    _, err := mc.ComposeAndSend("hello, fake test", []string{"xxx@example.com"}, "the test body")    if err != nil {        t.Errorf("want nil, got %v", err)    }}func TestComposeAndSendFail(t *testing.T) {    m := &fakeFailMailer{}    mc := mailclient.New(m)    _, err := mc.ComposeAndSend("hello, fake test", []string{"xxx@example.com"}, "the test body")    if err == nil {        t.Errorf("want non-nil, got nil")    }}
我们看到这个测试中mailer.Mailer的fake实现的确很简单，简单到只有一个返回语句。但就这样一个极其简化的实现却满足了对ComposeAndSend方法进行测试的所有需求。
使用fake替身进行测试的最常见理由是在测试环境无法构造被测代码所依赖的外部组件或服务，或者这些组件/服务有副作用。fake替身的实现也有两个极端：要么像标准库fakedb_test.go那样实现一个全功能的简化版内存数据库driver，要么像faketest1例子中那样针对被测代码的调用请求仅返回硬编码的成功或失败。这两种极端实现有一个共同点：并不具备在测试前对返回结果进行预设置的能力。这也是上面例子中我们针对成功和失败两个用例分别实现了一个替身的原因。（如果非要说成功和失败也是预设置的，那么fake替身的预设置能力也仅限于设置单一的返回值，即无论调用多少次，传入什么参数，返回值都是一个。）

>> 44.2　stub：对返回结果有一定预设控制能力的替身

>> stub也是一种替身概念，和fake替身相比，stub替身增强了对替身返回结果的间接控制能力，这种控制可以通过测试前对调用结果预设置来实现。不过，stub替身通常仅针对计划之内的结果进行设置，对计划之外的请求也无能为力。

>> 使用Go标准库net/http/httptest实现的用于测试的Web服务就可以作为一些被测对象所依赖外部服务的stub替身。下面就来看一个这样的例子。
该例子的被测代码为一个获取城市天气的客户端，它通过一个外部的天气服务来获得城市天气数据：
// chapter8/sources/stubtest1/weather_cli.gotype Weather struct {    City    string `json:"city"`    Date    string `json:"date"`    TemP    string `json:"temP"`    Weather string `json:"weather"`}func GetWeatherInfo(addr string, city string) (*Weather, error) {    url := fmt.Sprintf("%s/weather?city=%s", addr, city)    resp, err := http.Get(url)    if err != nil {        return nil, err    }    defer resp.Body.Close()    if resp.StatusCode != http.StatusOK {        return nil, fmt.Errorf("http status code is %d", resp.StatusCode)    }    body, err := ioutil.ReadAll(resp.Body)    if err != nil {        return nil, err    }    var w Weather    err = json.Unmarshal(body, &w)    if err != nil {        return nil, err    }    return &w, nil}

>> 下面是针对GetWeatherInfo函数的测试代码：
// chapter8/sources/stubtest1/weather_cli_test.govar weatherResp = []Weather{    {        City:    "nanning",        TemP:    "26~33",        Weather: "rain",        Date:    "05-04",    },    {        City:    "guiyang",        TemP:    "25~29",        Weather: "sunny",        Date:    "05-04",    },    {        City:    "tianjin",        TemP:    "20~31",        Weather: "windy",        Date:    "05-04",    },}func TestGetWeatherInfoOK(t *testing.T) {    ts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter,        r *http.Request) {        var data []byte        if r.URL.EscapedPath() != "/weather" {            w.WriteHeader(http.StatusForbidden)        }        r.ParseForm()        city := r.Form.Get("city")        if city == "guiyang" {            data, _ = json.Marshal(&weatherResp[1])        }        if city == "tianjin" {            data, _ = json.Marshal(&weatherResp[2])        }        if city == "nanning" {            data, _ = json.Marshal(&weatherResp[0])        }        w.Write(data)    }))    defer ts.Close()    addr := ts.URL    city := "guiyang"    w, err := GetWeatherInfo(addr, city)    if err != nil {        t.Fatalf("want nil, got %v", err)    }    if w.City != city {        t.Errorf("want %s, got %s", city, w.City)    }    if w.Weather != "sunny" {        t.Errorf("want %s, got %s", "sunny", w.City)    }}

>> 在上面的测试代码中，我们使用httptest建立了一个天气服务器替身，被测函数GetWeatherInfo被传入这个构造的替身天气服务器的服务地址，其对外部服务的依赖需求被满足。同时，我们看到该替身具备一定的对服务返回应答结果的控制能力，这种控制通过测试前对返回结果的预设置实现（上面例子中设置了三个城市的天气信息结果）。这种能力可以实现对测试结果判断的控制。

>> 在GitHub上有一个名为gostub（https://github.com/prashantv/gostub）的第三方包可以用于简化stub替身的管理和编写。以上面的例子为例，如果改写为使用gostub的测试，代码如下：
// chapter8/sources/stubtest3/mailclient_test.gofunc TestComposeAndSendWithSign(t *testing.T) {    sender := "tonybai@example.com"    timestamp := "Mon, 04 May 2020 11:46:12 CST"    stubs := gostub.Stub(&getSign, func(sender string) string {        selfSignTxt := senderSigns[sender]        return selfSignTxt + "\n" + timestamp    })    defer stubs.Reset()    ...}

>> 44.3　mock：专用于行为观察和验证的替身

>> 和fake、stub替身相比，mock替身更为强大：它除了能提供测试前的预设置返回结果能力之外，还可以对mock替身对象在测试过程中的行为进行观察和验证。不过相比于前两种替身形式，mock存在应用局限（尤指在Go中）。

>> ◦  和前两种替身相比，mock的应用范围要窄很多，只用于实现某接口的实现类型的替身。
◦  一般需要通过第三方框架实现mock替身。Go官方维护了一个mock框架——gomock（https://github.com/golang/mock），该框架通过代码生成的方式生成实现某接口的替身类型。

>> 首先安装Go官方维护的go mock框架。这个框架分两部分：一部分是用于生成mock替身的mockgen二进制程序，另一部分则是生成的代码所要使用的gomock包。先来安装一下mockgen：
$go get github.com/golang/mock/mockgen
通过上述命令，可将mockgen安装到$GOPATH/bin目录下（确保该目录已配置在PATH环境变量中）。

>> mockMailer.EXPECT().SendMail("hello, mock test", sender,    "dest1@example.com",    "the test body\n"+senderSigns[sender]+"\n"+timestamp).Return(nil).Times(1)
这就是前面提到的mock替身具备的能力：在测试前对预期返回结果进行设置（这里设置SendMail返回nil），对替身在测试过程中的行为进行验证。Times(1)意味着以该参数列表调用的SendMail方法在测试过程中仅被调用一次，多一次调用或没有调用均会导致测试失败。这种对替身观察和验证的能力是mock区别于stub的重要特征。

>> gomock是一个通用的mock框架，社区还有一些专用的mock框架可用于快速创建mock替身，比如：go-sqlmock（https://github.com/DATA-DOG/go-sqlmock）专门用于创建sql/driver包中的Driver接口实现的mock替身，可以帮助Gopher简单、快速地建立起对数据库操作相关方法的单元测试。

>> 小结
本条介绍了当被测代码对外部组件或服务有强依赖时可以采用的测试方案，这些方案采用了相同的思路：为这些被依赖的外部组件或服务建立替身。这里介绍了三类替身以及它们的适用场合与注意事项。
本条要点如下。
◦  fake、stub、mock等替身概念之间并非泾渭分明的，对这些概念的理解容易混淆。比如标准库net/http/transfer_test.go文件中的mockTransferWriter类型，虽然其名字中带有mock，但实质上它更像是一个fake替身。
◦  我们更多在包内测试应用上述替身概念辅助测试，这就意味着此类测试与被测代码是实现级别耦合的，这样的测试健壮性较差，一旦被测代码内部逻辑有变化，测试极容易失败。
◦  通过fake、stub、mock等概念实现的替身参与的测试毕竟是在一个虚拟的“沙箱”环境中，不能代替与真实依赖连接的测试，因此，在集成测试或系统测试等使用真实外部组件或服务的测试阶段，务必包含与真实依赖的联测用例。
◦  fake替身主要用于被测代码依赖组件或服务的简化实现。
◦  stub替身具有有限范围的、在测试前预置返回结果的控制能力。
◦  mock替身则专用于对替身的行为进行观察和验证的测试，一般用作

>> Go接口类型的实现的替身。

>> 第45条使用模糊测试让潜在bug无处遁形

>> 模糊测试就是指半自动或自动地为程序提供非法的、非预期、随机的数据，并监控程序在这些输入数据下是否会出现崩溃、内置断言失败、内存泄露、安全漏洞等情况（见图45-1）。

>> 
图45-1　模糊测试的定义

>> 传统软件测试技术越来越无法满足现代软件日益增长的规模、复杂性以及对开发速度的要求。传统软件测试一般会针对被测目标的特性进行人工测试设计。在设计一些异常测试用例的时候，测试用例质量好坏往往取决于测试设计人员对被测系统的理解程度及其个人能力。即便测试设计人员个人能力很强，对被测系统也有较深入的理解，他也很难在有限的时间内想到所有可能的异常组合和异常输入，尤其是面对庞大的分布式系统的时候。系统涉及的自身服务组件、中间件、第三方系统等多且复杂，这些系统中的潜在bug或者组合后形成的潜在bug是我们无法预知的。而将随机测试、边界测试、试探性攻击等测试技术集于一身的模糊测试对于上述传统测试技术存在的问题是一个很好的补充和解决方案。

>> 45.1　模糊测试在挖掘Go代码的潜在bug中的作用

>> 45.2　go-fuzz的初步工作原理

>> go-fuzz的工作流程如下：
1）生成随机数据；
2）将上述数据作为输入传递给被测程序；
3）观察是否有崩溃记录（crash），如果发现崩溃记录，则说明找到了潜在的bug。
之后开发者可以根据crash记录情况去确认和修复bug。修复bug后，我们一般会为被测代码添加针对这个bug的单元测试用例以验证bug已经修复。
go-fuzz采用的是代码覆盖率引导的fuzzing算法（Coverage-guided fuzzing）。

>> 45.3　go-fuzz使用方法

>> 1. 安装go-fuzz

>> 使用go-fuzz需要安装两个重要工具：go-fuzz-build和go-fuzz。通过标准go get就可以安装它们：
$ go get github.com/dvyukov/go-fuzz/go-fuzz$ go get github.com/dvyukov/go-fuzz/go-fuzz-build
go get会自动将两个工具安装到$GOROOT/bin或$GOPATH/bin下，因此你需要确保你的Path环境变量下包含这两个路径。

>> 2. 带有模糊测试的项目组织

>> 有时候，待测试包的包内功能很多，一个Fuzz函数不够用，我们可以在fuzztest下建立多个目录来应对：
github.com/bigwhite/fuzzexamples/foo/fuzztest]$tree.├── fuzz1│   ├── corpus│   ├── fuzz.go│   └── gen│       └── main.go└── fuzz2    ├── corpus    ├── fuzz.go    └── gen        └── main.go ...

>> . go-fuzz-build
go-fuzz-build会根据Fuzz函数构建一个用于go-fuzz执行的zip包（PACKAGENAME-fuzz.zip），包里包含了用途不同的三个文件：
cover.exe metadata sonar.exe
按照go-fuzz作者的解释，这三个二进制程序的功能分别如下。
◦  cover.exe：被注入了代码测试覆盖率桩设施的二进制文件。
◦  sonar.exe：被注入了sonar统计桩设施的二进制文件。
◦  metadata：包含代码覆盖率统计、sonar的元数据以及一些整型、字符串字面值。

>> 4. 执行go-fuzz
一旦生成了foo-fuzz.zip，我们就可以执行针对fuzz1的模糊测试。
$cd fuzz1$go-fuzz -bin=./foo-fuzz.zip -workdir=./

>> go-fuzz执行时是一个无限循环，上面的测试需要手动停下来。go-fuzz会在指定的workdir中创建另两个目录：crashers和suppressions。顾名思义，crashers中存放的是代码崩溃时的相关信息，包括引起崩溃的输入用例的二进制数据、输入数据的字符串形式（xxx.quoted）以及基于这个数据的输出数据（xxx.output）。suppressions目录中则保存着崩溃时的栈跟踪信息，方便开发人员快速定位bug。

>> 45.4　使用go-fuzz建立模糊测试的示例

>> 45.5　让模糊测试成为“一等公民”

>> go-fuzz的成功和广泛应用让Gopher认识到模糊测试对挖掘潜在bug、提升代码质量有着重要的作用。但目前Go尚未将模糊测试当成“一等公民”对待，即还没有在Go工具链上原生支持模糊测试，模糊测试在Go中的应用还仅限于使用第三方的go-fuzz或谷歌开源的gofuzz。

>> 那么模糊测试才算真正得到了“一等公民”的地位，这一直是模糊测试在Go语言中的努力方向。目前Go官方已经在讨论将模糊测试纳入Go工具链的实现方案了（https://github.com/golang/go/issues/19109）。

>> 小结
通过这一条，我们认识到模糊测试对于提升Go代码质量、挖掘潜在bug的重要作用。但模糊测试不是“银弹”，它有其适用的范围。模糊测试最适合那些处理复杂输入数据的程序，比如文件格式解析、网络协议解析、人机交互界面入口等。模糊测试是软件测试技术的一个重要分支，与单元测试等互为补充，相辅相成。
目前，并非所有编程语言都有对模糊测试工具的支持，Gopher和Go社区很幸运，Dmitry Vyukov为我们带来了go-fuzz模糊测试工具。如果你是追求高质量Go代码的开发者，请为你的Go代码建立起模糊测试。

>> 第46条为被测对象建立性能基准

>> 是否优化、何时优化实质上是一个决策问题，但决策不能靠直觉，要靠数据说话。借用上面名言中的句型：没有数据支撑的过早决策是万恶之源。

>> 46.1　性能基准测试在Go语言中是“一等公民”

>> 性能基准测试还可以通过传入-benchmem命令行参数输出内存分配信息（与基准测试代码中显式调用b.ReportAllocs的效果是等价的）

>> $go test -bench=Join ./benchmark_intro_test.go -benchmemgoos: darwingoarch: amd64BenchmarkConcatStringByJoin-8     23004709   48.8 ns/op   48 B/op     1 allocs/opPASSok         command-line-arguments 1.183s
这里输出的内存分配信息告诉我们，每执行一次concatStringByJoin平均进行一次内存分配，每次平均分配48字节的数据。

>> 46.2　顺序执行和并行执行的性能基准测试

>> 根据是否并行执行，Go的性能基准测试可以分为两类：顺序执行的性能基准测试和并行执行的性能基准测试。

>> 1. 顺序执行的性能基准测试

>> 默认情况下，每个性能基准测试函数（如BenchmarkSequential）的执行时间为1秒。如果执行一轮所消耗的时间不足1秒，那么go test会按就近的顺序增加b.N的值：1、2、3、5、10、20、30、50、100等。如果当b.N较小时，基准测试执行可以很快完成，那么go test基准测试框架将跳过中间的一些值，选择较大的值

>> 通过go test的命令行参数-benchtime将1秒这个默认性能基准测试函数执行时间改为2秒：
$go test -bench . sequential_test.go -benchtime 2s

>> 2. 并行执行的性能基准测试

>> 并行执行的性能基准测试的代码写法如下：
func BenchmarkXxx(b *testing.B) {    // ...    b.RunParallel(func(pb *testing.PB) {        for pb.Next() {            // 被测对象的执行代码        }    }}

>> 并行执行的基准测试主要用于为包含多goroutine同步设施（如互斥锁、读写锁、原子操作等）的被测代码建立性能基准。相比于顺序执行的基准测试，并行执行的基准测试更能真实反映出多goroutine情况下，被测代码在goroutine同步上的真实消耗。

>> // chapter8/sources/benchmark_paralell_demo_test.govar n1 int64func addSyncByAtomic(delta int64) int64 {    return atomic.AddInt64(&n1, delta)}func readSyncByAtomic() int64 {    return atomic.LoadInt64(&n1)}var n2 int64var rwmu sync.RWMutexfunc addSyncByMutex(delta int64) {    rwmu.Lock()    n2 += delta    rwmu.Unlock()}func readSyncByMutex() int64 {    var n int64    rwmu.RLock()    n = n2    rwmu.RUnlock()    return n}func BenchmarkAddSyncByAtomic(b *testing.B) {    b.RunParallel(func(pb *testing.PB) {        for pb.Next() {            addSyncByAtomic(1)        }    })}func BenchmarkReadSyncByAtomic(b *testing.B) {    b.RunParallel(func(pb *testing.PB) {        for pb.Next() {            readSyncByAtomic()        }    })}func BenchmarkAddSyncByMutex(b *testing.B) {    b.RunParallel(func(pb *testing.PB) {        for pb.Next() {            addSyncByMutex(1)        }    })}func BenchmarkReadSyncByMutex(b *testing.B) {    b.RunParallel(func(pb *testing.PB) {        for pb.Next() {            readSyncByMutex()        }    })}

>> 46.3　使用性能基准比较工具

>> 通过Go原生提供的性能基准测试为被测对象建立性能基准了。但被测代码更新前后的性能基准比较依然要靠人工计算和肉眼比对，十分不方便。为此，Go核心团队先后开发了两款性能基准比较工具：benchcmp（https://github.com/golang/tools/tree/master/cmd/benchcmp）和benchstat（https://github.com/golang/perf/tree/master/benchstat）。

>> 1. benchcmp
benchcmp上手快，简单易用，对于输出的比较结果我们无须参考文档帮助即可自行解读。

>> $benchcmp old.txt new.txtbenchmark             old ns/op     new ns/op     deltaBenchmarkStrcat-8     92.4          49.6          -46.32%

>> 如果向benchcmp传入-best命令行选项，benchcmp将分别从old.txt和new.txt中挑选性能最好的一条数据，然后进行比较

>> 2. benchstat
为了提高对性能基准数据比较的科学性，Go核心团队又开发了benchstat这款工具以替代benchcmp。

>> Go核心团队已经给benchcmp工具打上了“deprecation”（不建议使用）的标签，因此建议大家使用benchstat来进行性能基准数据的比较。

>> 46.4　排除额外干扰，让基准测试更精确

>> 有些复杂的基准测试在真正执行For循环之前或者在每个循环中，除了执行真正的被测代码之外，可能还需要做一些测试准备工作，比如建立基准测试所需的测试上下文等。如果不做特殊处理，这些测试准备工作所消耗的时间也会被算入最终结果中，这就会导致最终基准测试的数据受到干扰而不够精确。为此，testing.B中提供了多种灵活操控基准测试计时器的方法，通过这些方法可以排除掉额外干扰，让基准测试结果更能反映被测代码的真实性能。

>> func BenchmarkStrcatWithTestContextSetupAndRestartTimer(b *testing.B) {    b.StopTimer()    expensiveTestContextSetup()    b.StartTimer()    for n := 0; n < b.N; n++ {        concatStringByJoin(sl)    }

>> 如果不通过testing.B提供的计数器控制接口对测试上下文带来的消耗进行隔离，最终基准测试得到的数据（BenchmarkStrcatWithTestContextSetup）将偏离准确数据（BenchmarkStrcat）很远。

>> 将ResetTimer或StopTimer用在每个基准测试的For循环中是有副作用的。在默认情况下，每个性能基准测试函数的执行时间为1秒。如果执行一轮所消耗的时间不足1秒，那么会修改b.N值并启动新的一轮执行。这样一旦在For循环中使用StopTimer，那么想要真正运行1秒就要等待很长时间；而如果在For循环中使用了ResetTimer，由于其每次执行都会将计数器数据清零，因此这轮基准测试将一直执行下去，无法退出。综上，尽量不要在基准测试的For循环中使用ResetTimer！但可以在限定条件下在For循环中使用StopTimer/StartTimer，就像下面的Go标准库中这样：
// $GOROOT/src/runtime/map_test.gofunc benchmarkMapDeleteInt32(b *testing.B, n int) {    a := make(map[int32]int, n)    b.ResetTimer()    for i := 0; i < b.N; i++ {        if len(a) == 0 {            b.StopTimer()            for j := i; j < i+n; j++ {                a[int32(j)] = j            }            b.StartTimer()        }        delete(a, int32(i))    }}
上面的测试代码虽然在基准测试的For循环中使用了StopTimer，但其是在if len(a) == 0这个限定条件下使用的，StopTimer方法并不会在每次循环中都被调用。

>> 小结
无论你是否认为性能很重要，都请你为被测代码（尤其是位于系统关键业务路径上的代码）建立性能基准。如果你编写的是供其他人使用的软件包，则更应如此。只有这样，我们才能至少保证后续对代码的修改不会带来性能回退。已经建立的性能基准可以为后续是否进一步优化的决策提供数据支撑，而不是靠程序员的直觉。
本条要点：
◦  性能基准测试在Go语言中是“一等公民”，在Go中我们可以很容易为被测代码建立性能基准；
◦  了解Go的两种性能基准测试的执行原理；
◦  使用性能比较工具协助解读测试结果数据，优先使用benchstat工具；
◦  使用testing.B提供的定时器操作方法排除额外干扰，让基准测试更精确，但不要在Run-Parallel中使用ResetTimer、StartTimer和StopTimer，因为它们具有全局副作用。

>> 第47条使用pprof对程序进行性能剖析

>> Go是“自带电池”（battery included）的编程语言，拥有着让其他主流语言羡慕的工具链，Go还内置了对代码进行性能剖析的工具：pprof。pprof源自Google Perf Tools工具套件，在Go发布早期就被集成到Go工具链中了，并且Go运行时原生支持输出满足pprof需要的性能采样数据。

>> 47.1　pprof的工作原理

>> 使用pprof对程序进行性能剖析的工作一般分为两个阶段：数据采集和数据剖析，

>> 

图47-1　pprof工作原理

>> 1. 采样数据类型
在数据采集阶段，Go运行时会定期对剖析阶段所需的不同类型数据进行采样记录。当前主要支持的采样数据类型有如下几种。
（1）CPU数据（对应图47-1中的cpu.prof）

>> 一旦启用CPU数据采样，Go运行时会每隔一段短暂的时间（10ms）就中断一次（由SIGPROF信号引发）并记录当前所有goroutine的函数栈信息（存入cpu.prof）。

>> （2）堆内存分配数据（对应图47-1中的mem.prof）

>> 堆内存分配的采样频率可配置，默认每1000次堆内存分配会做一次采样（存入mem.prof）。

>> （3）锁竞争数据

>> mutex.prof

>> 锁竞争采样数据记录了当前Go程序中互斥锁争用导致延迟的操作。如果你认为很大可能是互斥锁争用导致CPU利用率不高，那么你可以为go tool pprof工具提供此类采样文件以供性能剖析阶段使用。该类型采样数据在默认情况下是不启用的，请参见runtime.SetMutexProfileFraction或go test -bench . xxx_test.go -mutexprofile mutex.out启用它。

>> （4）阻塞时间数据

>> block.prof

>> 该类型采样数据记录的是goroutine在某共享资源（一般是由同步原语保护）上的阻塞时间，包括从无缓冲channel收发数据、阻塞在一个已经被其他goroutine锁住的互斥锁、向一个满了的channel发送数据或从一个空的channel接收数据等。该类型采样数据在默认情况下也是不启用的，请参见runtime.SetBlockProfileRate或go test -bench . xxx_test.go -blockprofile block.out启用它。

>> 采样不是免费的，因此一次采样尽量仅采集一种类型的数据，不要同时采样多种类型的数据，避免相互干扰采样结果。

>> 2. 性能数据采集的方式

>> Go目前主要支持两种性能数据采集方式：通过性能基准测试进行数据采集和独立程序的性能数据采集。

>> （1）通过性能基准测试进行数据采集
为应用中的关键函数/方法建立起性能基准测试之后，我们便可以通过执行性能基准测试采集到整个测试执行过程中有关被测方法的各类性能数据。这种方式尤其适用于对应用中关键路径上关键函数/方法性能的剖析。
我们仅需为go test增加一些命令行选项即可在执行性能基准测试的同时进行性能数据采集。以CPU采样数据类型为例：
$go test -bench . xxx_test.go -cpuprofile=cpu.prof

>> $lscpu.prof xxx.test* xxx_test.go
一旦开启性能数据采集（比如传入-cpuprofile），go test的-c命令选项便会自动开启，go test命令执行后会自动编译出一个与该测试对应的可执行文件（这里是xxx.test）。该可执行文件可以在性能数据剖析过程中提供剖析所需的符号信息（如果没有该可执行文件，go tool pprof的disasm命令将无法给出对应符号的汇编代码）。而cpu.prof就是存储CPU性能采样数据的结果文件，后续将作为数据剖析过程的输入。

>> 对于其他类型的采样数据，也可以采用同样的方法开启采集并设置输出文件:
$go test -bench . xxx_test.go -memprofile=mem.prof$go test -bench . xxx_test.go -blockprofile=block.prof$go test -bench . xxx_test.go -mutexprofile=mutex.prof

>> （2）独立程序的性能数据采集
可以通过标准库runtime/pprof和runtime包提供的低级API对独立程序进行性能数据采集。

>> // chapter8/sources/pprof_standalone1.govar cpuprofile = flag.String("cpuprofile", "", "write cpu profile to `file`")var memprofile = flag.String("memprofile", "", "write memory profile to `file`")var mutexprofile = flag.String("mutexprofile", "", "write mutex profile to `file`")var blockprofile = flag.String("blockprofile", "", "write block profile to `file`")func main() {    flag.Parse()    if *cpuprofile != "" {        f, err := os.Create(*cpuprofile)        if err != nil {            log.Fatal("could not create CPU profile: ", err)        }        defer f.Close() // 该例子中暂忽略错误处理        if err := pprof.StartCPUProfile(f); err != nil {            log.Fatal("could not start CPU profile: ", err)        }        defer pprof.StopCPUProfile()    }    if *memprofile != "" {        f, err := os.Create(*memprofile)        if err != nil {            log.Fatal("could not create memory profile: ", err)        }        defer f.Close()        if err := pprof.WriteHeapProfile(f); err != nil {            log.Fatal("could not write memory profile: ", err)        }    }    if *mutexprofile != "" {        runtime.SetMutexProfileFraction(1)        defer runtime.SetMutexProfileFraction(0)        f, err := os.Create(*mutexprofile)        if err != nil {            log.Fatal("could not create mutex profile: ", err)        }        defer f.Close()        if mp := pprof.Lookup("mutex"); mp != nil {            mp.WriteTo(f, 0)        }    }    if *blockprofile != "" {        runtime.SetBlockProfileRate(1)        defer runtime.SetBlockProfileRate(0)        f, err := os.Create(*blockprofile)        if err != nil {            log.Fatal("could not create block profile: ", err)        }        defer f.Close()        if mp := pprof.Lookup("mutex"); mp != nil {            mp.WriteTo(f, 0)        }    }

>>     var wg sync.WaitGroup    c := make(chan os.Signal, 1)    signal.Notify(c, syscall.SIGINT, syscall.SIGTERM)    wg.Add(1)    go func() {        for {            select {            case <-c:                wg.Done()                return            default:                s1 := "hello,"                s2 := "gopher"                s3 := "!"                _ = s1 + s2 + s3            }            time.Sleep(10 * time.Millisecond)        }    }()    wg.Wait()    fmt.Println("program exit")}

>> 这种独立程序的性能数据采集方式对业务代码侵入较多，还要自己编写一些采集逻辑：定义flag变量、创建输出文件、关闭输出文件等。每次采集都要停止程序才能获取结果。（当然可以重新定义更复杂的控制采集时间窗口的逻辑，实现不停止程序也能获取采集数据结果。）
Go在net/http/pprof包中还提供了一种更为高级的针对独立程序的性能数据采集方式，这种方式尤其适合那些内置了HTTP服务的独立程序。net/http/pprof包可以直接利用已有的HTTP服务对外提供用于性能数据采集的服务端点（endpoint）。

>> 如果要采集该HTTP服务的性能数据，我们仅需在该独立程序的代码中像下面这样导入net/http/pprof包即可：
// chapter8/sources/pprof_standalone2.goimport (    _ "net/http/pprof")

>> 下面是net/http/pprof包的init函数，这就是空导入net/http/pprof的“副作用”：
//$GOROOT/src/net/http/pprof/pprof.gofunc init() {    http.HandleFunc("/debug/pprof/", Index)    http.HandleFunc("/debug/pprof/cmdline", Cmdline)    http.HandleFunc("/debug/pprof/profile", Profile)    http.HandleFunc("/debug/pprof/symbol", Symbol)    http.HandleFunc("/debug/pprof/trace", Trace)}

>> 我们看到该包的init函数向http包的默认请求路由器DefaultServeMux注册了多个服务端点和对应的处理函数。而正是通过这些服务端点，我们可以在该独立程序运行期间获取各种类型的性能采集数据。现在打开浏览器，访问http://localhost:8080/debug/pprof/

>> 如果想自定义采集时长，可以通过为服务端点传递时长参数实现，比如下面就是一个采样60秒的请求：
http://localhost:8080/debug/pprof/profile?seconds=60

>> 如果独立程序的代码中没有使用http包的默认请求路由器DefaultServeMux，那么我们就需要重新在新的路由器上为pprof包提供的性能数据采集方法注册服务端点，就像下面的示例一样：
// chapter8/sources/pprof_standalone3.go...func main() {    mux := http.NewServeMux()    mux.HandleFunc("/debug/pprof/", pprof.Index)    mux.HandleFunc("/debug/pprof/profile", pprof.Profile)    ...    mux.HandleFunc("/hello", http.HandlerFunc(func(w http.ResponseWriter,        r *http.Request) {        fmt.Println(*r)        w.Write([]byte("hello"))    }))    s := http.Server{        Addr:    "localhost:8080",        Handler: mux,    }    c := make(chan os.Signal, 1)    signal.Notify(c, syscall.SIGINT, syscall.SIGTERM)    go func() {        <-c        s.Shutdown(context.Background())    }()    log.Println(s.ListenAndServe())}

>> 如果是非HTTP服务程序，则在导入包的同时还需单独启动一个用于性能数据采集的goroutine，像下面这样：
// chapter8/sources/pprof_standalone4.go...func main() {    go func() {        // 单独启动一个HTTP server用于性能数据采集        fmt.Println(http.ListenAndServe("localhost:8080", nil))    }()    ...}

>> 通过上面几个示例我们可以看出，相比第一种方式，导入net/http/pprof包进行独立程序性能数据采集的方式侵入性更小，代码也更为独立，并且无须停止程序，通过预置好的各类性能数据采集服务端点即可随时进行性能数据采集。

>> 3. 性能数据的剖析

>> Go工具链通过pprof子命令提供了两种性能数据剖析方法：命令行交互式和Web图形化。命令行交互式的剖析方法更常用，也是基本的性能数据剖析方法；而基于Web图形化的剖析方法在剖析结果展示上更为直观。

>> （1）命令行交互方式
可以通过下面三种方式执行
go tool pprof以进入采用命令行交互式的性能数据剖析环节：
$go tool pprof xxx.test cpu.prof // 剖析通过性能基准测试采集的数据

$go tool pprof standalone_app cpu.prof // 剖析独立程序输出的性能采集数据// 

通过net/http/pprof注册的性能采集数据服务端点获取数据并剖析
$go tool pprof http://localhost:8080/debug/pprof/profile

>> topN命令的输出结果默认按flat(flat%)从大到小的顺序输出。
◦  flat列的值表示函数自身代码在数据采样过程中的执行时长。
◦  flat%列的值表示函数自身代码在数据采样过程中的执行时长占总采样执行时长的百分比。
◦  sum%列的值是当前行flat%值与排在该值前面所有行的flat%值的累加和。以第三行的sum%值75.00%为例，该值由前三行flat%累加而得，即16.67% + 20.83% + 37.50% = 75.00%。
◦  cum列的值表示函数自身在数据采样过程中出现的时长，这个时长是其自身代码执行时长及其等待其调用的函数返回所用时长的总和。越是接近函数调用栈底层的代码，其cum列的值越大。
◦  cum%列的值表示该函数cum值占总采样时长的百分比。比如：runtime.findrunnable函数的cum值为130ms，总采样时长为240ms，则其cum%值为两者的比值百分化后的值。

>> 命令行交互模式也支持按cum值从大到小的顺序输出采样结果：
(pprof) top -cum

>> 在命令行交互模式下，可以通过list命令列出函数对应的源码，比如列出main.main函数的源码：
(pprof) list main.main

>> 展开源码的同时，pprof还列出了代码中对应行的消耗时长（基于采样数据）。可以选择耗时较长的函数，进一步向下展开，这个过程类似一个对代码进行向下钻取的过程，直到找到令我们满意的结果（某个导致性能瓶颈的函数中的某段代码）

>> 在命令行交互模式下，还可以生成CPU采样数据的函数调用图，且可以导出为多种格式，如PDF、PNG、JPG、GIF、SVG等。不过要做到这一点，前提是本地已安装图片生成所依赖的插件graphviz。
如下导出一幅PNG格式的图片：
(pprof) pngGenerating report in profile001.png
png命令在当前目录下生成了一幅名为profile001.png的图片文件

>> 在命令行交互模式下，通过web命令还可以在输出SVG格式图片的同时自动打开本地浏览器展示该图片。要实现这个功能也有一个前提，那就是本地SVG文件的默认打开应用为浏览器，否则生成的SVG文件很可能会以其他文本形式被其他应用打开。

>> （2）Web图形化方式

>> 通过下面的命令行启动一个Web服务并自动打开本地浏览器、进入图形化剖析页面（见图47-4）：
$go tool pprof -http=:9090 pprof_standalone1_cpu.profServing web UI on http://localhost:9090

>> Top视图等价于命令行交互模式下的topN命令输出

>> Source视图等价于命令行交互模式下的list命令输出

>> Flame Graph视图即火焰图，该类型视图由性能架构师Brendan Gregg发明，并在近几年被广大开发人员接受。Go 1.10版本在go工具链中添加了对火焰图的支持。通过火焰图（见图47-7），我们可以快速、准确地识别出执行最频繁的代码路径，因此它多用于对CPU类型采集数据的辅助剖析（其他类型的性能采样数据也有对应的火焰图，比如内存分配）。

>> go tool pprof在浏览器中呈现出的火焰图与标准火焰图有些差异：它是倒置的，即调用栈最顶端的函数在最下方。在这样一幅倒置火焰图中，y轴表示函数调用栈，每一层都是一个函数。调用栈越深，火焰越高。倒置火焰图每个函数调用栈的最下方就是正在执行的函数，上方都是它的父函数。

>> 火焰图的x轴表示抽样数量，如果一个函数在x轴上占据的宽度越宽，就表示它被抽样到的次数越多，即执行的时间越长。倒置火焰图就是看最下面的哪个函数占据的宽度最大，这样的函数可能存在性能问题。

>> 47.2　使用pprof进行性能剖析的实例

>> 1. 待优化程序（step0）

>> 待优化程序是一个简单的HTTP服务，当通过浏览器访问其/hi服务端点时

>> 页面上有一个计数器，显示访客是网站的第几个访客。该页面还支持通过color参数进行标题颜色定制，比如使用浏览器访问下面的地址后，页面显示的“Welcome!”标题将变成红色。
http://localhost:8080/hi?color=red
该待优化程序的源码如下：
//chapter8/sources/go-pprof-optimization-demo/step0/demo.govar visitors int64func handleHi(w http.ResponseWriter, r *http.Request) {    if match, _ := regexp.MatchString(`^\w*$`, r.FormValue("color")); !match {        http.Error(w, "Optional color is invalid", http.StatusBadRequest)        return    }    visitNum := atomic.AddInt64(&visitors, 1)    w.Header().Set("Content-Type", "text/html; charset=utf-8")    w.Write([]byte("<h1 style='color: " + r.FormValue("color") +        "'>Welcome!</h1>You are visitor number " + fmt.Sprint(visitNum) + "!"))}func main() {    log.Printf("Starting on port 8080")    http.HandleFunc("/hi", handleHi)    log.Fatal(http.ListenAndServe("127.0.0.1:8080", nil))}

>> 2. CPU类性能数据采样及数据剖析（step1）

>> go tool pprof支持多种类型的性能数据采集和剖析，在大多数情况下我们都会先从CPU类性能数据的剖析开始。

>> 通过为示例程序建立性能基准测试的方式采集CPU类性能数据。
// chapter8/sources/go-pprof-optimization-demo/step1/demo_test.go...func BenchmarkHi(b *testing.B) {    req, err := http.ReadRequest(bufio.NewReader(strings.NewReader("GET /hi HTTP/1.0\r\n\r\n")))    if err != nil {        b.Fatal(err)    }    rw := httptest.NewRecorder()    b.ResetTimer()    for i := 0; i < b.N; i++ {        handleHi(rw, req)    }}...

>> 建立基准，取得初始基准测试数据：
$go test -v -run=^$ -bench=.

>> goos: darwingoarch: amd64pkg: chapter8/sources/go-pprof-optimization-demo/step1BenchmarkHiBenchmarkHi-8       365084             3218 ns/opPASSok         chapter8/sources/go-pprof-optimization-demo/step1   2.069s
接下来，利用基准测试采样CPU类型性能数据：
$go test -v -run=^$ -bench=^BenchmarkHi$ -benchtime=2s -cpuprofile=cpu.prof

>> 执行完上述命令后，step1目录下会出现两个新文件step1.test和cpu.prof。我们将这两个文件作为go tool pprof的输入对性能数据进行剖析：

>> $go tool pprof step1.test cpu.profFile: step1.testType: cpuTime: xxDuration: 2.35s, Total samples = 2.31s (98.44%)Entering interactive mode (type "help" for commands, "o" for options)(pprof) top -cumShowing nodes accounting for 0.18s, 7.79% of 2.31s totalDropped 43 nodes (cum <= 0.01s)Showing top 10 nodes out of 121      flat  flat%   sum%        cum   cum%         0     0%     0%      1.90s 82.25%  chapter8/sources/go-pprof-optimization-demo/step1.BenchmarkHi         0     0%     0%      1.90s 82.25%  chapter8/sources/go-pprof-optimization-demo/step1.handleHi         0     0%     0%      1.90s 82.25%  testing.(*B).launch         0     0%     0%      1.90s 82.25%  testing.(*B).runN         0     0%     0%      1.31s 56.71%  regexp.MatchString         0     0%     0%      1.26s 54.55%  regexp.Compile (inline)     0.01s  0.43%  0.43%      1.26s 54.55%  regexp.compile     0.16s  6.93%  7.36%      0.75s 32.47%  runtime.mallocgc     0.01s  0.43%  7.79%      0.49s 21.21%  regexp/syntax.Parse         0     0%  7.79%      0.48s 20.78%  bytes.(*Buffer).Write(pprof)

>> 通过top -cum，我们看到handleHi累积消耗CPU最多（用户层代码范畴）。通过list命令进一步展开handleHi函数：
(pprof) list handleHiTotal: 2.31sROUTINE ======================== chapter8/sources/go-pprof-optimization-demo/step1.handleHi in chapter8/sources/go-pprof-optimization-demo/step1/demo.go         0      1.90s (flat, cum) 82.25% of Total         .          .      9:)         .          .     10:         .          .     11:var visitors int64 // must be accessed atomically         .          .     12:         .          .     13:func handleHi(w http.ResponseWriter, r *http.Request) {         .      1.31s      14:if match, _ := regexp.MatchString(`^\w*$`, r.FormValue                                                  ("color")); !match {         .          .     15:              http.Error(w, "Optional color is invalid",                                                   http.StatusBadRequest)         .          .     16:              return         .          .     17:}         .          .     18:visitNum := atomic.AddInt64(&visitors, 1)         .       30ms     19:w.Header().Set("Content-Type", "text/html;                                                  charset=utf-8")         .      500ms      20:w.Write([]byte("<h1 style='color: " + r.FormValue                                         ("color") +         .       60ms     21:           "'>Welcome!</h1>You are visitor number                                            " + fmt.Sprint(visitNum) + "!"))         .          .     22:}         .          .     23:         .          .     24:func main() {         .          .     25:log.Printf("Starting on port 8080")         .          .     26:http.HandleFunc("/hi", handleHi)(pprof)
我们看到在handleHi中，MatchString函数调用耗时最长（1.31s）。

>> 3. 第一次优化（step2）
通过前面对CPU类性能数据的剖析，我们发现MatchString较为耗时。通过阅读代码发现，每次HTTP服务接收请求后，都会采用正则表达式对请求中的color参数值做一次匹配校验。校验使用的是regexp包的MatchString函数，该函数每次执行都要重新编译传入的正则表达式，因此速度较慢。我们的优化手段是：让正则表达式仅编译一次。下面是优化后的代码：
// chapter8/sources/go-pprof-optimization-demo/step2/demo.go...var visitors int64var rxOptionalID = regexp.MustCompile(`^\d*$`)func handleHi(w http.ResponseWriter, r *http.Request) {    if !rxOptionalID.MatchString(r.FormValue("color")) {        http.Error(w, "Optional color is invalid", http.StatusBadRequest)        return    }    ...}...

>> 在优化后的代码中，我们使用一个代表编译后正则表达式对象的rxOptionalID的MatchString方法替换掉了每次都需要重新编译正则表达式的MatchString函数调用。
重新运行一下性能基准测试：
$go test -v -run=^$ -bench=.goos: darwingoarch: amd64pkg: chapter8/sources/go-pprof-optimization-demo/step2BenchmarkHiBenchmarkHi-8      2624650              457 ns/opPASSok         chapter8/sources/go-pprof-optimization-demo/step2   1.734s
相比于优化前（3218 ns/op），优化后handleHi的性能（457 ns/op）提高了7倍多。

>> 4. 内存分配采样数据剖析
在对待优化程序完成CPU类型性能数据剖析及优化实施之后，再来采集另一种常用的性能采样数据——内存分配类型数据，探索一下在内存分配方面是否还有优化空间。Go程序内存分配一旦过频过多，就会大幅增加Go GC的工作负荷，这不仅会增加GC所使用的CPU开销，还会导致GC延迟增大，从而影响应用的整体性能。因此，优化内存分配行为在一定程度上也是提升应用程序性能的手段。

>> 在go-pprof-optimization-demo/step2目录下，为demo_test.go中的BenchmarkHi增加Report-Allocs方法调用，让其输出内存分配信息。然后，通过性能基准测试的执行获取内存分配采样数据：
$go test -v -run=^$ -bench=^BenchmarkHi$ -benchtime=2s -memprofile=mem.profgoos: darwingoarch: amd64pkg: chapter8/sources/go-pprof-optimization-demo/step2BenchmarkHiBenchmarkHi-8       5243474      455 ns/op      364 B/op      5 allocs/opPASSok         chapter8/sources/go-pprof-optimization-demo/step2   3.052s

>> 接下来，使用pprof工具剖析输出的内存分配采用数据（mem.prof）：
$go tool pprof step2.test mem.profFile: step2.testType: alloc_spaceEntering interactive mode (type "help" for commands, "o" for options)(pprof)
在go tool pprof的输出中有一行为Type: alloc_space。这行的含义是当前pprof将呈现程序运行期间所有内存分配的采样数据（即使该分配的内存在最后一次采样时已经被释放）。还可以让pprof将Type切换为inuse_space，这个类型表示内存数据采样结束时依然在用的内存。

>> 可以在启动pprof工具时指定所使用的内存数据呈现类型：
$go tool pprof --alloc_space step2.test mem.prof // 遗留方式$go tool pprof -sample_index=alloc_space step2.test mem.prof //最新方式
亦可在进入pprof交互模式后，通过sample_index命令实现切换：
(pprof) sample_index = inuse_space
现在以alloc_space类型进入pprof命令交互界面并执行top命令：
$go tool pprof -sample_index=alloc_space step2.test mem.profFile: step2.testType: alloc_spaceEntering interactive mode (type "help" for commands, "o" for options)(pprof) top -cumShowing nodes accounting for 2084.53MB, 99.45% of 2096.03MB totalShowing top 10 nodes out of 11     flat  flat%   sum%        cum   cum%        0     0%     0%  2096.03MB   100%  chapter8/sources/go-pprof-optimization-                                           demo/step2.BenchmarkHi 840.55MB 40.10% 40.10%  2096.03MB   100%  chapter8/sources/go-pprof-optimization-                                           demo/step2.handleHi        0     0% 40.10%  2096.03MB   100%  testing.(*B).launch        0     0% 40.10%  2096.03MB   100%  testing.(*B).runN        0     0% 40.10%  1148.98MB 54.82%  bytes.(*Buffer).Write        0     0% 40.10%  1148.98MB 54.82%  bytes.(*Buffer).grow1148.98MB 54.82% 94.92%  1148.98MB 54.82%  bytes.makeSlice        0     0% 94.92%  1148.98MB 54.82%  net/http/httptest.(*ResponseRecorder).                                           Write        0     0% 94.92%       95MB  4.53%  net/http.Header.Set (inline)     95MB  4.53% 99.45%       95MB  4.53%  net/textproto.MIMEHeader.Set (inline)(pprof)

>> 我们看到handleHi分配了较多内存。通过list命令展开handleHi的代码：
(pprof) list handleHiTotal: 2.05GBROUTINE ======================== chapter8/sources/go-pprof-optimization-demo/step2.handleHi in chapter8/sources/go-pprof-optimization-demo/step2/demo.go  840.55MB     2.05GB (flat, cum)   100% of Total         .          .     17:    http.Error(w, "Optional color is invalid",                                            http.StatusBadRequest)         .          .     18:    return         .          .     19: }         .          .     20:         .          .     21:  visitNum := atomic.AddInt64(&visitors, 1)         .       95MB     22:  w.Header().Set("Content-Type", "text/html;                                             charset= utf-8")  365.52MB     1.48GB     23:  w.Write([]byte("<h1 style='color: " +                                             r.FormValue ("color") +  475.02MB   486.53MB     24:    "'>Welcome!</h1>You are visitor number " +                                      fmt.Sprint(visitNum) + "!"))         .          .     25:}         .          .     26:         .          .     27:func main() {         .          .     28:  log.Printf("Starting on port 8080")         .          .     29:  http.HandleFunc("/hi", handleHi)(pprof)
通过list的输出结果我们可以看到handleHi函数的第23~25行分配了较多内存（见第一列）。

>> 5. 第二次优化（step3）
这里进行内存分配的优化方法如下：
◦  删除w.Header().Set这行调用；
◦  使用fmt.Fprintf替代w.Write。
优化后的handleHi代码如下：
// go-pprof-optimization-demo/step3/demo.go...func handleHi(w http.ResponseWriter, r *http.Request) {    if !rxOptionalID.MatchString(r.FormValue("color")) {        http.Error(w, "Optional color is invalid", http.StatusBadRequest)        return    }    visitNum := atomic.AddInt64(&visitors, 1)    fmt.Fprintf(w, "<html><h1 stype='color: %s'>Welcome!</h1>You are visitor number %d!", r.FormValue("color"), visitNum)}...

>> 再次执行性能基准测试来收集内存采样数据：
$go test -v -run=^$ -bench=^BenchmarkHi$ -benchtime=2s -memprofile=mem.profgoos: darwingoarch: amd64pkg: github.com/bigwhite/books/effective-go/chapters/chapter8/sources/go-pprof-optimization-demo/step3BenchmarkHiBenchmarkHi-8       7090537      346 ns/op      173 B/op      1 allocs/opPASSok      chapter8/sources/go-pprof-optimization-demo/step3     2.925s
和优化前的数据对比，内存分配次数由5 allocs/op降为1 allocs/op，每op分配的字节数由364B降为173B。

>> 再次通过pprof对上面的内存采样数据进行分析，查看BenchmarkHi中的内存分配情况：
$go tool pprof step3.test mem.profFile: step3.testType: alloc_spaceEntering interactive mode (type "help" for commands, "o" for options)(pprof) list handleHiTotal: 1.27GBROUTINE ======================== chapter8/sources/go-pprof-optimization-demo/step3.handleHi in chapter8/sources/go-pprof-optimization-demo/step3/demo.go   51.50MB     1.27GB (flat, cum)   100% of Total         .          .     17:    http.Error(w, "Optional color is invalid",                                             http. StatusBadRequest)         .          .     18:    return         .          .     19:  }         .          .     20:         .          .     21:  visitNum := atomic.AddInt64(&visitors, 1)   51.50MB     1.27GB     22:  fmt.Fprintf(w, "<html><h1 stype='color: %s'>Welcome!                                     </h1>You are visitor number %d!",                                  r.FormValue ("color"),visitNum)         .          .     23:}         .          .     24:         .          .     25:func main() {         .          .     26:  log.Printf("Starting on port 8080")         .          .     27:  http.HandleFunc("/hi", handleHi)(pprof)
我们看到，对比优化前handleHi的内存分配的确大幅减少（第一列：365MB+475MB -> 51.5MB）。

>> 6. 零内存分配（step4）

>> 经过一轮内存优化后，handleHi当前的内存分配集中到下面这行代码：
fmt.Fprintf(w, "<html><h1 stype='color: %s'>Welcome!</h1>You are visitor number %d!", r.FormValue("color"), visitNum)
fmt.Fprintf的原型如下：
$ go doc fmt.Fprintffunc Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error)
我们看到Fprintf参数列表中的变长参数都是interface{}类型。前文曾提到过，一个接口类型占据两个字（word），在64位架构下，这两个字就是16字节。这意味着我们每次调用fmt.Fprintf，程序就要为每个变参分配一个占用16字节的接口类型变量，然后用传入的类型初始化该接口类型变量。这就是这行代码分配内存较多的原因。

>> 要实现零内存分配，可以像下面这样优化代码：
// chapter8/sources/go-pprof-optimization-demo/step4/demo.go...var visitors int64 // 必须被自动访问var rxOptionalID = regexp.MustCompile(`^\d*$`)var bufPool = sync.Pool{    New: func() interface{} {        return bytes.NewBuffer(make([]byte, 128))    },}func handleHi(w http.ResponseWriter, r *http.Request) {    if !rxOptionalID.MatchString(r.FormValue("color")) {        http.Error(w, "Optional color is invalid", http.StatusBadRequest)        return    }    visitNum := atomic.AddInt64(&visitors, 1)    buf := bufPool.Get().(*bytes.Buffer)    defer bufPool.Put(buf)    buf.Reset()    buf.WriteString("<h1 style='color: ")    buf.WriteString(r.FormValue("color"))    buf.WriteString("'>Welcome!</h1>You are visitor number ")    b := strconv.AppendInt(buf.Bytes(), visitNum, 10)    b = append(b, '!')    w.Write(b)}
这里有几点主要优化：
◦  使用sync.Pool减少重新分配bytes.Buffer的次数；
◦  采用预分配底层存储的bytes.Buffer拼接输出；
◦  使用strconv.AppendInt将整型数拼接到bytes.Buffer中，

>> strconv.AppendInt的实现如下：
// $GOROOT/src/strconv/itoa.gofunc AppendInt(dst []byte, i int64, base int) []byte {    if fastSmalls && 0 <= i && i < nSmalls && base == 10 {        return append(dst, small(int(i))...)    }    dst, _ = formatBits(dst, uint64(i), base, i < 0, true)    return dst}
我们看到AppendInt内置对十进制数的优化。对于我们的代码而言，这个优化的结果就是没有新分配内存，而是利用了传入的bytes.Buffer的实例，这样，代码中strconv.AppendInt的返回值变量b就是bytes.Buffer实例的底层存储切片。
运行一下最新优化后代码的性能基准测试并采样内存分配性能数据：
$go test -v -run=^$ -bench=^BenchmarkHi$ -benchtime=2s -memprofile=mem.profgoos: darwingoarch: amd64pkg: chapter8/sources/go-pprof-optimization-demo/step4BenchmarkHiBenchmarkHi-8      10765006      234 ns/op      199 B/op      0 allocs/opPASSok         chapter8/sources/go-pprof-optimization-demo/step4  2.884s
可以看到，上述性能基准测试的输出结果中每op的内存分配次数为0，而且程序性能也有了提升（346 ns/op → 234 ns/op）。剖析一下输出的内存采样数据：
$go tool pprof step4.test mem.profFile: step4.testType: alloc_spaceEntering interactive mode (type "help" for commands, "o" for options)(pprof) list handleHiTotal: 2.12GBROUTINE ======================== chapter8/sources/go-pprof-optimization-demo/step4.handleHi in chapter8/sources/go-pprof-optimization-demo/step4/demo.go         0     2.12GB (flat, cum)   100% of Total         .          .     33:buf.WriteString("<h1 style='color: ")         .          .     34:buf.WriteString(r.FormValue("color"))         .          .     35:buf.WriteString("'>Welcome!</h1>You are visitor                                                  number ")         .          .     36:b := strconv.AppendInt(buf.Bytes(), visitNum, 10)         .          .     37:b = append(b, '!')         .     2.12GB     38:w.Write(b)         .          .     39:}         .          .     40:         .          .     41:func main() {         .          .     42:log.Printf("Starting on port 8080")         .          .     43:http.HandleFunc("/hi", handleHi)(pprof)
从handleHi代码展开的结果中已经看不到内存分配的数据了（第一列）。

>> 7. 查看并发下的阻塞情况（step5）

>> 前面进行的性能基准测试都是顺序执行的，无法反映出handleHi在并发下多个goroutine的阻塞情况，比如在某个处理环节等待时间过长等。为了了解并发下handleHi的表现，我们为它编写了一个并发性能基准测试：
// chapter8/sources/go-pprof-optimization-demo/step5/demo_test.go...func BenchmarkHiParallel(b *testing.B) {    r, err := http.ReadRequest(bufio.NewReader(strings.NewReader("GET /hi HTTP/1.0\r\n\r\n")))    if err != nil {        b.Fatal(err)    }    b.ResetTimer()    b.RunParallel(func(pb *testing.PB) {        rw := httptest.NewRecorder()        for pb.Next() {            handleHi(rw, r)        }    })}...

>> 执行该基准测试，并对阻塞时间类型数据（block.prof）进行采样与剖析：
$go test -bench=Parallel -blockprofile=block.profgoos: darwingoarch: amd64pkg: chapter8/sources/go-pprof-optimization-demo/step5BenchmarkHiParallel-8     15029988              118 ns/opPASSok         chapter8/sources/go-pprof-optimization-demo/step5   2.092s$go tool pprof step5.test block.profFile: step5.testType: delayEntering interactive mode (type "help" for commands, "o" for options)(pprof) topShowing nodes accounting for 3.70s, 100% of 3.70s totalDropped 18 nodes (cum <= 0.02s)Showing top 10 nodes out of 15      flat  flat%   sum%        cum   cum%     1.85s 50.02% 50.02%      1.85s 50.02%  runtime.chanrecv1     1.85s 49.98%   100%      1.85s 49.98%  sync.(*WaitGroup).Wait         0     0%   100%      1.85s 49.98%  chapter8/sources/go-pprof-optimization-                                            demo/step5.BenchmarkHiParallel         0     0%   100%      1.85s 50.02%  main.main         0     0%   100%      1.85s 50.02%  runtime.main         0     0%   100%      1.85s 50.02%  testing.(*B).Run         0     0%   100%      1.85s 49.98%  testing.(*B).RunParallel         0     0%   100%      1.85s 50.01%  testing.(*B).doBench         0     0%   100%      1.85s 49.98%  testing.(*B).launch         0     0%   100%      1.85s 50.01%  testing.(*B).run(pprof) list handleHiTotal: 3.70sROUTINE ======================== chapter8/sources/go-pprof-optimization-demo/step5.handleHi in chapter8/sources/go-pprof-optimization-demo/step5/demo.go         0    18.78us (flat, cum) 0.00051% of Total         .          .     19:    return bytes.NewBuffer(make([]byte, 128))         .          .     20:  },         .          .     21:}         .          .     22:         .          .     23:func handleHi(w http.ResponseWriter, r *http.Request) {         .    18.78us     24:  if !rxOptionalID.MatchString(r.FormValue("color")) {         .          .     25:    http.Error(w, "Optional color is invalid",                                    http. StatusBadRequest)         .          .     26:    return         .          .     27:  }         .          .     28:         .          .     29:  visitNum := atomic.AddInt64(&visitors, 1)(pprof)

>> handleHi并未出现在top10排名中。进一步展开handleHi代码后，我们发现整个函数并没有阻塞goroutine过长时间的环节，因此无须对handleHi进行任何这方面的优化。当然这也源于Go标准库对regexp包的Regexp.MatchString方法做过针对并发的优化（也是采用sync.Pool），具体优化方法这里就不赘述了。

>> 小结
在这一条中，我们学习了如何对Go程序进行性能剖析，讲解了使用pprof工具对Go应用进行性能剖析的原理、使用方法，并用一个示例演示了如何实施性能优化。
本条要点：
◦  通过性能基准测试判定程序是否存在性能瓶颈，如存在，可通过Go工具链中的pprof对程序性能进行剖析；
◦  性能剖析分为两个阶段——数据采集和数据剖析；
◦  go tool pprof工具支持多种数据采集方式，如通过性能基准测试输出采样结果和独立程序的性能数据采集；
◦  go tool pprof工具支持多种性能数据采样类型，如CPU类型（-cpuprofile）、堆内存分配类型（-memprofile）、锁竞争类型（-mutexprofile）、阻塞时间数据类型（-block-profile）等；
◦  go tool pprof支持两种主要的性能数据剖析方式，即命令行交互式和Web图形化方式；
◦  在不明确瓶颈原因的情况下，应优先对CPU类型和堆内存分配类型性能采样数据进行剖析。

>> 第48条使用expvar输出度量数据，辅助定位性能瓶颈点

>> 想对Go应用存在的性能瓶颈进行剖析，首先就要对不同类型的性能数据进行收集和采样。有两种收集和采样数据的方法。在微观层面，采用通过运行性能基准测试收集和采样数据的方法，这种方法适用于定位函数或方法实现中存在性能瓶颈点的情形；在宏观层面，采用独立程序收集和采样数据的方法。但通过独立程序进行性能数据采样时，往往很难快速捕捉到真正的瓶颈点，尤其是对于那些内部结构复杂、业务逻辑过多、内部有较多并发的Go程序。我们在对这样的程序进行性能采样时，真正的瓶颈点很可能被其他数据遮盖。

>> 那么如何能更高效地捕捉到应用的性能瓶颈点呢？我们需要知道Go应用运行的状态。应用运行状态一般以度量数据的形式呈现。通过了解应用关键路径上的度量数据，我们可以确定在某个度量点上应用的性能是符合预期性能指标还是较大偏离预期，这样就可以最大限度地缩小性能瓶颈点的搜索范围，从而快速定位应用中的瓶颈点并进行优化。
这些可以反映应用运行状态的数据也被称为应用的内省（introspection）数据。相比于通过查询应用外部特征而获取的探针类（probing）数据（比如查看应用某端口是否有响应并返回正确的数据或状态码），内省数据可以传达更为丰富、更多的有关应用程序状态的上下文信息。这些上下文信息可以是应用对各类资源的占用信息，比如应用运行占用了多少内存空间，也可以是自定义的性能指标信息，比如单位时间处理的外部请求数量、应答延迟、队列积压量等。
传统编程语言（如C++、Java等）并没有内置输出应用状态度量数据的设施（接口方式、指标定义方法、数据输出格式等），需要开发者自己通过编码实现或利用第三方库实现。Go是“自带电池”的编程语言，我们可以轻松地使用Go标准库提供的expvar包按统一接口、统一数据格式、一致的指标定义方法输出自定义的度量数据。在本条中，我们就一起来看看如何使用expvar输出自定义的性能度量数据。

>> 48.1　expvar包的工作原理

>> Go标准库中的expvar包提供了一种输出应用内部状态信息的标准化方案，这个方案标准化了以下三方面内容：
◦  数据输出接口形式；
◦  输出数据的编码格式；
◦  用户自定义性能指标的方法。

>> Go应用通过expvar包输出内部状态信息的工作原理如图48-1所示。

图48-1　expvar包工作原理

>> Go应用如果需要输出自身状态数据，需要以下面的形式导入expvar：
import _ "expvar"
和net/http/pprof类似，expvar包也在自己的init函数中向http包的默认请求“路由器”DefaultServeMux注册一个服务端点/debug/vars：
// $GOROOT/src/expvar/expvar.gofunc init() {    http.HandleFunc("/debug/vars", expvarHandler)    ...}

>> 这个服务端点就是expvar提供给外部的获取应用内部状态的唯一标准接口，外部工具（无论是命令行还是基于Web的图形化程序）都可以通过标准的http get请求从该服务端点获取应用内部状态数据。

>> // chapter8/sources/expvar_demo1.gopackage mainimport (    _ "expvar"    "fmt"    "net/http")func main() {    http.Handle("/hi", http.HandlerFunc(func(w http.ResponseWriter,        r *http.Request) {        w.Write([]byte("hi"))    }))    fmt.Println(http.ListenAndServe("localhost:8080", nil))}
运行上述示例后，通过浏览器访问http://localhost:8080/debug/vars

>> 如果应用程序本身并没有使用默认“路由器”DefaultServeMux，那么我们需要手动将expvar包的服务端点注册到应用程序所使用的“路由器”上。expvar包提供了Handler函数，该函数可用于其内部expvarHandler的注册。
// expvar_demo2.gopackage mainimport (    "expvar"    "fmt"    "net/http")func main() {    mux := http.NewServeMux()    mux.Handle("/hi", http.HandlerFunc(func(w http.ResponseWriter,        r *http.Request) {        w.Write([]byte("hi"))    }))    mux.Handle("/debug/vars", expvar.Handler())    fmt.Println(http.ListenAndServe("localhost:8080", mux))}
如果应用程序本身并没有启动HTTP服务，那么还需在一个单独的goroutine中启动一个HTTP服务，这样expvar提供的服务才能有效。

>> expvar包提供的内部状态服务端点返回的是标准的JSON格式数据。样例如下：
{    "cmdline": ["/var/folders/cz/sbj5kg2d3m3c6j650z0qfm800000gn/T/go-build507091832/ b001/exe/expvar_demo2"],    "memstats": {        "Alloc": 223808,        "TotalAlloc": 223808,        "Sys": 71387144,        "Lookups": 0,        "Mallocs": 743,        "Frees": 11,        ...    }}
在默认返回的状态数据中包含了两个字段：cmdline和memstats。这两个输出数据是expvar包在init函数中就已经发布（Publish）了的变量：
//$GOROOT/src/expvar/expvar.gofunc init() {    http.HandleFunc("/debug/vars", expvarHandler)    Publish("cmdline", Func(cmdline))    Publish("memstats", Func(memstats))}
cmdline字段的含义是输出数据的应用名，这里因为是通过go run运行的应用，所以cmdline的值是一个临时路径下的应用。
而memstats输出的数据对应的是runtime.Memstats结构体，反映的是应用在运行期间堆内存分配、栈内存分配及GC的状态。runtime.Memstats结构体的字段可能会随着Go版本的演进而发生变化，其字段具体含义可以参考Memstats结构体中的注释。

>> //$GOROOT/src/expvar/expvar.gofunc memstats() interface{} {    stats := new(runtime.MemStats)    runtime.ReadMemStats(stats)    return *stats}

>> 48.2　自定义应用通过expvar输出的度量数据

>> ◦  标准的接口：通过http get（默认从/debug/vars服务端点获取数据）。
◦  标准的数据编码格式：JSON。

>> 第三个标准：自定义输出的度量数据的标准方法

>> 从debug/vars服务端点获取到的JSON结果数据中有一个名为custom_var的字段，这是一个自定义的度量数据。

>> Go应用的init函数中，我们发现了下面的代码：
func init() {    expvar.Publish("custom_var", customVar)}
expvar包提供了Publish函数，该函数用于发布通过debug/vars服务端点输出的数据，上面expvar内置输出的cmdline和memstats就是通过Publish函数发布的。Publish函数的原型如下：
// $GOROOT/src/expvar/expvar.gofunc Publish(name string, v Var)
该函数接收两个参数：name和v。name是对应字段在输出结果中的字段名，而v是字段值。v的类型为Var，这是一个接口类型：
// $GOROOT/src/expvar/expvar.gotype Var interface {    String() string}
所有实现了该接口类型的变量都可以被发布并作为输出的应用内部状态的一部分。

>> 我们在设计能反映Go应用内部状态的自定义指标时，经常会设计下面两类指标。
◦  测量型：这类指标是数字，支持上下增减。我们定期获取该指标的快照。常见的CPU、内存使用率等指标都可归为此类型。在业务层面，当前网站上的在线访客数量、当前业务系统平均响应延迟等都属于这类指标。
◦  计数型：这类指标也是数字，它的特点是随着时间的推移，其数值不会减少。虽然它们永远不会减少，但有时可以将其重置为零，它们会再次开始递增。系统正常运行时间、某端口收发包的字节数、24小时内入队列的消息数量等都是此类指标。计数型指标的一个优势在于可以用来计算变化率：将T+1时刻获取的指标值与T时刻的指标值做比较，即可获得两个时刻之间的变化率。
针对上述两类常见指标，我们无须像上面示例中的CustomVar那样自行实现，expvar包提供了对常用指标类型的原生支持，比如整型指标、浮点型指标以及像memstats那样的Map型复合指标等。以最常用的整型指标为例：
//$GOROOT/src/expvar/expvar.gotype Int struct {    i int64}func (v *Int) Value() int64 {    return atomic.LoadInt64(&v.i)}func (v *Int) String() string {    return strconv.FormatInt(atomic.LoadInt64(&v.i), 10)}func (v *Int) Add(delta int64) {    atomic.AddInt64(&v.i, delta)}func (v *Int) Set(value int64) {    atomic.StoreInt64(&v.i, value)}

>> expvar.Int类型在满足Var接口的同时，还实现了Add、Set和Value方法，方便我们使用它来创建测量型、计数型指标，并且对其值的修改是并发安全的。针对expvar.Int类型，expvar包还提供了创建即发布的NewInt函数，这样我们就无须再自行调用Publish函数发布指标了：
func NewInt(name string) *Int {    v := new(Int)    Publish(name, v)    return v}
将上面示例中的customVar指标改为使用expvar.Int实现：
// chapter8/sources/expvar_demo4.govar customVar *expvar.Intfunc init() {    customVar = expvar.NewInt("customVar")    customVar.Set(17)}func main() {    http.Handle("/hi", http.HandlerFunc(func(w http.ResponseWriter,        r *http.Request) {        w.Write([]byte("hi"))    }))    // 模拟业务逻辑    go func() {        // ...        for {            customVar.Add(1)            time.Sleep(time.Second)        }    }()    fmt.Println(http.ListenAndServe("localhost:8080", nil))}
可以看到利用expvar.Int实现自定义性能指标让代码更为简洁。

>> 看一下使用expvar.Map类型定义一个像memstats那样的复合指标的例子：
// chapter8/sources/expvar_demo5.go...var customVar *expvar.Mapfunc init() {    customVar = expvar.NewMap("customVar")    var field1 expvar.Int    var field2 expvar.Float    customVar.Set("field1", &field1)    customVar.Set("field2", &field2)}func main() {    http.Handle("/hi", http.HandlerFunc(func(w http.ResponseWriter,        r *http.Request) {        w.Write([]byte("hi"))    }))    // 模拟业务逻辑    go func() {        // ...        for {            customVar.Add("field1", 1)            customVar.AddFloat("field2", 0.001)            time.Sleep(time.Second)        }    }()    fmt.Println(http.ListenAndServe("localhost:8080", nil))}

>> 定义一个expvar.Map类型变量后，可以向该复合指标变量中添加指标，比如示例中的“field1”。在业务逻辑中，可以通过expvar.Map提供的Add、AddFloat等方法对复合指标内部的单个指标值进行更新。

>> 如果想将一个结构体类型当作一个复合指标直接输出，expvar包也提供了很好的支持。

>> // chapter8/sources/expvar_demo6.go...type CustomVar struct {    Field1 int64   `json:"field1"`    Field2 float64 `json:"field2"`}var (    field1 expvar.Int    field2 expvar.Float)func exportStruct() interface{} {    return CustomVar{        Field1: field1.Value(),        Field2: field2.Value(),    }}func init() {    expvar.Publish("customVar", expvar.Func(exportStruct))}func main() {    http.Handle("/hi", http.HandlerFunc(func(w http.ResponseWriter,        r *http.Request) {        w.Write([]byte("hi"))    }))    // 模拟业务逻辑    go func() {        // ...        for {            field1.Add(1)            field2.Add(0.001)            time.Sleep(time.Second)        }    }()    fmt.Println(http.ListenAndServe("localhost:8080", nil))}
我们看到，针对结构体类型，expvar包并未提供像对整型、浮点型或Map型那样的直接支持。我们是通过实现一个返回interface{}类型的函数（这里是exportStruct），并通过Publish函数将该函数发布出去的（expvar.Func(exportStruct)）。注意，这个返回interface{}类型的函数的返回值底层类型必须是一个支持序列化为JSON格式的类型。在上面的示例中，这个返回值的底层类型为CustomVar结构体类型，该类型本身支持被序列化为一个JSON文本。理论上，通过这种通用的方法可以发布任何类型的自定义指标。

>> 48.3　输出数据的展示

>> JSON格式文本很容易反序列化，开发者可自行解析后使用，比如：编写一个Prometheus exporter，将数据导入Prometheus背后的存储（比如InfluxDB）中，并利用一些基于Web图形化的方式直观展示出来；或者导入Elasticsearch，再通过Kibana或Grafana的页面展示出来。
Go开发者Ivan Daniluk开发了一款名为expvarmon的开源工具，该工具支持将从expvar输出的数据以基于终端的图形化方式展示出来。这种方式可以让开发者以最快的速度看到自定义的指标数据。

>> expvarmon基于终端生成的图形化展示页面是定期刷新的，可以通过-i命令行选项指定刷新时间。我们看到，通过expvarmon可以快速将应用内部状态展示出来，而无须安装任何依赖。

>> 小结
在本条中，我们学习了如何使用Go标准库的expvar包输出应用程序内省数据来辅助定位应用性能瓶颈点。expvar包不仅可用于辅助缩小定位性能瓶颈的范围，还可以用来输出度量数据以对应用的运行状态进行监控，这样当程序出现问题时，我们可以快速发现问题并利用输出的度量数据对程序进行诊断并快速定位问题。

>> 本条要点：
◦  将应用内部状态以度量指标数据的形式输出，可以帮助我们最大限度地缩小性能瓶颈的搜索范围并快速定位瓶颈点；
◦  了解expvar包的工作原理；
◦  使用expvar包提供的内置类型实现应用要输出的度量指标；
◦  通过expvarmon等第三方工具快速展示应用内部状态信息。

>> 第49条使用Delve调试Go代码

>> bug就是编码过程的伴生品。既然将之称为“伴生品”，那就意味着“凡是软件，必有bug”。也许有人不同意这个观点，但无关大碍，因为如何看待bug本身就是一个哲学范畴的话题，见仁见智。

>> 49.1　关于调试，你首先应该知道的几件事

>> 2. 预防bug的发生，降低bug的发生概率

>> （1）充分的代码检查

>> 这些工具包括编译器（尽可能将警告级别提升到你可以接受的最高级别）、静态代码检查工具（linter，如go vet）等。

>> （2）为调试版添加断言

>> （3）充分的单元测试

>> （4）代码同级评审

>> 3. bug的原因定位和修正

>> bug不能避免。一旦bug发生，我们该怎么办？其实与bug做艰苦卓绝的斗争也是有一定方法的。

>> （1）收集“现场数据”

>> （2）定位问题所在

>> （3）修正并验证

>> 49.2　Go调试工具的选择

>> 排前两名的分别是使用文本输出（fmt.Print等）调试Go代码和使用专业调试器（如Delve、GDB）在本机上调试Go代码。这里我将采用第一种方法的称为“print派”，将采用第二种方法的称为“专业工具派”。

>> 使用调试器进行调试比仅打印出值和思考要慢得多。

>> 用print语句辅助调试与采用专业调试器对代码进行调试并不矛盾，它们之间是互相补充和相辅相成的。

>> 那么GDB调试器是否可以调试通过标准Go编译器编译生成的Go程序呢？答案是肯定的。但GDB对标准Go编译器输出的程序的支持是不完善的，主要体现在GDB并不十分了解Go程序：

>> GDB显然也不是Go调试工具的最佳选择，虽然其适用于调试带有cgo代码的Go程序或事后调查调试。

>> Delve（https://github.com/go-delve/delve）是另一个Go语言调试器，该调试器工程于2014年由Derek Parker创建。Delve旨在为Go提供一个简单、功能齐全、易用使用和调用的调试工具。它紧跟Go语言版本演进，是目前Go调试器的事实标准。和GDB相比，Delve的优势在于它可以更好地理解Go的一切，对并发程序有着很好的支持，支持跨平台（支持Windows、macOS、Linux三大主流平台），而且前后端分离的设计使得它可以非常容易地被集成到各种IDE（如GoLand）、编译器插件（vscode go、vim-go等）、图形化调试器前端（如gdlv）中。接下来，我们就来看看如何使用Delve调试Go程序。

>> 49.3　Delve调试基础、原理与架构

>> 3. Delve架构与原理

>> 为了便于各种调试器前端（命令行、IDE、编辑器插件、图形化前端）与Delve集成，Delve采用了一个前后分离的架构

>> UI Layer对应的就是我们使用的dlv命令行或Goland/vim-go中的调试器前端，而Service Layer显然用于前后端通信。Delve真正施展的“魔法”是由Symbolic Layer和Target Layer两层合作实现的。
Target Layer通过各个操作系统提供的系统API来控制被调试目标进程，它对被调试目标的源码没有任何了解，实现的功能包括：
◦  挂接（attach）/分离（detach）目标进程；
◦  枚举目标进程中的线程；
◦  启动/停止单个线程（或整个进程）；
◦  接收和处理“调试事件”（线程创建/退出以及线程在断点处暂停）；
◦  读写目标进程的内存；
◦  读写停止线程的CPU寄存器；
◦  读取core dump文件。
真正了解被调试目标源码文件的是Symbolic Layer，这一层通过读取Go编译器（包括链接器）以DWARF格式（一种标准的调试信息格式）写入目标二进制文件中的调试符号信息来了解被调试目标源码，并实现了被调试目标进程中的地址、二进制文件中的调试符号及源码相关信息三者之间的关系映射，如图49-3所示。

图49-3　Delve Symbolic层原理

>> 49.4　并发、Coredump文件与挂接进程调试

>> 1. Delve调试并发程序

>> Delve还提供了thread和threads命令，通过这两个命令我们可以查看当前启动的线程列表并在各个线程间切换，就像上面在goroutine间切换调试一样

>> Delve调试并发程序可以像调试普通程序一样简单、方便。

>> 2. 使用Delve调试core dump文件

>> core dump文件是在程序异常终止或崩溃时操作系统对程序当时的内存状态进行记录并保存而生成的一个数据文件，该文件以core命名，也被称为核心转储文件。通过对操作系统记录的core文件中的数据的分析诊断，开发人员可以快速定位程序中存在的bug，这尤其适用于生产环境中的调试。根据Delve官方文档的描述，Delve目前支持对linux/amd64、linux/arm64架构下产生的core文件的调试，以及Windows/amd64架构下产生的minidump小转储文件的调试。在这里我们以linux/amd64架构为例，看看如何使用Delve调试core dump文件。

>> 建立一个明显会崩溃的Go程序：
// chapter8/sources/delve-demo3/main.gofunc main() {    var p *int    *p = 1    fmt.Println("program exit")}
这个程序运行后将因为空指针解引用而崩溃。我们在Linux/amd64下（Ubuntu 18.04，Go 1.14，Delve 1.4.1）进行这次调试。要想在Linux下让Go程序崩溃时产生core文件，我们需要进行一些设置（因为默认情况下Go程序崩溃并不会产生core文件）：
$ulimit -c unlimited // 不限制core文件大小$go build main.go$GOTRACEBACK=crash ./mainpanic: runtime error: invalid memory address or nil pointer dereference[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x49142f]goroutine 1 [running]:panic(0x4a6ee0, 0x55c880)    /root/.bin/go1.14/src/runtime/panic.go:1060 +0x420 fp=0xc000068ef8 sp=0xc000068e50 pc=0x42e7f0runtime.panicmem(...)    /root/.bin/go1.14/src/runtime/panic.go:212runtime.sigpanic()    /root/.bin/go1.14/src/runtime/signal_unix.go:687 +0x3da fp=0xc000068f28 sp=0xc000068ef8 pc=0x4429eamain.main()    /root/test/go/delve/main.go:8 +0x1f fp=0xc000068f88 sp=0xc000068f28 pc=0x49142fruntime.main()    /root/.bin/go1.14/src/runtime/proc.go:203 +0x212 fp=0xc000068fe0 sp=0xc000068f88 pc=0x431222runtime.goexit()    /root/.bin/go1.14/src/runtime/asm_amd64.s:1373 +0x1 fp=0xc000068fe8 sp=0xc000068fe0 pc=0x45b911...goroutine 5 [runnable]:runtime.runfinq()    /root/.bin/go1.14/src/runtime/mfinal.go:161 fp=0xc0000307e0 sp=0xc0000307d8 pc=0x414f60runtime.goexit()    /root/.bin/go1.14/src/runtime/asm_amd64.s:1373 +0x1 fp=0xc0000307e8 sp=0xc0000307e0 pc=0x45b911created by runtime.createfing    /root/.bin/go1.14/src/runtime/mfinal.go:156 +0x61Aborted (core dumped)

>> 程序如预期崩溃并输出core dumped。在当前目录下，我们能看到core文件已经产生了并且其体积不小（103MB）：
$ls -lhtotal 103M

>> 接下来就轮到Delve登场了，我们假装并不知道问题出在哪里。使用dlv core命令对产生的core文件进行调试：
$dlv core ./main ./coreType 'help' for list of commands.(dlv) bt 0  0x000000000045d4a1 in runtime.raise    at /root/.bin/go1.14/src/runtime/sys_linux_amd64.s:165 1  0x0000000000442acb in runtime.dieFromSignal    at /root/.bin/go1.14/src/runtime/signal_unix.go:721 2  0x0000000000442f5e in runtime.sigfwdgo    at /root/.bin/go1.14/src/runtime/signal_unix.go:935 3  0x00000000004419d4 in runtime.sigtrampgo    at /root/.bin/go1.14/src/runtime/signal_unix.go:404 4  0x000000000045d803 in runtime.sigtramp    at /root/.bin/go1.14/src/runtime/sys_linux_amd64.s:389 5  0x000000000045d8f0 in runtime.sigreturn    at /root/.bin/go1.14/src/runtime/sys_linux_amd64.s:481 6  0x0000000000442c5a in runtime.crash    at /root/.bin/go1.14/src/runtime/signal_unix.go:813 7  0x000000000042ee54 in runtime.fatalpanic    at /root/.bin/go1.14/src/runtime/panic.go:1212 8  0x000000000042e7f0 in runtime.gopanic    at /root/.bin/go1.14/src/runtime/panic.go:1060 9  0x00000000004429ea in runtime.panicmem    at /root/.bin/go1.14/src/runtime/panic.go:21210  0x00000000004429ea in runtime.sigpanic    at /root/.bin/go1.14/src/runtime/signal_unix.go:68711  0x000000000049142f in main.main    at ./main.go:812  0x0000000000431222 in runtime.main    at /root/.bin/go1.14/src/runtime/proc.go:20313  0x000000000045b911 in runtime.goexit    at /root/.bin/go1.14/src/runtime/asm_amd64.s:1373(dlv)

>> 通过stack（简写为bt）命令输出的函数调用栈多为Go运行时的函数，我们唯一熟悉的就是main.main，于是，通过frame命令跳到main.main这个函数栈帧中：
(dlv) frame 11> runtime.raise() /root/.bin/go1.14/src/runtime/sys_linux_amd64.s:165 (PC: 0x45d4a1)Warning: debugging optimized functionFrame 11: ./main.go:8 (PC: 49142f)     3:    import "fmt"     4:     5:    func main() {     6:           var p *int     7:           p = nil=>   8:           *p = 1     9:           fmt.Println("program exit")    10:    }(dlv)
因为代码简单，这里我们一眼就能看出=>所指的那一行代码存在的问题。如果代码复杂且涉及函数调用较多，我们还可以继续通过up和down在各层函数栈帧中搜寻问题的原因。

>> 3. 使用Delve挂接到正在运行的进程进行调试

>> 在一些特定的情况下，我们可能需要对正在运行的Go应用进程进行调试。不过这类调试是有较大风险的：调试器一旦成功挂接到正在运行的进程中，调试器就掌握了进程执行的指挥权，并且正在运行的goroutine都会暂停，等待调试器的进一步指令。因此，不到万不得已，请不要在生产环境中使用这种调试方法。

>> 使用delve attach命令来切入delve-demo2应用正在运行的进程：
$ps -ef|grep delve-demo2  501 75863 63197   0  3:33下午 ttys011    0:00.02 ./delve-demo2$dlv attach 75863 ./delve-demo2Type 'help' for list of commands.(dlv)

>> Delve一旦成功切入delve-demo2进程，delve-demo2进程内的所有goroutine都将暂停运行，等待Delve的进一步指令。现在可以利用之前使用过的所有命令操作被调试进程了，比如查看goroutine列表、设置断点、在断点处暂停调试等。

>> 被调试的进程将在调试器的“指挥”下执行并在代码执行到I/O输出时向标准输出输出对应的变量值。

>> 小结
Delve的功能不限于上面的这些调试场景，比如Delve还支持调试单元测试代码（delve test）等。鉴于篇幅有限，这里不一一细说。另外Delve的单步调试使其非常适合做源码分析辅助工具，在Delve这柄“放大镜”面前，再深奥复杂的源码流程也会被看得一清二楚。
本条要点：
◦  通过编译器、静态代码检查工具（linter）、编写单元测试等最佳实践尽量降低调试在整个开发过程中的比例；
◦  通过编程语言内置的print语句辅助调试与采用专门的调试器调试代码是相辅相成的；
◦  专门的调试器适用于与外部调试前端集成（编辑器插件、IDE、其他图形化前端）；
◦  专门的调试器适用于对core dump文件的调试分析以及生产环境的挂接进程调试；
◦  相比于GDB，Delve能更好地理解Go程序，并支持对Go并发程序、core文件、在线挂接进程及单元测试的调试。


◆ 第九部分 标准库、反射与cgo

>> 第九部分标准库、反射与cgo

>> 第50条理解Go TCP Socket网络编程模型

>> Go中暴露给语言使用者的TCP Socket接口是建立在操作系统原生TCP Socket接口之上的。由于Go运行时调度的需要，Go设计了一套适合自己的TCP Socket网络编程模型。

>> 该模型下Go TCP Socket在各个场景下的使用方法、行为特点及注意事项。

>> 50.1　TCP Socket网络编程模型

>> 网络I/O模型定义的是应用线程与操作系统内核之间的交互行为模式。我们通常用阻塞（Blocking）和非阻塞（Non-Blocking）来描述网络I/O模型。不同标准对于网络I/O模型的说法有所不同，比如POSIX.1标准还定义了同步（Sync）和异步（Async）这两个术语来描述模型。
阻塞和非阻塞是以内核是否等数据全部就绪才返回（给发起系统调用的应用线程）来区分的。如果内核一直等到全部数据就绪才返回，则这种行为模式称为阻塞；如果内核查看数据就绪状态后，即便没有就绪也立即返回错误（给发起系统调用的应用线程），则这种行为模式称为非阻塞。

>> 有些标准使用同步和异步来描述网络I/O操作模型。所谓同步I/O指的是能引起请求线程阻塞，直到I/O操作完成；而异步I/O则不引起请求线程的阻塞。按照这个说法，前面提到的阻塞I/O、非阻塞I/O、I/O多路复用均可看成同步I/O模型，而只有异步I/O才是名副其实的“异步I/O”模型。
伴随着模型的演进，服务程序愈发强大，可以支持更多的连接，获得更好的处理性能。目前主流网络服务器采用的多是I/O多路复用模型，有的也结合了多线程。不过I/O多路复用模型在支持更多连接、提升I/O操作效率的同时，也给使用者带来了不低的复杂性，以至于出现了许多高性能的I/O多路复用框架（如libevent、libev、libuv等）以降低开发复杂性，减轻开发者的心智负担。
不过Go语言的设计者认为I/O多路复用的这种通过回调割裂控制流的模型依旧复杂，且有悖于一般顺序的逻辑设计，为此他们结合Go语言的自身特点，将该“复杂性”隐藏在了Go运行时中。这样，在大多数情况下，Go开发者无须关心Socket是不是阻塞的，也无须亲自将Socket文件描述符的回调函数注册到类似select这样的系统调用中，而只需在每个连接对应的goroutine中以最简单、最易用的阻塞I/O模型的方式进行Socket操作即可，这种设计大大减轻了网络应用开发人员的心智负担。

>> 一个典型的Go网络服务端程序大致如下：
// chapter9/sources/go-tcpsock/server.gofunc handleConn(c net.Conn) {    defer c.Close()    for {        // 从连接上读取数据        // ...        // 向连接上写入数据        // ...    }}func main() {    l, err := net.Listen("tcp", ":8888")    if err != nil {        fmt.Println("listen error:", err)        return    }    for {        c, err := l.Accept()        if err != nil {            fmt.Println("accept error:", err)            break        }        // 启动一个新的goroutine处理这个新连接        go handleConn(c)    }}
在Go程序的用户层（相对于Go运行时层）看来，goroutine采用了“阻塞I/O模型”进行网络I/O操作，Socket都是“阻塞”的。但实际上，这样的假象是Go运行时中的netpoller（网络轮询器）通过I/O多路复用机制模拟出来的，对应的底层操作系统Socket实际上是非阻塞的：
// $GOROOT/src/net/sock_cloexec.gofunc sysSocket(family, sotype, proto int) (int, error) {    ...    if err = syscall.SetNonblock(s, true); err != nil {        poll.CloseFunc(s)        return -1, os.NewSyscallError("setnonblock", err)    }    ...}

>> 只是运行时拦截了针对底层Socket的系统调用返回的错误码，并通过netpoller和goroutine调度让goroutine“阻塞”在用户层所看到的Socket描述符上。比如：当用户层针对某个Socket描述符发起read操作时，如果该Socket对应的连接上尚无数据，那么Go运行时会将该Socket描述符加入netpoller中监听，直到Go运行时收到该Socket数据可读的通知，Go运行时才会重新唤醒等待在该Socket上准备读数据的那个goroutine。而这个过程从goroutine的视角来看，就像是read操作一直阻塞在那个Socket描述符上似的。
Go语言在netpoller中采用了I/O多路复用模型。考虑到最常见的多路复用系统调用select有比较多的限制，比如监听Socket的数量有上限（1024）、时间复杂度高等，Go运行时选择了在不同操作系统上使用操作系统各自实现的高性能多路复用函数，比如Linux上的epoll、Windows上的iocp、FreeBSD/macOS上的kqueue、Solaris上的event port等，这样可以最大限度地提高netpoller的调度和执行性能。

>> 50.2　TCP连接的建立

>> 在连接的建立过程中，服务端是一个标准的Listen+Accept的结构（可参考上面的代码），而在客户端Go语言使用Dial或DialTimeout函数发起连接建立请求。
Dial在调用后将一直阻塞，直到连接建立成功或失败。

>> 1. 网络不可达或对方服务未启动

>> getsockopt: connection refused

>> 2. 对方服务的listen backlog队列满了

>>  dial error: dial tcp :8888: getsockopt: operation timed out

>> 3. 若网络延迟较大，Dial将阻塞并超时

>> Dial也会返回类似“getsockopt: operation timed out”的错误。

>> 将连接的最长阻塞时间限定在2秒，如果超出这个时长，函数将返回超时错误：
// chapter9/sources/go-tcpsock/conn_establish/client3.go...func main() {    log.Println("begin dial...")    conn, err := net.DialTimeout("tcp", "105.236.176.96:80", 2*time.Second)    if err != nil {        log.Println("dial error:", err)        return    }    defer conn.Close()    log.Println("dial ok")}

>> 延迟较大的糟糕网络环境，注意不是不可达）：
$go run client3.go2020/11/17 09:28:34 begin dial...2020/11/17 09:28:36 dial error: dial tcp 105.236.176.96:80: i/o timeout

>> 50.3　Socket读写

>> Go运行时隐藏了I/O多路复用的复杂性。语言使用者只需采用goroutine+阻塞I/O模型即可满足大部分场景需求。

>> Dial连接成功后会返回一个net.Conn接口类型的变量值，这个接口变量的底层类型为一个*TCPConn

>> TCPConn内嵌了一个非导出类型conn，因此“继承”了conn类型的Read和Write方法，后续通过Dial函数返回值调用的Write和Read方法均是net.conn的方法

>> 通过几个场景来总结一下conn.Read的行为特点。
1. Socket中无数据

>> 连接建立后，如果客户端未发送数据，服务端会阻塞在Socket的读操作上，这和前面提到的阻塞I/O模型的行为模式是一致的。执行该读操作的goroutine也会被挂起。Go运行时会监视该Socket，直到其有数据读事件才会重新调度该Socket对应的goroutine完成读操作。

>> 2. Socket中有部分数据

>> 如果Socket中有部分数据就绪，且数据数量小于一次读操作所期望读出的数据长度，那么读操作将会成功读出这部分数据并返回，而不是等待期望长度数据全部读取后再返回。

>> 3. Socket中有足够多的数据
如果连接上有数据，且数据长度大于或等于一次Read操作所期望读出的数据长度，那么Read将会成功读出这部分数据并返回。这个情景是最符合我们对Read的期待的：Read在用连接上的数据将我们传入的切片缓冲区填满后返回n = 10, err = nil。

>> 客户端发送的内容长度为15字节，服务端传给Read的切片长度为10，因此服务端执行一次Read只会读取10字节；网络上还剩5字节数据，服务端在再次读取时就会把剩余数据全部读出。

>> 在客户端关闭Socket并退出后，server3依旧没有开始执行Read操作。10秒后的第一次Read操作成功读出了5字节的数据；当执行第二次Read操作时，由于此时客户端已经关闭Socket并退出了，Read返回了错误EOF（代表连接断开）。
通过上面这个例子，我们可以大致猜测出无数据关闭情形下的结果，那就是服务端调用Read后直接返回EOF。

>> 5. 读操作超时
有些场合对读操作的阻塞时间有严格限制，在这种情况下，读操作的行为到底是什么样的呢？在返回超时错误时，是否也同时读出了一部分数据呢？

>> 第一次读取超时，读出数据长度为0；第二次成功读取所有数据，没有超时。反复执行了多次，没出现读出部分数据且返回超时错误的情况。

>> 6. 成功写

>> 7. 写阻塞

>> TCP通信连接两端的操作系统内核都会为该连接保留数据缓冲区，一端调用Write后，实际上数据是写入操作系统协议栈的数据缓冲区中的。TCP是全双工通信，因此每个方向都有独立的数据缓冲区。当发送方将对方的接收缓冲区及自身的发送缓冲区都写满后，Write调用就会阻塞。

>> 8. 写入部分数据

>> broken pipe错误

>> 9. 写入超时
如果非要给Write增加一个期限，我们可以调用SetWriteDeadline方法。

>> 在写入超时时，依旧存在数据部分写入的情况。
综合以上例子可知，虽然Go提供了阻塞I/O的便利，但在调用Read和Write时依旧要结合这两个方法返回的n和err的结果来做出正确处理。

>> 10. goroutine安全的并发读写

>> goroutine的网络编程模型决定了存在不同goroutine间共享conn的情况

>> netFD在不同平台上有着不同的实现，这里以net/fd_unix.go中的netFD为例：
// $GOROOT/src/net/fd_unix.go// 网络文件描述符type netFD struct {    // sysfd的锁，保证读写顺序进行    fdmu fdMutex    ...}
我们看到netFD类型中包含一个运行时实现的fdMutex类型字段，从其注释来看，该fdMutex用来串行化对该netFD对应sysfd的Write和Read操作。也就是说，所有对conn的Read和Write操作都是由fdMutex来同步的。

>> netFD的Read和Write方法的实现也证实了这一点：
// $GOROOT/src/net/fd_unix.go

>> 每次Write操作都是受锁保护的，直到此次数据全部写完。因此在应用层面，要想保证多个goroutine在一个conn上的Write操作是安全的，需要让每一次Write操作完整地写入一个业务包。一旦将业务包的写入拆分为多次Write操作，就无法保证某个goroutine的某业务包数据在conn上发送的连续性。
同时可以看出，即便是Read操作，也是有锁保护的。多个goroutine对同一conn的并发读不会出现读出内容重叠的情况，但内容断点是依运行时调度来随机确定的。存在一个业务包数据三分之一的内容被goroutine-1读走，而另三分之二被goroutine-2读走的情况。比如一个完整数据包“world”。当goroutine的读缓冲区长度小于5时，存在这样一种可能：一个goroutine读出“worl”，而另一个goroutine读出“d”。

>> 50.4　Socket属性

>> 原生Socket API提供了丰富的sockopt设置接口，而Go有自己的网络编程模型。Go提供的socket options接口也是基于上述模型的必要的属性设置，包括SetKeepAlive、SetKeep-AlivePeriod、SetLinger、SetNoDelay （默认为no delay）、SetWriteBuffer、SetReadBuffer。
不过上面的方法是TCPConn类型的，而不是Conn类型的。要使用上面的方法，需要进行类型断言（type assertion）操作：
tcpConn, ok := c.(*TCPConn)if !ok {    // 错误处理}tcpConn.SetNoDelay(true)
对于listener的监听Socket，Go默认设置了SO_REUSEADDR，这样当你重启服务程序时，不会因为address in use的错误而重启失败。

>> 50.5　关闭连接

>> 在己方已经关闭的Socket上再进行Read和Write操作，会得到“use of closed network connection”的错误。而从server1的执行结果来看，在对方关闭的Socket上执行Read操作会得到EOF错误，但Write操作依然会成功，因为数据会成功写入己方的内核Socket缓冲区中，即便最终发不到对方的Socket缓冲区（因为己方Socket尚未关闭）。因此当发现对方Socket关闭时，己方应该正确处理自己的Socket，再继续进行Write操作已经无任何意义了。

>> 小结
在这一条中，我们学习了常见的网络I/O模型，了解了Go基于非阻塞Socket+I/O多路复用模型的网络编程模型的优点，包括降低通信复杂性，大幅减轻开发者的心智负担等，最后通过实例说明了在Go网络编程模型下，建立TCP连接、Socket读写（包括并发读写）、Socket属性设置及关闭连接的行为特点和注意事项。

>> 第51条使用net/http包实现安全通信

>> 51.1　HTTPS：在安全传输层上运行的HTTP协议

>> Go标准库net/http包同样提供了对采用HTTPS协议的Web服务的支持。只需修改一行代码就能将上面示例中的那个基于HTTP协议的Web服务改为一个采用HTTPS协议的Web服务：
// chapter9/sources/go-https/https_hello_world_server.gofunc main() {    http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {        fmt.Fprintf(w, "Hello, World!\n")    })    fmt.Println(http.ListenAndServeTLS("localhost:8081", "server.crt", "server. key", nil))}

>> 51.2　HTTPS安全传输层的工作机制

>> 为了探究安全传输层连接的建立过程，我们通过curl命令再次访问上面的HTTPS Web示例服务，不过这次加上了-v参数，让curl输出更为详细的日志

>> $curl -v -k https://127.0.0.1:8081* Rebuilt URL to: https://127.0.0.1:8081/*   Trying 127.0.0.1...* TCP_NODELAY set* Connected to 127.0.0.1 (127.0.0.1) port 8081 (#0)* ALPN, offering h2* ALPN, offering http/1.1* Cipher selection: ALL:!EXPORT:!EXPORT40:!EXPORT56:!aNULL:!LOW:!RC4:@STRENGTH* successfully set certificate verify locations:*   CAfile: /etc/ssl/cert.pem  CApath: none* TLSv1.2 (OUT), TLS handshake, Client hello (1):* TLSv1.2 (IN), TLS handshake, Server hello (2):* TLSv1.2 (IN), TLS handshake, Certificate (11):* TLSv1.2 (IN), TLS handshake, Server key exchange (12):* TLSv1.2 (IN), TLS handshake, Server finished (14):* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):* TLSv1.2 (OUT), TLS change cipher, Client hello (1):* TLSv1.2 (OUT), TLS handshake, Finished (20):* TLSv1.2 (IN), TLS change cipher, Client hello (1):* TLSv1.2 (IN), TLS handshake, Finished (20):* SSL connection using TLSv1.2 / ECDHE-RSA-AES128-GCM-SHA256...

>> 我们将上述curl命令（作为客户端）与https_hello_world_server（作为服务端）的通信过程归纳为图51-5。
安全传输层建立连接的过程也称为“握手阶段”（handshake）。从图51-5中可以看出，这个握手阶段涉及四轮通信，下面逐一简单说明。
（1）ClientHello（客户端 → 服务端）
客户端向服务端发出建立安全层传输连接，构建加密通信通道的请求。在这个请求中，客户端会向服务端提供本地最新TLS版本、支持的加密算法组合的集合（比如上面curl示例所建立的安全层传输会话最终选择的ECDHE-RSA-AES128-GCM-SHA256组合）以及随机数等。
（2）ServerHello & Server certificate &ServerKeyExchange（服务端 → 客户端）
这一轮通信分为三个重要步骤。
第一步，服务端收到客户端发过来的ClientHello请求后，用客户端发来的信息与自己本地支持的TLS版本、加密算法组合的集合做比较，选出一个TLS版本和一个合适的加密算法组合，然后生成一个随机数，一起打包到ServerHello中返回给客户端。
第二步，服务器会将自己的服务端公钥证书发送给客户端（Server certificate），这个服务端公钥证书身兼两大职责：客户端对服务端身份的验证以及后续双方会话密钥的协商和生成。

>> 
图51-5　HTTPS安全传输层建立连接的过程
如果服务端要验证客户端身份（可选的），那么这里服务端还会发送一个CertificateRequest的请求给客户端，要求对客户端的公钥证书进行验证。
第三步，发送开启双方会话密钥协商的请求（ServerKeyExchange）。相比非对称加密算法，对称加密算法的性能要高出几个数量级，因此HTTPS在开始真正传输应用层的用户数据之前，选择了在非对称加密算法的帮助下协商一个基于对称加密算法的密钥。在密钥协商环节，通常会使用到Diffie-Hellman（DH）密钥交换算法，这是一种密钥协商的协议，支持通信双方在不安全的通道上生成对称加密算法所需的共享密钥。因此，在这个步骤的请求中，服务端会向客户端发送密钥交换算法的相关参数信息。
最后，服务端以Server Finished（又称为ServerDone）作为该轮通信的结束标志。
（3）ClientKeyExchange & ClientChangeCipher & Finished （客户端 → 服务端）
客户端在收到服务端的公钥证书后会对服务端的身份进行验证（当然也可以选择不验证），如果验证失败，则此次安全传输层连接建立就会以失败告终。如果验证通过，那么客户端将从证书中提取出服务端的公钥，用于加密后续协商密钥时发送给服务端的信息。
如果服务端要求对客户端进行身份验证（接到服务端发送的CertificateRequest请求），那么客户端还需通过ClientCertificate将自己的公钥证书发送给服务端进行验证。
收到服务端对称加密共享密钥协商的请求后，客户端根据之前的随机数、确定的加密算法组合以及服务端发来的参数计算出最终的会话密钥，然后将服务端单独计算出会话密钥所需的信息用服务端的公钥加密后以ClientKeyExchange请求发送给服务端。

>> 随后客户端用ClientChangeCipher通知服务端从现在开始发送的消息都是加密过的。
最后，伴随着ClientChangeCipher消息，总会有一个Finished消息来验证双方的对称加密共享密钥协商是否成功。其验证的方法就是通过协商好的新共享密钥和对称加密算法对一段特定内容进行加密，并以服务端是否能够正确解密该请求报文作为密钥协商成功与否的判定标准。而被加密的这段特定内容包含的是连接至今的全部报文内容。Finished报文作为该轮通信的结束标志，也是客户端发出的第一条使用协商密钥加密的信息。
（4）ServerChangeCipher & Finished（服务端 → 客户端）
服务端收到客户端发过来的ClientKeyExchange中的参数后，也将单独计算出会话密钥。之后和客户端一样，服务端用ServerChangeCipher通知客户端从现在开始发送的消息都是加密过的。
最后，服务端用一个Finished消息跟在ServerChangeCipher后面，既用于标识该轮握手结束，也用于验证对方计算出来的共享密钥是否有效。这也是服务端发出的第一条使用协商密钥加密的信息。
一旦HTTPS安全传输层的连接成功建立起来，后续双方通信的内容（应用层的HTTP协议）就会在一个经过加密处理的安全通道中得以传输。

>> 51.3　非对称加密和公钥证书

>> 非对称加密的性能相较于对称加密要差很多，这也是在实际应用（比如HTTPS的传输安全层）中会将两种加密方式结合使用的原因。

>> 
图51-7　公钥证书申请与校验的过程

>> 我们通过示例来演示一下CA签发证书的过程。首先创建一个模拟CA。CA的核心就是一个私钥以及由该私钥自签名的CA公钥证书（内置到操作系统和浏览器中分发）

>> 51.4　对服务端公钥证书的校验

>> 如果客户端信任这个服务端，可以忽略对服务端证书的校验：
// chapter9/sources/go-https/verify-server-cert/client_skip_verify.go...func main() {    tr := &http.Transport{        TLSClientConfig: &tls.Config{InsecureSkipVerify: true},    }    client := &http.Client{Transport: tr}    resp, err := client.Get("https://localhost:8081")    if err != nil {        fmt.Println("error:", err)        return    }    defer resp.Body.Close()    body, err := ioutil.ReadAll(resp.Body)    fmt.Println(string(body))}

>> 不过大多数时候，我们是要对服务端证书进行检验的，这时我们就需要让客户端知晓并加载CA的公钥证书。下面的代码演示了如何在客户端加载CA公钥证书：
// chapter9/sources/go-https/verify-server-cert/client_verify_by_cacert.gofunc main() {    pool := x509.NewCertPool()    caCertPath := "../ca.crt"    caCrt, err := ioutil.ReadFile(caCertPath)    if err != nil {        fmt.Println("ReadFile err:", err)        return    }    pool.AppendCertsFromPEM(caCrt)    tr := &http.Transport{        TLSClientConfig: &tls.Config{RootCAs: pool},    }    client := &http.Client{Transport: tr}    resp, err := client.Get("https://localhost:8081")    if err != nil {        fmt.Println("Get error:", err)        return    }    defer resp.Body.Close()    body, err := ioutil.ReadAll(resp.Body)    fmt.Println(string(body))}

>> 也可以将自签名的CA公钥证书导入系统CA证书存储目录下。如图51-8所示，在macOS下，我们可以使用“钥匙串访问”导入ca.crt（其他主流操作系统都有自己的导入数字证书的方法）。导入后，在“信任”→“使用此证书时”的下拉选项中选择“始终信任”。

>> 51.5　对客户端公钥证书的校验

>> 服务端需要增加校验客户端公钥证书的设置，并加载用于校验公钥证书的ca.crt：
// chapter9/sources/go-https/verify-dual-cert/hello_world_server.go...func main() {    pool := x509.NewCertPool()    caCertPath := "../ca.crt"    caCrt, err := ioutil.ReadFile(caCertPath)    if err != nil {        fmt.Println("ReadFile err:", err)        return    }    pool.AppendCertsFromPEM(caCrt)    s := &http.Server{        Addr: "localhost:8081",        Handler: http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {            fmt.Fprintf(w, "Hello, World!\n")        }),        TLSConfig: &tls.Config{            ClientCAs:  pool,            ClientAuth: tls.RequireAndVerifyClientCert,        },    }    fmt.Println(s.ListenAndServeTLS("../server-signed-by-ca.crt",        "../server.key"))}
上面新版服务端的代码通过将tls.Config.ClientAuth赋值为tls.RequireAndVerifyClientCert来实现服务端强制校验客户端证书。ClientCAs是用来存储校验客户端证书的CA公钥证书的池。

>> 实现一版提供客户端公钥证书的客户端：
// chapter9/sources/go-https/verify-dual-cert/client_provide_cert.go...func main() {    pool := x509.NewCertPool()    caCertPath := "../ca.crt"    caCrt, err := ioutil.ReadFile(caCertPath)    if err != nil {        fmt.Println("ReadFile err:", err)        return    }    pool.AppendCertsFromPEM(caCrt)    cliCrt, err := tls.LoadX509KeyPair("../client.crt", "../client.key")    if err != nil {        fmt.Println("Loadx509keypair err:", err)        return    }    tr := &http.Transport{        TLSClientConfig: &tls.Config{            RootCAs:      pool,            Certificates: []tls.Certificate{cliCrt},        },    }    client := &http.Client{Transport: tr}    resp, err := client.Get("https://localhost:8081")    if err != nil {        fmt.Println("Get error:", err)        return    }    defer resp.Body.Close()    body, err := ioutil.ReadAll(resp.Body)    fmt.Println(string(body))}

>> 服务端成功地校验了客户端提供的公钥证书，也就是说在这个示例中我们实现了双向公钥证书校验。

>> 小结
在本条中，我们了解了如何利用Go标准库提供的net/http、crypto/tls及crypto/x509等包建立一条安全的HTTPS协议通信通道。
本条要点：
◦  了解HTTP协议的优点与不足；
◦  了解HTTPS协议安全传输层的建立过程；
◦  理解非对称加密体系以及数字证书的组成与功用；
◦  数字证书就是使用CA私钥对证书申请者的公钥和证书相关信息进行签名后的满足标准证书格式的信息；
◦  了解如何使用Go实现对服务端和客户端证书的双向校验。

>> 第52条掌握字符集的原理和字符编码方案间的转换

>> Go语言源码默认使用Unicode字符集，并采用UTF-8编码方案，Go还提供了rune原生类型来表示Unicode字符。

>> 我们可以通过标准库提供的unicode/utf8包对rune进行编解码操作，看下面的示例：
// chapter9/sources/go-character-set-encoding/rune_encode_and_decode.go// rune -> []bytefunc encodeRune() {    var r rune = 0x4E2D // 0x4E2D为Unicode字符"中"的码点    buf := make([]byte, 3)    n := utf8.EncodeRune(buf, r)    fmt.Printf("the byte slice after encoding rune 0x4E2D is ")    fmt.Printf("[ ")    for i := 0; i < n; i++ {        fmt.Printf("0x%X ", buf[i])    }    fmt.Printf("]\n")    fmt.Printf("the unicode charactor is %s\n", string(buf))}// []byte -> runefunc decodeRune() {    var buf = []byte{0xE4, 0xB8, 0xAD}    r, _ := utf8.DecodeRune(buf)    fmt.Printf("the rune after decoding [0xE4, 0xB8, 0xAD] is 0x%X\n", r)}func main() {    encodeRune()    decodeRune()}
运行该示例：
$go run rune_encode_and_decode.gothe byte slice after encoding rune 0x4E2D is [ 0xE4 0xB8 0xAD ]the unicode character is 中the rune after decoding [0xE4, 0xB8, 0xAD] is 0x4E2D

>> // chapter9/sources/go-character-set-encoding/dump_utf8_encoding_of_string.gofunc main() {    var s = "中"    fmt.Printf("Unicode字符：%s => 其UTF-8内存编码表示为: ", s)    for _, v := range []byte(s) {        fmt.Printf("0x%X ", v)    }    fmt.Printf("\n")}
运行该实例，我们看到Unicode字符“中”底层的内存空间内容与其UTF-8编码后的切片中的内容是一样的：
$go run dump_utf8_encoding_of_string.goUnicode字符：中 => 其UTF-8内存编码表示为: 0xE4 0xB8 0xAD

>> Go标准库没有直接提供简体中文编码与UTF-8编码之间的转换实现，但Go标准库依赖的golang.org/x/text模块中提供了相关转换实现。golang.org/x/text同样是Go核心团队维护的工具包，我认为我们可以将该模块下的包当作标准库，只是Go1兼容性并不保证这些包对外提供的API的稳定性。下面是转换的实现代码：
// chapter9/sources/go-character-set-encoding/convert_utf8_to_gb18030.gopackage mainimport (    "bytes"    "errors"    "fmt"    "io/ioutil"    "os"    "unicode/utf8"    "golang.org/x/text/encoding/simplifiedchinese"    "golang.org/x/text/transform")func dumpToFile(in []byte, filename string) error {    f, err := os.OpenFile(filename, os.O_CREATE|os.O_TRUNC|os.O_RDWR, 0666)    if err != nil {        return err    }    defer f.Close()    _, err = f.Write(in)    if err != nil {        return err    }    return nil}func utf8ToGB18030(in []byte) ([]byte, error) {    if !utf8.Valid(in) {        return nil, errors.New("invalid utf-8 runes")    }    r := bytes.NewReader(in)    t := transform.NewReader(r, simplifiedchinese.GB18030.NewEncoder())    out, err := ioutil.ReadAll(t)    if err != nil {        return nil, err    }    return out, nil}func main() {    var src = "中国人" // <=> "\u4E2D\u56FD\u4EBA"    var dst []byte    for i, v := range src {        fmt.Printf("Unicode字符: %s <=> 码点(rune): %X <=> UTF8编码内存表示: ", string(v), v)        s := src[i : i+3]        for _, v := range []byte(s) {            fmt.Printf("0x%X ", v)        }        t, _ := utf8ToGB18030([]byte(s))        fmt.Printf("<=> GB18030编码内存表示: ")        for _, v := range t {            fmt.Printf("0x%X ", v)        }        fmt.Printf("\n")        dst = append(dst, t...)    }    dumpToFile(dst, "gb18030.txt")}

>> 在这个实现中，真正执行UTF-8到GB18030编码形式转换的是simplifiedchinese.GB18030.NewEncoder方法，它读取以UTF-8编码表示形式存在的字节流（[]byte），并将其转换为以GB18030编码表示形式的字节流返回。
运行上述代码：
$go run convert_utf8_to_gb18030.goUnicode字符: 中 <=> 码点(rune): 4E2D <=> UTF8编码内存表示: 0xE4 0xB8 0xAD <=> GB18030编码内存表示: 0xD6 0xD0Unicode字符: 国 <=> 码点(rune): 56FD <=> UTF8编码内存表示: 0xE5 0x9B 0xBD <=> GB18030编码内存表示: 0xB9 0xFAUnicode字符: 人 <=> 码点(rune): 4EBA <=> UTF8编码内存表示: 0xE4 0xBA 0xBA <=> GB18030编码内存表示: 0xC8 0xCB
该示例代码除了输出上面的信息之外，还将转换后的GB18030编码数据写入gb18030.txt文件。我们在UTF-8编码环境下输出该文件的内容：
$cat gb18030.txt?й???%
输出的内容为乱码。在macOS系统中，我们将环境变量中涉及字符集编码的变量都设置为GB18030，然后在新标签窗口中再次输出gb18030.txt文件的内容：
$localeLANG="zh_CN.GB18030"LC_COLLATE="zh_CN.GB18030"LC_CTYPE="zh_CN.GB18030"LC_MESSAGES="zh_CN.GB18030"LC_MONETARY="zh_CN.GB18030"LC_NUMERIC="zh_CN.GB18030"LC_TIME="zh_CN.GB18030"LC_ALL=$cat gb18030.txt中国人
这回终端上文件内容中的乱码消失了，取而代之的是正确的内容：“中国人”。

>> 使用Go标准库及其依赖库golang.org/x/text下的包，我们不仅可以实现Go默认字符编码UTF-8与其他字符集编码的相互转换，还可以实现任意字符集编码之间的相互转换。下面再来看一个将GB18030编码数据转换为UTF-16和UTF-32的示例（将上面示例生成的gb18030.txt作为输入数据源）：
// chapter9/sources/go-character-set-encoding/convert_gb18030_to_utf16_and_utf32.gofunc catFile(filename string) ([]byte, error) {    f, err := os.Open(filename)    if err != nil {        return nil, err    }    defer f.Close()    return ioutil.ReadAll(f)}func gb18030ToUtf16BE(in []byte) ([]byte, error) {    r := bytes.NewReader(in) //gb18030    s := transform.NewReader(r, simplifiedchinese.GB18030.NewDecoder())    d := transform.NewReader(s,          unicode.UTF16(unicode.BigEndian, unicode.IgnoreBOM).NewEncoder())    out, err := ioutil.ReadAll(d)    if err != nil {        return nil, err    }    return out, nil}func gb18030ToUtf32BE(in []byte) ([]byte, error) {    r := bytes.NewReader(in) //gb18030    s := transform.NewReader(r, simplifiedchinese.GB18030.NewDecoder())    d := transform.NewReader(s,          utf32.UTF32(utf32.BigEndian, utf32.IgnoreBOM).NewEncoder())    out, err := ioutil.ReadAll(d)    if err != nil {        return nil, err    }    return out, nil}func main() {    src, err := catFile("gb18030.txt")    if err != nil {        fmt.Println("open file error:", err)        return    }    // 从gb18030到utf-16be    dst, err := gb18030ToUtf16BE(src)    if err != nil {        fmt.Println("convert error:", err)        return    }    fmt.Printf("UTF-16BE(no BOM)编码: ")    for _, v := range dst {        fmt.Printf("0x%X ", v)    }    fmt.Printf("\n")    // 从gb18030到utf-32be    dst1, err := gb18030ToUtf32BE(src)    if err != nil {        fmt.Println("convert error:", err)        return

>>     }    fmt.Printf("UTF-32BE(no BOM)编码: ")    for _, v := range dst1 {        fmt.Printf("0x%X ", v)    }    fmt.Printf("\n")}
图52-6描绘了上面示例的逻辑轮廓。

图52-6　利用transform.Reader链实现任意字符编码间的转换
从图52-6中我们看到，我们使用了一个惯用的Reader链结构完成了数据从gb18030编码到UTF-16和UTF-32编码的转换。以gb18030到UTF-16的转换为例：第一个transform.Reader在GB18030.Decoder的帮助下，将gb18030编码的源数据（[]byte）转换为了rune，即unicode码点，并以Go默认的UTF-8编码格式保存在内存中；而第二个transform.Reader则在UTF16.Encoder的帮助下，将rune再编码转换为最终数据。
下面是该示例的运行结果：
$go run convert_gb18030_to_utf16_and_utf32.goUTF-16BE(no BOM)编码: 0x4E 0x2D 0x56 0xFD 0x4E 0xBAUTF-32BE(no BOM)编码: 0x0 0x0 0x4E 0x2D 0x0 0x0 0x56 0xFD 0x0 0x0 0x4E 0xBA
小结
在本条中，我们学习了Go默认字符集Unicode以及采用的编码方案UTF-8，深入理解了字符、字符集的属性——码点和内存编码表示（位模式）以及它们之间的关系，并通过实例讲解了如何利用Go标准库及扩展包实现不同字符编码方案间的转换。

>> 第53条掌握使用time包的正确方式

>> 常见的时间操作有获取当前时间、时间比较、时区相关的时间操作、时间格式化、定时器（一次性定时器timer和重复定时器ticker）的使用等。

>> 53.1　时间的基础操作
1. 获取当前时间

>> t := time.Now()

>> type Time struct {    wall uint64    ext  int64    loc *Location}
由三个字段组成的Time结构体要同时表示两种时间——挂钟时间（wall time）和单调时间（monotonic time），并且精度级别为纳秒。

>> 连续两次通过Now函数获取的挂钟时间之间的差值不一定都是正值。在Go 1.9版本中加入对单调时间的支持之前，Cloudflare公司的DNS系统就曾因两次采集的挂钟时间之差为负值（遇到闰秒）而出现过严重故障。

>> 单调时间则是永远不会出现“时间倒流”现象的。单调时间表示的是程序进程启动之后流逝的时间，两次采集的单调时间之差永远不可能为负数。Go 1.9版本中加入了对单调时间的支持，单调时间常被用于两个即时时间之间的比较和间隔计算。

>> 真正获取系统时间的操作是在下面的汇编代码中通过系统调用（system call）实现的（以Linux为例）：
// $GOROOT/src/runtime/sys_linux_amd64.sTEXT runtime·walltime1(SB),NOSPLIT,$8-12...noswitch:    SUBQ    $16, SP         // 为结果预留空间    ANDQ    $~15, SP        // 为C代码进行对齐    MOVQ    runtime·vdsoClockgettimeSym(SB), AX    CMPQ    AX, $0    JEQ     fallback    MOVL    $0, DI // CLOCK_REALTIME    LEAQ    0(SP), SI    CALL    AX...TEXT runtime·nanotime1(SB),NOSPLIT,$8-8...noswitch:    SUBQ    $16, SP         // 为结果预留空间    ANDQ    $~15, SP        // 为C代码进行对齐    MOVQ    runtime·vdsoClockgettimeSym(SB), AX    CMPQ    AX, $0    JEQ     fallback...

>> 2. 获取特定时区的当前时间

>> （1）设置TZ环境变量
time.Now函数在获取当前时间时会考虑时区信息，如果TZ环境变量不为空，那么它将尝试读取该环境变量指定的时区信息并输出对应时区的即时时间表示。下面的示例输出美国东部纽约所在时区的当前时间（并对比北京时间）：
$TZ=America/New_York go run 

>> 如果TZ环境变量提供的时区信息有误或显式设置为""，time.Now根据其值在时区数据库中找不到对应的时区信息，那么它将使用UTC时间（Coordinated Universal Time，国际协调时间）

>> （2）显式加载时区信息

>> 利用time包提供的LoadLocation函数显式加载特定时区信息，并将本地当前时间转换为特定时区的即时时间

>> t := time.Now()    fmt.Println(t) //北京时间    loc, err := time.LoadLocation("America/New_York")    if err != nil {        fmt.Println("load time location failed:", err)        return    }    t1 := t.In(loc) // 转换成美国东部纽约时间表示    fmt.Println(t1)}

>> 3. 时间的比较与运算

>> 直接用==和!=来做比较是不适宜的，这也是time.Time类型不应被用作map类型的key值的原因。time.Time提供了Equal方法，该方法专用于对两个Time实例的比较

>> Equal方法的比较逻辑是这样的：当两个Time实例均带有单调时间数据时（hasMonotonic都为1），那么直接比较两者的单调时间是否相等；否则，分别比较两个时间的整秒部分（sec）和非整秒部分（nsec）。如果两个部分分别相等，那么两个时间相同，否则不同。

>> 除了对两个Time实例的比较关系操作提供支持之外，time包还可以用来对两个即时时间进行时间运算，其中最主要的运算就是由Sub方法提供的差值运算（Since和Until方法均是基于Sub方法实现的）

>> 53.2　时间的格式化输出

>> Go另辟蹊径，采用了不同于strftime的时间格式化输出方案。Go的设计者主要出于这样的考虑：虽然strftime的单个占位符使用了对应单词首字母的形式，但是真正写起代码来，不打开strftime函数的手册或查看网页版的strftime助记符说明（http://strftime.org），很难拼出一个复杂的时间格式。并且对于一个"%Y-%m-%d %H:%M:%S"的格式串，如果不对照文档，很难在大脑中准确给出格式化后的时间结果。比如%Y和%y有何不同？%M和%m又有何差别呢？
Go语言采用了更为直观的参考时间（reference time）替代strftime的各种标准占位符，使用参考时间构造出来的时间格式串与最终输出串是一模一样的，这就省去了程序员再次在大脑中对格式串进行解析的过程。我们通过下例看看Go方案的输出结果：
// chapter9/sources/go-time-operations/timeformat_in_go_way.gofunc main() {    fmt.Println(time.Now().Format("2006年01月02日 15时04分05秒"))}
运行该示例：
$go run timeformat_in_go_way.go2020年06月18日 12时27分32秒
例子中我们使用的格式字符串：
"2006年01月02日 15时04分05秒"
输出结果：
2020年06月18日 12时27分32秒

>> 是不是有点所见即所得的意味？
Go文档中给出的标准的参考时间如下：
2006-01-02 15:04:05 PM -07:00 Jan Mon MST
这个绝对时间本身并没有什么实际意义，仅是出于好记的考虑，我们将这个参考时间换为另一种时间输出格式：
01/02 03:04:05PM '06 -0700
可见Go设计者的良苦用心！这个时间格式串恰好是将助记符从小到大排序（从01到07）的结果，可以理解为：01对应的是%M，02对应的是%d，依次类推。图53-3形象地展示了参考时间、格式串与最终格式化的输出结果之间的关系。

>> 
图53-3　参考时间、格式串与最终格式化的输出结果之间的关系
就笔者使用Go的经历来看，在做时间格式化输出时，尤其是构建略微复杂的时间格式化输出时，还是要通过go doc time命令行或打开time包的参考手册页面的。从社区的反馈来看，很多Gopher也有类似的经历，尤其是那些已经用惯了strftime方案的Gopher。
下面是一个格式化字符串与实际输出结果的速查表，由go-time-operations/timeformat_cheatsheet.go生成，可以作为日常在Go中进行时间格式化输出的参考。速查表的第一列为含义，第二列为格式串写法，第三列为对应格式串写法下的输出结果（取当前时间）：
2020-06-19 14:44:58 PM +08:00 Jun Fri CSTYear            | 2006         | 2020Year            | 06           | 20Month           | 01           | 06Month           | 1            | 6Month           | Jan          | JunMonth           | January      | JuneDay             | 02           | 19Day             | 2            | 19Week day        | Mon          | FriWeek day        | Monday       | FridayHours           | 03           | 02Hours           | 3            | 2Hours           | 15           | 14Minutes         | 04           | 44Minutes         | 4            | 44Seconds         | 05           | 58Seconds         | 5            | 58AM or PM        | PM           | PMMiliseconds     | .000         | .906Microseconds    | .000000      | .906783Nanoseconds     | .000000000   | .906783000Timezone offset | -0700        | +0800Timezone offset | -07:00       | +08:00Timezone offset | Z0700        | +0800Timezone offset | Z07:00       | +08:00Timezone        | MST          | CST--------------- + ------------ + ------------

>> 53.3　定时器的使用

>> time包提供了两类定时器：一次性定时器Timer和重复定时器Ticker。

>> 1. Timer的创建
time包提供了多种创建Timer定时器的方式

>> 该结构体包含两个字段C和r，其中C是用户层用户接收定时器触发事件的channel，而r则是一个与runtime.timer（runtime/time.go）对应且要保持一致的结构。另外我们注意到，NewTimer创建的用于接收定时器触发事件的channel是一个带缓冲的channel。
被实例化后的Timer将交给运行时层的startTimer函数，后者使用其初始化运行时层面的runtime.timer结构，并将runtime.timer加入为每个P分配的定时器最小堆中进行管理。

>> 为每个P（goroutine调度器中的那个P）创建一个定时器最小堆，并通过网络轮询器（net poller）在运行时调度的协助下对各个定时器最小堆进行统一管理和调度

>> 2. Timer的资源释放

>> 很多Go初学者在使用Timer时担心Timer的创建会占用系统资源。从上面的Timer创建和触发原理来看，Go中的定时器是在Go运行时层面实现的，并不会占用系统资源。尤其是新版本定时器的管理和调度已经与运行时网络轮询器融合在一起，一个定时器占用的资源仅限于对应数据结构占用的内存以及一个带缓冲channel（通过AfterFunc创建的定时器还会启动一个额外的goroutine来执行用户传入的函数）。在定时器被从最小堆移除并触发事件后，其占用的内存资源、channel等都会在后续被垃圾收集器回收。

>> 及时调用定时器的Stop方法从最小堆删除定时器或重用（Reset）处于活跃状态的定时器。

>> 3. 停止Timer

>> Timer提供了Stop方法来将尚未触发的定时器从P中的最小堆中移除，使之失效，这样可以减小最小堆管理和垃圾回收的压力。因此，使用定时器时及时调用Stop方法是一个很好的Go语言实践。

>> // chapter9/sources/go-time-operations/timer_stop.go...func consume(c <-chan bool) bool {    timer := time.NewTimer(time.Second * 5)    defer timer.Stop()    select {    case b := <-c:        if b == false {            log.Printf("recv false, continue")            return true        }        log.Printf("recv true, return")        return false    case <-timer.C:        log.Printf("timer expired")        return true    }}func main() {    c := make(chan bool)    var wg sync.WaitGroup    wg.Add(2)    // 生产者    go func() {        for i := 0; i < 5; i++ {            time.Sleep(time.Second * 1)            c <- false        }        time.Sleep(time.Second * 1)        c <- true        wg.Done()    }()    // 消费者    go func() {        for {            if b := consume(c); !b {                wg.Done()                return            }        }    }()    wg.Wait()}

>> 4. 重用Timer

>> 如果不想重复创建这么多Timer实例，而是重用现有的Timer实例，那么就要用到Timer的Reset方法。Go官方文档建议只对如下两种定时器调用Reset方法：
◦  已经停止了的定时器（Stopped）；
◦  已经触发过且Timer.C中的数据已经被读空。

>> Go官方文档还给出了推荐的使用模式：
if !t.Stop() {    <-t.C}t.Reset(d)
接下来，我们就将上面的例子改造为只使用一个定时器。
// chapter9/sources/go-time-operations/timer_reset_1.gofunc consume(c <-chan bool, timer *time.Timer) bool {    if !timer.Stop() {        <-timer.C    }    timer.Reset(5 * time.Second)    select {    case b := <-c:        if b == false {            log.Printf("recv false, continue")            return true        }        log.Printf("recv true, return")        return false    case <-timer.C:           log.Printf("timer expired")           return true    }}func main() {     c := make(chan bool)     var wg sync.WaitGroup     wg.Add(2)     go func() {         for i := 0; i < 5; i++ {             time.Sleep(time.Second * 1)             c <- false         }         time.Sleep(time.Second * 1)         c <- true         wg.Done()     }()     go func() {         timer := time.NewTimer(time.Second * 5)         for {             if b := consume(c, timer); !b {                 wg.Done()                 return             }         }     }()     wg.Wait()}

>> 使用Reset改造后的代码中生产者的行为并未改变，在实际执行时每次循环中，定时器在被重置之前都没有触发（fire），因此timer.Stop的调用均返回true，即成功将timer停止。该示例的执行结果如下：
$go run timer_reset_1.go2020/06/21 05:10:20 recv false, continue2020/06/21 05:10:21 recv false, continue2020/06/21 05:10:22 recv false, continue2020/06/21 05:10:23 recv false, continue2020/06/21 05:10:24 recv false, continue2020/06/21 05:10:25 recv true, return
这个输出结果与前面使用Stop的示例并无二致。
现在我们来改变一下生产者的发送行为：从之前每隔1秒“生产”一次数据变成每隔7秒“生产”一次数据，而消费者的行为不变。考虑到篇幅，这里仅列出变化的生产者的代码：
// chapter9/sources/go-time-operations/timer_reset_2.go...func main() {    c := make(chan bool)    var wg sync.WaitGroup    wg.Add(2)    go func() {        for i := 0; i < 5; i++ {            time.Sleep(time.Second * 7)            c <- false        }        time.Sleep(time.Second * 7)        c <- true        wg.Done()    }()    ...}

>> 我们来看看生产者行为变更后的执行结果：
$go run timer_reset_2.go2020/06/21 05:14:23 timer expiredfatal error: all goroutines are asleep - deadlock!...
这次运行的程序死锁了！为什么会出现这种情况呢？我们来分析一下。生产者的“生产”行为发生了变化，导致消费者在收到第一个数据前有了一次定时器触发（对应上面输出结果的第一行），for循环重启一轮接收。这时timer.Stop方法返回的不再是true而是false，因为这个将被重用的timer已经触发过。于是按照预定逻辑，消费者将尝试抽干（drain）timer.C中的数据，但timer.C中此时并没有数据，于是消费者goroutine就会阻塞在对该channel的读取操作上。而此时生产者处于sleep状态，主goroutine处于wait状态，Go运行时判断所有goroutine均不能前进执行，于是报了deadlock错误。

>> 问题的根源在于，已经触发且其对应的channel已经被取空的timer符合直接使用Reset的前提，但我们仍然尝试去抽干该定时器的channel，导致消费者goroutine阻塞。我们来改进一下该示例：在timer.C无数据可读的情况下，也不要阻塞在这个channel上。代码如下：
// chapter9/sources/go-time-operations/timer_reset_3.gofunc consume(c <-chan bool, timer *time.Timer) bool {    if !timer.Stop() {         select {         case <-timer.C:         default:         }    }    timer.Reset(5 * time.Second)    select {    case b := <-c:        if b == false {            log.Printf("recv false, continue")            return true        }        log.Printf("recv true, return")        return false    case <-timer.C:        log.Printf("timer expired")        return true    }}
在上面的改进版示例中，我们使用了一个小技巧：通过带有default分支的select来处理timer.C。这样当timer.C中无数据时，代码可以通过default分支继续向下处理，而不会再阻塞在对timer.C的读取上了。

>> 5. 重用Timer时存在的竞态条件

>> 当一个定时器触发时，运行时会调用runtime.runOneTimer调用定时器关联的触发函数：
// $GOROOT/src/runtime/time.go (Go 1.14)func runOneTimer(pp *p, t *timer, now int64) {    ...    unlock(&pp.timersLock)    f(arg, seq)    lock(&pp.timersLock)    ...}
我们看到在runOneTimer执行f(arg, seq)函数前，runOneTimer对p的timersLock进行了解锁操作，也就是说f的执行并不在锁内。f执行的是什么呢？
◦  对于通过AfterFunc创建的定时器来说，就是启动一个新goroutine，并在这个新goroutine中执行用户传入的函数；
◦  对于通过After或NewTimer创建的定时器而言，f的执行就是time.sendTime函数，也就是将当前时间写入定时器的通知channel中。
这个时候会有一个竞态条件出现：定时器触发的过程中，f函数的执行与用户层重置定时器前抽干channel的操作是分别在两个goroutine中执行的，谁先谁后，完全依靠运行时调度。于是timer_reset_3.go中的看似没有问题的代码，也可能存在问题（当然需要时间粒度足够小，比如毫秒级的定时器）。以通过After或NewTimer创建的定时器为例（即f函数为time.sendTime）。

>> ◦  如果sendTime的执行发生在抽干channel动作之前，那么就是timer_reset_3.go中的执行结果：Stop方法返回false（因为定时器已经触发了），显式抽干channel的动作是可以读出数据的。后续定时器重置后，定时器将继续正常运行。
◦  如果sendTime的执行发生在抽干channel动作之后，那么就有问题了。虽然Stop方法返回false（因为定时器已经触发了），但抽干channel的动作并没有读出任何数据。之后，sendTime将数据写到channel中。这样定时器重置后的定时器channel中实际上已经有了数据，于是当消费者进入下面的select语句中时，case <-timer.C这一分支因有数据而被直接选中，没有起到超时等待的作用。也就是说定时器被重置之后居然又立即触发了。
目前这个竞态问题[1]尚无理想解决方案，不过大多数情况下按照timer_reset_3.go中Reset的使用方法是可以正常工作的。

>> 第54条不要忽略对系统信号的处理

>> Go多用于后端应用编程，而后端应用多以守护进程（daemon）的方式运行于机器上。守护程序对健壮性的要求甚高，即便是在退出时也要求做好收尾和清理工作，我们称之为优雅退出。在Go中，通过系统信号是实现优雅退出的一种常见手段。

>> 54.1　为什么不能忽略对系统信号的处理

>> 系统信号（signal）是一种软件中断，它提供了一种异步的事件处理机制，用于操作系统内核或其他应用进程通知某一应用进程发生了某种事件。

>> 应用程序收到系统信号后，一般有三种处理方式。
（1）执行系统默认处理动作
对于中断键触发的SIGINT信号，系统的默认处理动作是终止该应用进程，这是以上示例采用的信号处理方式，也是以上示例没有输出退出提示就退出了的原因。对于大多数系统信号，系统默认的处理动作是终止该进程。
（2）忽略信号
如果应用选择忽略对某些信号的处理，那么在应用进程收到这些信号后，既不会执行系统默认处理动作，也不会执行其他自定义的处理动作，信号被忽略掉了，就好像该信号从来就没有发生过似的。系统的大多数信号可使用这种方式进行处理。
（3）捕捉信号并执行自定义处理动作
如果应用进程对于某些信号，既不想执行系统默认处理动作，也不想忽略信号，那么它可以预先提供一个包含自定义处理动作的函数，并告知系统在接收到某些信号时调用这个函数。系统中有两个系统信号是不能被捕捉的：终止程序信号SIGKILL和挂起程序信号SIGSTOP。

>> 对于运行在生产环境下的程序，我们不要忽略对系统信号的处理，而应采用捕捉退出信号的方式执行自定义的收尾处理函数。

>> 54.2　Go语言对系统信号处理的支持

>> 通过kill -l命令查看各个系统对信号的支持情况

>> Go语言将这些复杂性留给了运行时层，为用户层提供了体验相当友好接口——os/signal包。
Go语言在标准库的os/signal包中提供了5个函数（截至Go 1.14版本），其中最主要的函数是Notify函数：
func Notify(c chan<- os.Signal, sig ...os.Signal)
该函数用来设置捕捉那些应用关注的系统信号，并在Go运行时层与Go用户层之间用一个channel相连。Go运行时捕捉到应用关注的信号后，会将信号写入channel，这样监听该channel的用户层代码便可收到该信号通知。

>> Go将信号分为两大类：一类是同步信号，另一类是异步信号。

>> （1）同步信号
同步信号是指那些由程序执行错误引发的信号，包括SIGBUS（总线错误/硬件异常）、SIGFPE（算术异常）和SIGSEGV（段错误/无效内存引用）。一旦应用进程中的Go运行时收到这三个信号中的一个，意味着应用极大可能出现了严重bug，无法继续执行下去，这时Go运行时不会简单地将信号通过channel发送到用户层并等待用户层的异步处理，而是直接将信号转换成一个运行时panic并抛出。如果用户层没有专门的panic恢复代码，那么Go应用将默认异常退出。

>> （2）异步信号
同步信号之外的信号都被Go划归为异步信号。异步信号不是由程序执行错误引起的，而是由其他程序或操作系统内核发出的。异步信号的默认处理行为因信号而异。SIGHUP、SIGINT和SIGTERM这三个信号将导致程序直接退出；SIGQUIT、SIGILL、SIGTRAP、SIGABRT、SIGSTKFLT、SIGEMT和SIGSYS在导致程序退出的同时，还会将程序退出时的栈状态打印出来；SIGPROF信号则是被Go运行时用于实现运行时CPU性能剖析指标采集。其他信号不常用，均采用操作系统的默认处理动作。对于用户层通过Notify函数捕获的信号，Go运行时则通过channel将信号发给用户层。

>> Notify无法捕捉SIGKILL和SIGSTOP（操作系统机制决定的），也无法捕捉同步信号（Go运行时决定的），只有捕捉异步信号才是有意义的。下面的例子直观展示了无法被捕获的信号、同步信号及异步信号的运作机制：
// chapter9/sources/go-signal/go-program-notify-sync-and-async-signal.gofunc catchAsyncSignal(c chan os.Signal) {    for {        s := <-c        fmt.Println("收到异步信号:", s)    }}func triggerSyncSignal() {    time.Sleep(3 * time.Second)    defer func() {        if e := recover(); e != nil {            fmt.Println("恢复panic:", e)            return        }    }()    var a, b = 1, 0    fmt.Println(a / b)}func main() {    var wg sync.WaitGroup    c := make(chan os.Signal, 1)    signal.Notify(c, syscall.SIGFPE,        syscall.SIGINT,        syscall.SIGKILL)    wg.Add(2)    go func() {        catchAsyncSignal(c)        wg.Done()    }()    go func() {        triggerSyncSignal()        wg.Done()    }()    wg.Wait()}
构建并运行该例子后，先不断按中断组合键（ctrl+c）查看异步信号的处理动作；3秒后，同步信号被除0计算触发；最后用kill命令向该应用进程发送一个SIGKILL的不可捕获信号。我们来看看示例程序的运行结果：
$go build -o notify-signal go-program-notify-sync-and-async-signal.go$./notify-signal^C收到异步信号: interrupt^C收到异步信号: interrupt恢复panic: runtime error: integer divide by zero[1]    94498 killed     ./notify-signal

>> 如果多次调用Notify拦截某信号，但每次调用使用的channel不同，那么当应用进程收到异步信号时，Go运行时会给每个channel发送一份异步信号副本：
// chapter9/sources/go-signal/go-program-notify-signal-twice.go...func main() {    c1 := make(chan os.Signal, 1)    c2 := make(chan os.Signal, 1)    signal.Notify(c1, syscall.SIGINT, syscall.SIGTERM)    signal.Notify(c2, syscall.SIGINT, syscall.SIGTERM)    go func() {        s := <-c1        fmt.Println("c1: 收到异步信号", s)    }()    s := <-c2    fmt.Println("c2: 收到异步信号", s)    time.Sleep(5 * time.Second)}

>> 运行该示例后，按下中断组合键ctrl+c，可以看到如下结果：
$go run go-program-notify-signal-twice.go^Cc2: 收到异步信号 interruptc1: 收到异步信号 interrupt
我们看到虽然只触发一次异步信号，但由于有两个channel“订阅”对该信号的拦截事件，于是运行时在向c1发送一份信号的同时，又向c2发送了一份信号副本。
如果上述例子中c1 == c2，即在同一个channel上两次调用Notify函数（拦截同一异步信号），那么在信号触发后这个channel会不会收到两个信号呢？运行下面的示例，我们就能得到结果：
// chapter9/sources/go-signal/go-program-notify-signal-twice-on-same-channel.go...func main() {    var wg sync.WaitGroup    c := make(chan os.Signal, 2)    signal.Notify(c, syscall.SIGINT)    signal.Notify(c, syscall.SIGINT)    wg.Add(1)    go func() {        for {            s := <-c            fmt.Println("c: 收到异步信号", s)        }        wg.Done()    }()    wg.Wait()}
运行该示例后，不断按中断组合键ctrl+c，我们发现每次触发SIGINT信号，该程序都仅输出一行日志，即channel仅收到一个信号：
$go run go-program-notify-signal-twice-on-same-channel.go^Cc: 收到异步信号 interrupt^Cc: 收到异步信号 interrupt^Cc: 收到异步信号 interrupt^Cc: 收到异步信号 interrupt^\SIGQUIT: quit...

>> 使用Notify函数后，用户层与运行时层的唯一联系就是channel。运行时收到异步信号后，会将信号写入channel。如果在用户层尚未来得及接收信号的时间段内，运行时连续多次收到触发信号，用户层是否可以收到全部信号呢？来看下面这个示例：
// chapter9/sources/go-signal/go-program-notify-lost-signal.go...func main() {    c := make(chan os.Signal, 1)    signal.Notify(c, syscall.SIGINT)    // 在这10s期间，多次触发SIGINT信号    time.Sleep(10 * time.Second)    for {        select {        case s := <-c:            fmt.Println("c: 获取异步信号", s)        default:            fmt.Println("c: 没有信号, 退出")            return        }    }}
运行该示例后，在10s内连续按5次中断组合键，10s后可以看到下面的输出结果：
$go run go-program-notify-block-signal.go^C^C^C^C^Cc: 获取异步信号 interruptc: 没有信号, 退出
我们看到用户层仅收到一个SIGINT信号，其他四个都被“丢弃”了。我们将channel的缓冲区大小由1改为5，再来试一下：
$go run go-program-notify-block-signal.go^C^C^C^C^Cc: 获取异步信号 interruptc: 获取异步信号 interruptc: 获取异步信号 interruptc: 获取异步信号 interruptc: 获取异步信号 interruptc: 没有信号, 退出
这回用户层收到了全部五个SIGINT信号。因此在使用Notify函数时，要根据业务场景的要求，适当选择channel缓冲区的大小。

>> 54.3　使用系统信号实现程序的优雅退出

>> 与优雅退出对立的是强制退出，也就是我们常说的使用kill -9，即kill -s SIGKILL pid。

>> // chapter9/sources/go-signal/go-program-exit-gracefully-with-notify.go...func main() {    var wg sync.WaitGroup    http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {        fmt.Fprintf(w, "Hello, Signal!\n")    })    var srv = http.Server{        Addr: "localhost:8080",    }    srv.RegisterOnShutdown(func() {        // 在一个单独的goroutine中执行        fmt.Println("clean resources on shutdown...")        time.Sleep(2 * time.Second)        fmt.Println("clean resources ok")        wg.Done()    })    wg.Add(2)    go func() {        quit := make(chan os.Signal, 1)        signal.Notify(quit, syscall.SIGINT,           syscall.SIGTERM,           syscall.SIGQUIT,           syscall.SIGHUP)        <-quit        timeoutCtx, cf := context.WithTimeout(context.Background(),            time.Second*5)        defer cf()        var done = make(chan struct{}, 1)        go func() {            if err := srv.Shutdown(timeoutCtx); err != nil {                fmt.Printf("web server shutdown error: %v", err)            } else {                fmt.Println("web server shutdown ok")            }            done <- struct{}{}            wg.Done()        }()        select {        case <-timeoutCtx.Done():            fmt.Println("web server shutdown timeout")        case <-done:        }    }()    err := srv.ListenAndServe()    if err != nil {        if err != http.ErrServerClosed {            fmt.Printf("web server start failed: %v\n", err)            return        }    }    wg.Wait()    fmt.Println("program exit ok")}
这是一个实现HTTP服务优雅退出的典型方案。

>> 1）通过Notify捕获SIGINT、SIGTERM、SIGQUIT和SIGHUP这四个系统信号，这样当这四个信号中的任何一个触发时，HTTP服务都有机会在退出前做一些清理工作。
2）使用http包提供的Shutdown来实现HTTP服务内部的退出清理工作，包括立即关闭所有listener、关闭所有空闲的连接、等待处于活动状态的连接处理完毕（变成空闲连接）等。
3）http.Server还提供了RegisterOnShutdown方法以允许开发者注册shutdown时的回调函数。这是个在服务关闭前清理其他资源、做收尾工作的好场所，注册的函数将在一个单独的goroutine中执行，但Shutdown不会等待这些回调函数执行完毕。

>> 按下中断组合键ctrl+c开启HTTP服务的优雅退出过程：
$go run go-program-exit-gracefully-with-notify.go^\web server shutdown okclean resources on shutdown...clean resources okprogram exit ok

>> 系统信号的工作原理以及应用收到信号后的三种处理方式，学习了Go对系统信号的封装原理（同步信号由Go运行时转换为运行时panic，异步信号通过channel发送给用户层）

>> 第55条使用crypto下的密码学包构建安全应用

>> 55.1　Go密码学包概览与设计原则
Go核心团队维护的密码学包由两部分组成：一部分就是我们在标准库crypto目录下看到的相关包；另一部分则是扩展包，位于golang.org/x/crypto下（其仓库镜像地址在github.com/golang/crypto）。

>> 标准库下已经实现的密码学包大致可分为如下几类：
◦  分组密码（block cipher）
▪  cipher包：实现了分组密码算法的五种标准分组模式（block mode），包括ECB模式（Electronic CodeBook mode，电子密码本模式）、CBC模式（Cipher Block Chaining mode，密码分组链接模式）、CFB模式（Cipher Feedback mode，密文反馈模式）、OFB模式（Output Feedback mode，输出反馈模式）和CTR模式（CounTeR mode，计数器模式）。
▪  des包：实现了对称密码（symmetric cryptography）标准中的Data Encryption Standard（DES）和Triple Data Encryption（TDEA）算法，后者也称三重DES。
▪  aes包：实现了对称密码标准中的Advanced Encryption Standard（AES，亦称Rijndael算法）。
◦  公钥密码（public-key cryptography，亦称非对称密码asymmetric cryptography）与数字签名（digital signature）
▪  tls包：实现了TLS 1.2（RFC 5246）和TLS 1.3（RFC 8446）协议。
▪  x509包：实现了对X.509编码格式的密钥和证书的解析。
▪  rsa包：实现了由Ron Rivest、Adi Shamir和Leonard Adleman共同提出的并以他们名字首字母组合命名的RSA公钥密码算法，用于进行公钥加密和私钥签名操作。
▪  elliptic包：实现了在素数域上的几个标准椭圆曲线算法。
▪  dsa包：实现了美国国家标准技术研究所（NIST）的“数字签名算法（DSA）”规范。
▪  ecdsa包：实现了一种利用椭圆曲线密码来实现的数字签名算法，该算法标准同样由NIST发布。

>> ▪  ed25519包：实现了由著名密码学家Daniel J. Bernstein在2006年独立设计的椭圆曲线签名算法Ed25519（http://ed25519.cr.yp.to/）。
◦  单向散列函数，亦称消息摘要（digest）或指纹（fingerprint）
▪  md5包：实现了RFC 1321中定义的MD5哈希算法。
▪  sha1包：实现了RFC 3174中定义的SHA-1哈希算法。
▪  sha256包：实现了NIST标准中的SHA224和SHA256哈希算法。
▪  sha512包：实现了NIST标准中的SHA384和SHA512哈希算法。
◦  消息认证码（Message Authentication Code，MAC）
    hmac包：实现了NIST标准中的基于单向散列函数的消息认证码（HMAC）算法。
◦  随机数生成
    rand包：支持生成密码学安全的随机数。
Go密码学包的目标是帮助Go开发人员构建安全应用，因此它的演进设计原则如下。
◦  实现安全（secure）：以提供一个没有安全漏洞的安全实现为第一原则。
◦  使用安全（safe）：密码学包应该易于安全使用，因为密码学包滥用与使用存在安全漏洞的密码学包对应用的危害是一样大的。
◦  简单实用（practical）：聚焦于常见的、通用的应用场景。
◦  与时俱进（modern）：与密码学工程的最新进展保持同步。

>> 上述这些原则是按优先级从高到低排序的，也就是说实现安全是最重要的。不安全的实现或不安全的API，无论它多么符合其他原则，性能有多好，都是不能接受的。由此可见，秉持这些设计原则的Go密码学包是一个安全且值得信赖的实现。

>> 55.2　分组密码算法
密码算法可以分为分组密码（block cipher）和流密码（stream cipher）两种。流密码是对数据流进行连续处理的一类算法，而我们日常使用最多的DES、AES加密算法则都归于分组密码算法范畴。

>> 使用AES进行加密的示例代码：
// chapter9/sources/go-crypto/aes_cbc_cipher_encrypt.gofunc main() {    // 密钥(key) 32字节 => AES-256    key := []byte("12345678123456781234567812345678")    // 创建AES分组密码算法实例    aesCipher, err := aes.NewCipher(key)    if err != nil {        panic(err)    }    // 待加密的明文字符串（长度恰为分组长度的整数倍）    plaintext := []byte("I love go programming language!!")    // 存储密文的切片，预留出在密文头部放置初始变量的空间    ciphertext := make([]byte, aes.BlockSize+len(plaintext))    // 这里初始变量采用固定字符串，这样多次运行结果相同，便于示例说明    iv := []byte("abcdefghijklmnop")    // 创建分组模式的实例，这里使用CBC模式    cbcModeEncrypter := cipher.NewCBCEncrypter(aesCipher, iv)    // 对明文进行加密    cbcModeEncrypter.CryptBlocks(ciphertext[aes.BlockSize:], plaintext)    // 这里将初始变量放在密文的头部（初始变量的长度 = block length）    copy(ciphertext[:aes.BlockSize], []byte("abcdefghijklmnop"))    fmt.Printf("明文：%s\n", plaintext)    fmt.Printf("密文(包含IV)：%x\n", ciphertext)}

>> 上述加密程序对应的解密程序如下：
// chapter9/sources/go-crypto/aes_cbc_cipher_decrypt.gofunc main() {    // 密钥(key) 32字节 => AES-256    key := []byte("12345678123456781234567812345678")    // 带有初始向量的密文数据（前16字节为初始向量）    ciphertextWithIV, err := hex.DecodeString("6162636465666768696a6b6c6d6e6f70bc93b5cb1a081b47357f73d40966e3ce53c29db21a13bec2f9be4f76d8f09f2b")    if err != nil {        panic(err)    }    // 从密文数据中提取初始向量数据    iv := ciphertextWithIV[:aes.BlockSize]    // 待解密的密文数据    ciphertext := ciphertextWithIV[aes.BlockSize:]    // 创建AES分组密码算法实例    aesCipher, err := aes.NewCipher(key)    if err != nil {        panic(err)    }    // 解密后存放明文的字节切片    plaintext := make([]byte, len(ciphertext))    // 创建分组模式的实例，这里使用CBC模式    cbcModeDecrypter := cipher.NewCBCDecrypter(aesCipher, iv)    // 对密文进行解密    cbcModeDecrypter.CryptBlocks(plaintext, ciphertext)    fmt.Printf("密文(包含IV)：%x\n", ciphertextWithIV)    fmt.Printf("明文：%s\n", plaintext)}

>> 55.3　公钥密码
在对称密码系统中，加密与解密使用相同的密钥。如果在通信系统中使用对称密码系统，那么用于解密的密钥必须被配送给数据接收者，这就会涉及密钥的配送问题。常见的密钥配送方案有事先共享密钥（事先以安全的方式将密钥交给通信方）、密钥分配中心（每个通信方要事先与密钥分配中心共享密钥）、Diffie-Hellman密钥交换算法、公钥密码等。

>> 在公钥密码系统中，每个通信方都会生成两把密钥：私有密钥（private key，简称私钥）和公共密钥（public key，简称公钥）。

>> 55.4　单向散列函数

>> Go标准库密码学包提供了多种主流单向散列函数标准的实现，包括MD5、SHA-1、SHA-256、SHA-384和SHA-512等。Go语言还在扩展包golang.org/x/crypto/sha3中提供了最新的SHA-3标准的实现。

>> SHA-256、SHA-384和SHA-512也都是由NIST设计的单向散列函数，它们的散列值长度分别为256比特（32字节）、384比特（48字节）和512比特（64字节）。这三个散列函数合起来统称SHA-2标准，它是目前应用最为广泛且强抗碰撞性尚未被攻破的单向散列函数标准。SHA-256是这个标准中使用最多的单向散列函数，下面是它的一个应用示例：
// chapter9/sources/go-crypto/sha256_sum.gofunc sum256(data []byte) string {    sum := sha256.Sum256(data)    return fmt.Sprintf("%x", sum)}func main() {    s := "I love go programming language!!"    fmt.Println(sum256([]byte(s)))}

>> 55.5　消息认证码

>> 消息认证码是一种不仅能确认数据完整性，还能保证消息来自期望来源的密码技术。

>> 在实际使用中，对数据进行对称加密且携带MAC值的方式被称为“认证加密”（Authenticated Encryption with Associated Data，AEAD）。认证加密同时满足了机密性（对称加密）、完整性（MAC中的单向散列）以及认证（MAC）的特性，在生产中有着广泛的应用。
认证加密主要有以下三种方式。
◦  Encrypt-then-MAC：先用对称密码对明文进行加密，然后计算密文的MAC值。
◦  Encrypt-and-MAC：将明文用对称密码加密，并计算明文的MAC值。
◦  MAC-then-Encrypt：先计算明文的MAC值，然后将明文和MAC值一起用对称密码加密。
分组密码中的GCM（Galois Counter Mode）就是一种认证加密模式，它使用CTR（计数器）分组模式和128比特分组长度的AES加密算法进行加密，并使用Carter-Wegman MAC算法实现MAC值计算。

>> 55.6　数字签名
消息认证码虽然解决了消息发送者的身份认证问题，但由于采用消息认证码的通信双方共享密钥，因此对于一条通过了MAC验证的消息，通信双方依旧无法向第三方证明这条消息就是对方发送的。同时任何一方也都没有办法防止对方否认该条消息是自己发送的。也就是说单凭消息认证码无法防止否认（non-repudiation）。
数字签名（Digital Signature）就是专为解决上述问题而被发明的密码技术。在消息认证码中，生成MAC和验证MAC使用的是同一密钥，这是无法防止否认问题的根源。因此数字签名技术对生成签名的密钥和验证签名的密钥进行了区分（见图55-10），签名密钥只能由签名一方持有，它的所有通信对端将持有用于验证签名的密钥。

>> 数字签名就是通过将公钥密码反过来用而实现的

>> 在实际生产应用中，我们通常对消息的摘要进行签名。这是因为公钥密码加密算法本身很慢，如果对消息全文进行加密将非常耗时。如果先使用高性能的单向散列函数计算出消息的摘要，再用私钥加密摘要以获得数字签名，将大幅降低数字签名过程的耗时。对摘要进行签名与对原文进行签名在最终消息内容完整性和签名验证上的效果是等价的。

>> 55.7　随机数生成

>> Go密码学包crypto/rand提供了密码学级别的随机数生成器实现rand.Reader，在不同平台上rand.Reader使用的数据源有所不同。在类Unix操作系统上，它使用的是该平台上密码学应用的首选随机数源/dev/urandom：
// $GOROOT/src/crypto/rand/rand_unix.goconst urandomDevice = "/dev/urandom"func init() {    if runtime.GOOS == "plan9" {        Reader = newReader(nil)    } else {        Reader = &devReader{name: urandomDevice}    }}

>> 小结
本条讲解了密码学中常用的几种工具以及在Go中对应的实现包与使用方法。
◦  对称密码（分组密码）：解决数据机密性的问题。
◦  公钥密码：解决密钥分发的问题。
◦  单向散列函数：解决消息完整性检查问题。
◦  消息认证码：可以识别伪装者。
◦  数字签名：解决消息究竟是谁所发的问题，防止否认。
◦  随机数：密码学建构的基础。

>> 第56条掌握bytes包和strings包的基本操作

>> 字节切片本质上是一个三元组（array, len, cap），而字符串则是一个二元组（str, len）

>> 
图56-1　字节切片与字符串的运行时表示

>> bytes和strings包提供的API几乎涵盖了所有基本操作，大致可分为如下几类：
◦  查找与替换；
◦  比较；
◦  拆分；
◦  拼接；
◦  修剪和变换；
◦  快速创建实现了io.Reader接口的实例。

>> 56.1　查找与替换

>> 1. 定性查找

>> Contains系列、HasPrefix和HasSuffix。

>> （1）Contains函数

>> （2）ContainsAny函数

>> ContainsAny函数的语义是，将其两个参数看成两个Unicode字符的集合，如果两个集合存在不为空的交集，则返回true

>> （3）ContainsRune函数

>> fmt.Println(strings.ContainsRune("Golang", 97))            // true，字符[a]的Unicode码点 = 97

>> ContainsRune用于判断某一个Unicode字符（以码点形式即rune类型值传入）是否包含在第一个参数代表的字符串或字节切片中。

>> （4）HasPrefix和HasSuffix函数

>> 2. 定位查找

>> 和定性查找不同，定位相关查找函数会给出第二个参数代表的字符串/字节切片在第一个参数中第一次出现的位置（下标），如果没有找到，则返回-1。另外定位查找还有方向性，从左到右为正向定位查找（Index系列），反之为反向定位查找（LastIndex系列）。

>> 和ContainsAny只查看交集是否为空不同，IndexAny函数返回非空交集中第一个字符在第一个参数中的位置信息。另外要注意，反向查找空串或nil切片，返回的是第一个参数的长度，但作为位置（下标）信息，这个值已经越界了。

>> 说明
strings包并未提供模糊查找功能，基于正则表达式的模糊查找可以使用标准库在regexp包中提供的实现。

>> 3. 替换

>> Go标准库在strings包中提供了两种进行字符串替换的方法：Replace函数与Replacer类型

>> 。bytes包中则只提供了Replace函数用于字节切片的替换。

>> 如果传入-1，则全部替换。而ReplaceAll函数本质上等价于最后一个参数传入-1的Replace函数

>> 56.2　比较

>> 1. 等值比较

>> Go语言原生支持通过操作符==或!=对string类型变量进行等值比较，因此strings包未像bytes包一样提供Equal函数。而bytes包的Equal函数的实现也是基于原生字符串类型的等值比较的：
// $GOROOT/src/bytes/bytes.gofunc Equal(a, b []byte) bool {    return string(a) == string(b)}

>> strings和bytes包还共同提供了EqualFold函数，用于进行不区分大小写的Unicode字符的等值比较。字节切片在比较时，切片内的字节序列将被解释成字符的UTF-8编码表示后再进行比较

>> 2. 排序比较

>> bytes包和strings包均提供了Compare方法来对两个字符串/字节切片做排序比较。但Go原生支持通过操作符>、>=、<和<=对字符串类型变量进行排序比较，因此strings包中Compare函数存在的意义更多是为了与bytes包尽量保持API一致，其自身也是使用原生排序比较操作符实现的

>> 实际应用中，我们很少使用strings.Compare，更多的是直接使用排序比较操作符对字符串类型变量进行比较。

>> bytes包的Compare按字典序对两个字节切片中的内容进行比较

>> 56.3　分割

>> Go标准库的strings包和bytes包提供的对字符串/字节切片进行分割（Split）的API

>> 1. Fields相关函数

>> 空白分割的字符串是最简单且最常见的由特定分隔符分隔的数据。strings包和bytes包中的Fields函数可直接用于处理这类数据的分割

>> fmt.Printf("%q\n", strings.Fields("go java python"))     // ["go" "java" "python"]

>> Fields函数采用了Unicode空白字符的定义，下面的字符均会被识别为空白字符：
// $GOROOT/src/unicode/graphic.go'\t', '\n', '\v', '\f', '\r', ' ', U+0085 (NEL), U+00A0 (NBSP)

>> Go标准库还提供了灵活定制分割逻辑的FieldsFunc函数，通过传入一个用于指示是否为“空白”字符的函数，我们可以实现按自定义逻辑对原字符串进行分割

>> // go-bytes-and-strings/split_and_fields.gosplitFunc := func(r rune) bool {    return r == rune('\n')}fmt.Printf("%q\n", strings.FieldsFunc("\tgo  \f \u0085 \u00a0 java \n\n\rpython", splitFunc)) // ["\tgo  \f \u0085 \u00a0 java " "\rpython"]

>> 2. Split相关函数

>> Go标准库提供了Split相关函数，可以更为通用地对字符串或字节切片进行分割

>> bytes.SplitAfter([]byte("a,b,c,d"), []byte(",")))    // ["a," "b," "c," "d"]

>> ◦  Split函数既可以处理以逗号作为分隔符的字符串，也可以处理以普通字母b为分隔符的字符串。当传入空串（或bytes.Split被传入nil切片）作为分隔符时，Split函数会按UTF-8的字符编码边界对Unicode进行分割，即每个Unicode字符都会被视为一个分割后的子字符串。如果原字符串中没有传入的分隔符，那么Split会将原字符串作为返回的字符串切片中的唯一元素。
◦  SplitN函数的最后一个参数表示对原字符串进行分割后产生的分段数量，Split函数等价于SplitN函数的最后一个参数被传入-1。
◦  SplitAfter不同于Split的地方在于它对原字符串/字节切片的分割点在每个分隔符的后面，由于分隔符并未真正起到分隔的作用，因此它不会被剔除，而会作为子串的一部分返回。SplitAfterN函数的最后一个参数表示对原字符串进行分割后产生的分段数量，SplitAfter函数等价于SplitAfterN函数的最后一个参数被传入-1。

>> 56.4　拼接

>> 拼接（Concatenate）是分割的逆过程。strings和bytes包分别提供了各自的Join函数用于实现字符串或字节切片的拼接。

>> strings包还提供了Builder类型及相关方法用于高效地构建字符串，而bytes包与之对应的用于拼接切片的则是Buffer类型及相关方法

>> 56.5　修剪与变换

>> 1. 修剪

>> （1）TrimSpace

>> （2）Trim、TrimRight和TrimLeft

>> （3）TrimPrefix和TrimSuffix

>> 2. 变换

>> （1）大小写转换

>> strings和bytes包提供了ToUpper和ToLower函数

>> （2）Map函数

>> Go标准库在strings和bytes包中提供了Map函数。

>> 顾名思义，该函数用于将原字符串/字节切片中的部分数据按照传入的映射规则变换为新数据。在下面的示例中，我们通过这种方式将原输入数据中的python变换为了golang：
// Map(string)trans := func(r rune) rune {    switch {    case r == 'p':       return 'g'    case r == 'y':       return 'o'    case r == 't':       return 'l'    case r == 'h':       return 'a'    case r == 'o':       return 'n'    case r == 'n':       return 'g'    }    return r}fmt.Printf("%q\n", strings.Map(trans, "I like python!!"))  // "I like golang!!"// Map([]byte)fmt.Printf("%q\n", bytes.Map(trans, []byte("I like python!!")))                                                           // "I like golang!!"

>> 56.6　快速对接I/O模型

>> strings和bytes包提供了快速创建满足io.Reader接口的方案。利用这两个包的NewReader函数并传入我们的数据域即可创建一个满足io.Reader接口的实例

>> // chapter9/sources/go-bytes-and-strings/string_and_bytes_reader.go...func main() {    var buf bytes.Buffer    var s = "I love Go!!"    _, err := io.Copy(&buf, strings.NewReader(s))    if err != nil {        panic(err)    }    fmt.Printf("%q\n", buf.String()) // "I love Go!!"    buf.Reset()    var b = []byte("I love Go!!")    _, err = io.Copy(&buf, bytes.NewReader(b))    if err != nil {        panic(err)    }    fmt.Printf("%q\n", buf.String()) // "I love Go!!"}
通过创建的strings.Reader或bytes.Reader新实例，我们就可以读取作为数据源的字符串或字节切片中的数据。

>> 第57条理解标准库的读写模型

>> Go语言追求“简单”的设计哲学，这体现在Go语言的各个角落，标准库也不例外。Go基于io.Writer和io.Reader这两个简单的接口类型构建了图57-1所示的Go标准库读写模型。

>> 57.1　直接读写字节序列

>> 使用os.OpenFile创建并打开文件，传入的os.O_APPEND表示采用追加模式打开文件并写入数据

>> 57.2　直接读写抽象数据类型实例

>> 有些时候，我们无须先将数据转换成[]byte类型字节序列后再写入文件或将文件中的数据读取到[]byte类型中，借助标准库的包就可以直接将抽象数据类型实例写入文件或从将从文件中读取的数据填充到抽象数据类型实例中

>> 1. 利用fmt.Fscan和fmt.Fprint系列函数进行读写

>> 2. 利用binary.Read和binary.Write函数进行读写

>> 我们看到fmt.Fscanf系列函数的运作本质是扫描和解析读出的文本字符串，这导致其数据还原能力有局限：无法将从文件中读取的数据直接整体填充到抽象数据类型实例中，只能逐个字段填充。在数据还原方面，二进制编码有着先天优势。

>> 3. 利用gob包的Decode和Encode方法进行读写

>> 虽然binary包实现了抽象数据类型实例的直接读写，但只支持采用定长表示的抽象数据类型，限制了其应用范围。不过，Go标准库为我们提供了一种更为通用的选择：gob包。gob包支持对任意抽象数据类型实例的直接读写，唯一的约束是自定义结构体类型中的字段至少有一个是导出的（字段名首字母大写）。

>> // chapter9/sources/go-read-and-write/direct_read_and_write_adt_in_gob.go...type Player struct {    Name   string    Age    int    Gender string}func directWriteADTToFile(path string, players []Player) error {    f, err := os.Create(path)    ...    enc := gob.NewEncoder(f)    for _, player := range players {        err = enc.Encode(player)        if err != nil {            return err        }    }    return nil}func main() {    var players = []Player{        {"Tommy", 18, "male"},        {"Lucy", 17, "female"},        {"George", 19, "male"},    }    err := directWriteADTToFile("players.dat", players)    ...    f, err := os.Open("players.dat")    ...    var player Player    dec := gob.NewDecoder(f)    for {        err := dec.Decode(&player)        if err == io.EOF {            fmt.Println("read meet EOF")            return        }        if err != nil {            fmt.Println("read file error: ", err)            return        }        fmt.Printf("%v\n", player)    }}
运行该示例：
$go run direct_read_and_write_adt_in_gob.go{Tommy 18 male}{Lucy 17 female}{George 19 male}read meet EOF
可以看出，gob包是上述三种直接读写抽象数据类型实例方法中最为理想的那个。同时，gob包也是Go标准库提供的一个序列化/反序列化方案，和JSON、XML等序列化/反序列化方案不同，它的API直接支持读写实现了io.Reader和io.Writer接口的实例。

>> 57.3　通过包裹类型读写数据

>> 在第29条中，我们提到一种接口的常见应用模式：包裹函数（wrapper function）。我们来简单回顾一下。包裹函数的形式是这样的：接受接口类型参数，并返回与其参数类型相同的返回值。示例如下：
func YourWrapperFunc(param YourInterfaceType) YourInterfaceType

>> 通过包裹函数返回的包裹类型可以实现对输入数据的过滤、装饰、变换等操作，并将结果再次返回给调用者。Go标准库的读写模型广泛运用了包裹函数模式，并且基于这种模式实现了有缓冲I/O、数据格式变换等。

>> 1. 通过包裹类型实现带缓冲I/O

>> Go标准库中的带缓冲I/O是通过包裹函数创建的包裹类型实现的。

>> 带缓冲读文件

>> // chapter9/sources/go-read-and-write/bufio_read_byte_slice.go...func main() {    file := "./bufio.txt"    f, err := os.Open(file)    ...    // 通过包裹函数创建带缓冲I/O的类型    // 初始缓冲区大小为64字节    bio := bufio.NewReaderSize(f, 64)    fmt.Printf("初始状态下缓冲区缓存数据数量=%d字节\n\n", bio.Buffered())    var i int = 1    for {        data := make([]byte, 15)        n, err := bio.Read(data)        if err == io.EOF {            fmt.Printf("第%d次读取数据，读到文件末尾，程序退出\n", i)            return        }        if err != nil {            fmt.Println("读取数据出错：", err)            return        }        fmt.Printf("第%d次读出数据：%q，长度=%d\n", i, data, n)        fmt.Printf("当前缓冲区缓存数据数量=%d字节\n\n", bio.Buffered())        i++    }}

>> 标准库通过包裹函数模式轻松实现了带缓冲的I/O。这充分展示了标准库读写模型的优势。当然bufio不仅可用于磁盘文件，还可以用于包裹任何实现了io.Writer和io.Reader接口的类型（比如网络连接），为其提供缓冲I/O的特性。

>> 2. 通过包裹类型实现数据压缩/解压缩

>> 通过包裹函数返回的包裹类型，我们还可以实现对读出或写入数据的变换，比如压缩等。Go标准库中的compress/gzip包就提供了这样的包裹函数与包裹类型。我们看一个压缩数据并形成压缩文件的例子：
// chapter9/sources/go-read-and-write/gzip_compress_data.go...
func main() {    
	file := "./hello_gopher.gz"    
	f, err := os.OpenFile(file, os.O_RDWR|os.O_CREATE|os.O_APPEND, 0666)    
	...    
	defer f.Close()    
	zw := gzip.NewWriter(f)    
	defer zw.Close()    
	_, err = zw.Write([]byte("hello, gopher! I love golang!!"))    
	if err != nil {        
		fmt.Println("write compressed data error:", err)    
	}    
	fmt.Println("write compressed data ok")
}


>> 这里利用gzip包提供的包裹函数NewWriter对io.File实例进行包裹，得到包裹类型gzip.Writer类型的实例zw。后续通过这里实例调用Write方法写入的数据都会被进行压缩处理并写入文件实例。zw.Close方法调用会将压缩变换后的数据刷新到文件实例中。

>> 小结
抽象数据类型实例与字节序列间的编解码方案除了gob外，还可以使用标准库提供的json和xml等。鉴于篇幅有限，这里就不详细展开了。
本条要点：
◦  Go标准库的读写模型以io.Reader和io.Writer接口为中心；
◦  模型既可以直接读写字节序列数据，也可以直接读写抽象数据类型实例；
◦  本质上，抽象数据类型实例的读写也会被转换为字节序列，只不过这种转换由Go标准库的包代劳了；
◦  通过包裹函数返回的包裹类型，我们可以轻松实现对读取或写入数据的缓冲、变换等处理。这种模式在标准库中有广泛应用。

>> 第58条掌握unsafe包的安全使用模式

>> Go最初的定位是系统编程语言，在考虑类型安全的同时，语言的设计者们还要兼顾性能以及如何实现与操作系统、C代码等互操作的低级代码等问题。最终，Go语言的设计者们选择了在类型系统上开一道“后门”的方案，即在标准库中内置一个特殊的Go包——unsafe包。
“后门”意味着收益与风险并存。使用unsafe包我们可以实现性能更高、与底层系统交互更容易的低级代码，但unsafe包的存在也让我们有了绕过Go类型安全屏障的“路径”。一旦使用该包不当，便可能会导致引入安全漏洞、引发程序崩溃（panic）等问题，并且难于发现和调试。为此，Go设计者们明确了unsafe包的安全使用模式。

>> 58.1　简洁的unsafe包
Go标准库中的unsafe包非常简洁。如果去掉注释，下面的几行代码就是unsafe包的全部内容了（Go 1.14版本）：
// $GOROOT/src/unsafe/unsafe.gopackage unsafefunc Alignof(x ArbitraryType) uintptrfunc Offsetof(x ArbitraryType) uintptrfunc Sizeof(x ArbitraryType) uintptrtype ArbitraryType inttype Pointer *ArbitraryType

>> unsafe包之所以被命名为unsafe，主要是因为该包中定义了unsafe.Pointer类型。unsafe.Pointer可用于表示任意类型的指针，并且它具备下面四条其他指针类型所不具备的性质。
1）任意类型的指针值都可以被转换为unsafe.Pointer。

>> 2）unsafe.Pointer也可以被转换为任意类型的指针值。

>> 3）uintptr类型值可以被转换为一个unsafe.Pointer。

>> 4）unsafe.Pointer也可以被转换为一个uintptr类型值。

>> 综合unsafe.Pointer的四个性质，我们发现通过unsafe.Pointer，可以很容易穿透Go的类型安全保护，就像本条开头那个C语言的例子一样：
// chapter9/sources/go-unsafe/go_is_not_type_safe.gofunc main() {    var a uint32 = 0x12345678    fmt.Printf("0x%x\n", a) // 0x12345678    p := (unsafe.Pointer)(&a) // 利用unsafe.Pointer的性质1    b := (*[4]byte)(p) // 利用unsafe.Pointer的性质2    b[0] = 0x23    b[1] = 0x45    b[2] = 0x67    b[3] = 0x8a    fmt.Printf("0x%x\n", a) // 0x8a674523 (注：在小端字节序系统中输出此值)}
我们看到，原本被解释为uint32类型的一段内存（起始地址为&a，长度为4字节），通过unsafe.Pointer被重新解释成了[4]byte并且通过变量b（*[4]byte类型）可以对该段内存进行修改。

>> 58.2　unsafe包的典型应用

>> 在Go 1兼容性声明文档中能看到如下描述：
unsafe包的使用。导入了unsafe包的包代码可能依赖于Go实现的内部属性。我们保留更改实现的权利，这可能会破坏此类程序。
尽管使用unsafe包无法得到Go1兼容性的保障，是不可移植的，并且很可能导致现在编写的程序在将来无法通过编译或运行出错，但unsafe包所具有的独一无二的穿透类型安全保护的能力对开发人员依旧充满了诱惑力，它首先就被广泛应用于Go标准库和Go运行时的实现当中，reflect、sync、syscall和runtime包都是unsafe包的重度“用户”，这些包有的需要绕过Go类型保护直接操作内存，有的对性能敏感，还有的与操作系统或C语言低级代码交互频繁。

>> 1. reflect包中unsafe包的典型应用

>> ValueOf和TypeOf函数是reflect包中用得最多的两个API，它们是进入运行时反射层、获取反射层信息的入口。这两个函数均将任意类型变量转换为一个interface{}类型变量，再利用unsafe.Pointer将这个变量绑定的内存区域重新解释为reflect.emptyInterface类型，以获得传入变量的类型和值的信息。

>> // $GOROOT/src/reflect/value.go

>> 2. sync包中unsafe包的典型应用

>> sync.Pool是一个并发安全的高性能临时对象缓冲池。sync.Pool为每个P分配了一个本地缓冲池，并通过下面函数实现快速定位P的本地缓冲池

>> // $GOROOT/src/sync/pool.go

>> 3. syscall包中unsafe包的典型应用

>> 标准库中的syscall包封装了与操作系统交互的系统调用接口，比如Stat、Listen、Select等

>> // $GOROOT/src/syscall/zsyscall_linux_amd64.go

>> // $GOROOT/src/syscall/syscall_unix.go

>> 4. runtime包中unsafe包的典型应用

>> runtime包实现的goroutine调度和内存管理（包括GC）都有unsafe包的身影。

>> 以goroutine的栈管理为例：
// $GOROOT/src/runtime/runtime2.go

>> unsafe包在这些项目中主要被用于如下两个场景。
（1）与操作系统以及非Go编写的代码的通信
与操作系统的通信主要通过系统调用进行，这在之前已提过。而与非Go编写的代码的通信则主要通过cgo方式，如下面的示例：
func SetIcon(iconBytes []byte) {    // 转换成一个C char类型    cstr := (*C.char)(unsafe.Pointer(&iconBytes[0]))    // 调用来自systray.h的函数    C.setIcon(cstr, (C.int)(len(iconBytes)))}

>> （2）高效类型转换
使用unsafe包，Gopher可以绕开Go类型系统的安全检查，因此可以通过unsafe包实现性能更好的类型转换。最常见的类型转换是string与[]byte类型间的相互转换：
func Bytes2String(b []byte) string {
	return *(*string)(
		unsafe.Pointer(&b))
}
func String2Bytes(s string) []byte {
	sh := (*reflect.StringHeader)(unsafe.Pointer(&s))
	bh := reflect.SliceHeader{
		Data: sh.Data,
		Len:  sh.Len,
		Cap:  sh.Len,
	}
	return *(*[]byte)(unsafe.Pointer(&bh))
}

>> 在Go中，string类型变量是不可变的（immutable），通过常规方法将一个string类型变量转换为[]byte类型，Go会为[]byte类型变量分配一块新内存，并将string类型变量的值复制到这块新内存中。而通过上面基于unsafe包实现的String2Bytes函数，这种转换并不需要额外的内存复制：转换后的[]byte变量与输入参数中的string类型变量共享底层存储（但注意，我们依旧无法通过对返回的切片的修改来改变原字符串）。而将[]byte变量转换为string类型则更为简单，因为[]byte的内部表示是一个三元组(ptr, len, cap)，string的内部表示为一个二元组(ptr, len)，通过unsafe.Pointer将[]byte的内部表示重新解释为string的内部表示，这就是Bytes2String的原理。
此外unsafe在自定义高性能序列化函数（marshal）、原子操作（atomic）及内存操作（指针运算）上都有一定程度的应用。

>> [1]见文章《破坏的类型安全：对unsafe包使用的研究》，地址为https://arxiv.org/abs/2006.09973。

>> 58.3　正确理解unsafe.Pointer与uintptr

>> 作为Go类型安全层上的一个“后门”，unsafe包在带来强大的低级编程能力的同时，也极容易导致代码出现错误。而出现这些错误的主要原因可归结为对unsafe.Pointer和uintptr的理解不到位。

>> unsafe.Pointer和其他常规类型指针一样，可以作为对象引用。如果一个对象仍然被某个unsafe.Pointer变量引用着，那么该对象是不会被垃圾回收的。但是uintptr并不是指针，它仅仅是一个整型值，即便它存储的是某个对象的内存地址，它也不会被算作对该对象的引用。如果认为将对象地址存储在一个uintptr变量中，该对象就不会被垃圾回收器回收，那就是对uintptr的最大误解。

>> 下面的例子直观地对比了对象被unsafe.Pointer引用与被uintptr“引用”的差别：
// chapter9/sources/go-unsafe/go_mem_obj_ref_unsafepointer_vs_uintptr.go...type Foo struct {    name string}func finalizer(p *Foo) {    fmt.Printf("Foo: [%s]被垃圾回收\n", p.name)}func NewFoo(name string) *Foo {    var f Foo = Foo{        name: name,    }    runtime.SetFinalizer(&f, finalizer)    return &f}func allocLargeObject() *[1000000]uint64 {    a := [1000000]uint64{}    return &a}func main() {    var p1 = uintptr(unsafe.Pointer(NewFoo("FooRefByUintptr")))    var p2 = unsafe.Pointer(NewFoo("FooRefByPointer"))    for i := 0; i < 5; i++ {        allocLargeObject()        // 尝试输出p1和p2地址上的值        q1 := (*Foo)(unsafe.Pointer(p1))        fmt.Printf("object ref by uintptr: %+v\n", *q1)        q2 := (*Foo)(p2)        fmt.Printf("object ref by pointer: %+v\n", *q2)        runtime.GC() // 运行垃圾回收        time.Sleep(1 * time.Second)    }}

>> 在这个例子中，我们通过NewFoo创建了两个Foo类型实例，NewFoo函数在每个实例上设置了finalizer，这样便于直观看到该实例是否在程序运行过程中被垃圾回收了。我们将这两个新实例的内存地址分别赋值给一个uintptr类型变量p1和一个unsafe.Pointer类型变量p2。之后，我们运行了一个循环，在每次循环中，我们都会通过调用allocLargeObject做一些内存分配工作，并显式调用runtime.GC触发垃圾回收。每次循环我们还尝试输出这两个实例的值。下面是该示例的运行结果（为了避免编译器对程序进行内联优化，我们在运行时传入了-gcflags="-l"命令行选项）：
$go run -gcflags="-l" go_mem_obj_ref_unsafepointer_vs_uintptr.goFoo: [FooRefByUintptr]被垃圾回收object ref by uintptr: {name:FooRefByUintptr}object ref by pointer: {name:FooRefByPointer}object ref by uintptr: {name:FooRefByUintptr}object ref by pointer: {name:FooRefByPointer}object ref by uintptr: {name:FooRefByUintptr}object ref by pointer: {name:FooRefByPointer}object ref by uintptr: {name:}object ref by pointer: {name:FooRefByPointer}object ref by uintptr: {name:}object ref by pointer: {name:FooRefByPointer}
我们看到，uintptr“引用”的Foo实例（FooRefByUintptr）在程序运行起来后很快就被回收了，而unsafe.Pointer引用的Foo实例（FooRefByPointer）的生命周期却持续到程序终止。FooRefByUintptr实例被回收后，p1变量值中存储的地址值已经失效，上面的输出结果也证实了这一点：这个地址处的内存后续被重新利用了。
使用uintptr类型变量保存栈上变量的地址同样是有风险的，因为Go使用的是连续栈的栈管理方案，每个goroutine的默认栈大小为2KB（_StackMin = 2048）。当goroutine当前剩余栈空间无法满足函数/方法调用对栈空间的需求时，Go运行时就会新分配一块更大的内存空间作为该goroutine的新栈空间，并将该goroutine的原有栈整体复制过来，这样原栈上分配的变量的地址就会发生变化。

>> 我们来看下面这个例子：
// chapter9/sources/go-unsafe/go_stack_obj_ref_by_uintptr.go...func main() {    var x = [10]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 0}    fmt.Printf("变量x的值=%d\n", x)    println("变量x的地址=", &x)    var p = uintptr(unsafe.Pointer(&x))    var q = unsafe.Pointer(&x)    a(x) // 执行一系列函数调用    // 变更数组x中元素的值    for i := 0; i < 10; i++ {        x[i] = x[i] + 10    }    println("栈扩容后，变量x的地址=", &x)    fmt.Printf("栈扩容后，变量x的值=%d\n", x)    fmt.Printf("变量p(uintptr)存储的地址上的值=%d\n", *(*[10]int)(unsafe.Pointer(p)))    fmt.Printf("变量q(unsafe.Pointer)引用的地址上的值=%d\n", *(*[10]int)(q))}func a(x [10]int) {    var y [100]int    b(y)}func b(x [100]int) {    var y [1000]int    c(y)}func c(x [1000]int) {}
在这个例子中，我们分别用一个uintptr类型变量p和unsafe.Pointer类型变量q存储了栈上变量x的地址。调用函数a之后，goroutine栈发生了扩容。我们变更了数组x中的元素值以用于栈扩容前后的对比。运行该示例：
$go run -gcflags="-l" go_stack_obj_ref_by_uintptr.go变量x的值=[1 2 3 4 5 6 7 8 9 0]变量x的地址= 0xc00006cec8栈扩容后，变量x的地址= 0xc000117ec8栈扩容后，变量x的值=[11 12 13 14 15 16 17 18 19 10]变量p(uintptr)存储的地址上的值=[1 2 3 4 5 6 7 8 9 0]变量q(unsafe.Pointer)引用的地址上的值=[11 12 13 14 15 16 17 18 19 10]

>> 我们看到，栈扩容后，变量x的地址发生了变化（从0xc00006cec8变成0xc000117ec8），unsafe.Pointer类型变量q的值被Go运行时做了同步变更；但uintptr类型变量p只是一个整型值，它的值是不变的，因此输出uintptr类型变量p存储的地址上的值时，得到的仍是变量x变更前的值。

>> 58.4　unsafe.Pointer的安全使用模式

>> “长江之险，险于荆江。”unsafe包之险，险于unsafe.Pointer的使用。我们既需要unsafe.Pointer打破类型安全屏障的能力，又需要其能被安全使用，要想鱼与熊掌兼得，就必须按照unsafe.Pointer的安全使用模式的要求去做。Go（1.14版本）在unsafe的文档中定义了6条安全使用模式，我们逐一来理解一下。

>> 模式1：*T1 -> unsafe.Pointer -> *T2

>> 模式1的本质就是内存块的重解释：将原本解释为T1类型的内存重新解释为T2类型。这是unsafe.Pointer突破Go类型安全屏障的基本使用模式。

>> 模式2：unsafe.Poiner -> uintptr

>> 模式2比较简单，就是将unsafe.Pointer显式转换为uintptr，并且转换后的uintptr类型变量不会再转换回unsafe.Pointer，只用于打印输出，并不参与其他操作。

>> 模式3：模拟指针运算

>> 操作任意内存地址上的数据都离不开指针运算。Go常规语法不支持指针运算，但我们可以使用unsafe.Pointer的第三种安全使用模式来模拟指针运算，即在一个表达式中，将unsafe.Pointer转换为uintptr类型，使用uintptr类型的值进行算术运算后，再转换回unsafe.Pointer

>> 模式4：调用syscall.Syscall系列函数时指针类型到uintptr类型参数的转换
Go标准库的syscall包的Syscall系列函数的参数都是uintptr类型

>> 模式5：将reflect.Value.Pointer或reflect.Value.UnsafeAddr转换为指针

>> 模式6：reflect.SliceHeader和reflect.StringHeader必须通过模式1构建
reflect包的SliceHeader和StringHeader两个结构体分别代表着切片类型和string类型的内存表示。

>> Go核心团队一直在完善工具链，加强对代码中unsafe使用安全性的检查。通过go vet可以检查unsafe.Pointer和uintptr之间的转换是否符合上述六种安全模式。

>> Go 1.14编译器在-race和-msan命令行选型开启的情况下，会执行-d=checkptr检查，即对unsafe.Pointer进行下面两项合规性检查。
1）当将*T1类型按模式1通过unsafe.Pointer转换为*T2时，T2的内存地址对齐系数不能高于T1的对齐系数。

>> 2）做完指针运算后，转换后的unsafe.Pointer仍应指向原先的内存对象。

>> 小结
作为最初以系统编程语言为目标的语言，Go为了兼顾性能以及低级代码操作，在其安全类型的保护盾下开了一个“后门”。在大多数情况下，这是Go核心团队自用的机制。我们要想使用unsafe包，就必须遵循unsafe包，尤其是unsafe.Pointer的安全使用规则。
本条要点：
◦  Go语言在常规操作下是类型安全的，但使用unsafe包可以“刺透”Go的类型安全保护层；
◦  Go兼容性并不包含对unsafe包的任何承诺，因此除非必要，尽量不要使用unsafe包，尤其是unsafe.Pointer；
◦  uintptr仅仅是一个整型值，即便它存储的是内存对象的地址值，它对内存对象也起不到引用的作用；
◦  使用unsafe包前，请先牢记并理解unsafe.Pointer的六条安全使用模式；
◦  如果使用了unsafe包，请使用go vet等工具对代码进行unsafe包使用合规性的检查。

>> 第59条谨慎使用reflect包提供的反射能力

>> Go语言的interface{}类型变量具有析出任意类型变量的类型信息（type）和值信息（value）的能力

>> Go的反射本质上就是利用interface{}的这种能力在运行时对任意变量的类型和值信息进行检视甚至是对值进行修改的机制。

>> 59.1　Go反射的三大法则

>> json.Marshal也是通过这种特性对传入的任意结构体类型进行解构并正确生成对应的JSON文本。

>> // chapter9/sources/go-reflect/construct_sql_query_stmt.gofunc ConstructQueryStmt(obj interface{}) (stmt string, err error) {    // 仅支持struct或struct指针类型    typ := reflect.TypeOf(obj)    if typ.Kind() == reflect.Ptr {        typ = typ.Elem()    }    if typ.Kind() != reflect.Struct {        err = errors.New("only struct is supported")        return    }    buffer := bytes.NewBufferString("")    buffer.WriteString("SELECT ")    if typ.NumField() == 0 {        err = fmt.Errorf("the type[%s] has no fields", typ.Name())        return    }    for i := 0; i < typ.NumField(); i++ {        field := typ.Field(i)        if i != 0 {            buffer.WriteString(", ")        }        column := field.Name        if tag := field.Tag.Get("orm"); tag != "" {            column = tag        }        buffer.WriteString(column)    }    stmt = fmt.Sprintf("%s FROM %s", buffer.String(), typ.Name())    return}

>> Go反射十分适合处理这一类问题，它们的典型特点包括：
◦  输入参数的类型无法提前确定；
◦  函数或方法的处理结果因传入参数（的类型信息和值信息）的不同而异。

>> “反射并不是Go推荐的惯用法，建议大家谨慎使用。”在绝大多数情况下，反射都不是为你提供的。

>> ◦  反射让你的代码逻辑看起来不那么清晰，难于理解；
◦  反射让你的代码运行得更慢；
◦  在编译阶段，编译器无法检测到使用反射的代码中的问题（这种问题只能在Go程序运行时暴露出来，并且一旦暴露，很大可能会导致运行时的panic）。

>> Rob Pike还为Go反射的规范使用定义了三大法则，如果经过评估，你必须使用反射才能实现你要的功能特性，那么你在使用反射时需要牢记这三条法则。
◦  反射世界的入口：经由接口（interface{}）类型变量值进入反射的世界并获得对应的反射对象（reflect.Value或reflect.Type）。
◦  反射世界的出口：反射对象（reflect.Value）通过化身为一个接口（interface{}）类型变量值的形式走出反射世界。
◦  修改反射对象的前提：反射对象对应的reflect.Value必须是可设置的（Settable）。

>> 59.2　反射世界的入口
reflect.TypeOf和reflect.ValueOf是进入反射世界仅有的两扇“大门”。通过reflect.TypeOf这扇“门”进入反射世界，你将得到一个reflect.Type对象，该对象中包含了被反射的Go变量实例的所有类型信息；而通过reflect.ValueOf这扇“门”进入反射世界，你将得到一个reflect.Value对象。Value对象是反射世界的核心，不仅该对象中包含了被反射的Go变量实例的值信息，而且通过调用该对象的Type方法，我们还可以得到Go变量实例的类型信息，这与通过reflect.TypeOf获得类型信息是等价的

>> reflect.Value类型拥有很多方便我们进行值检视的方法，比如Bool、Int、String等

>> reflect.Type是一个接口类型，它包含了很多用于检视类型信息的方法，而对于简单原生类型来说，通过Name、String或Kind方法就可以得到我们想要的类型名称或类型类别等信息。

>> 通过Value提供的Index方法，我们可以获取到切片及数组类型元素所对应的Value对象值（通过Value对象值我们可以得到其值信息）。通过Value的MapRange、MapIndex等方法，我们可以获取到map中的key和value对象所对应的Value对象值，有了Value对象，我们就可以像上面获取简单原生类型的值信息那样获得这些元素的值信息。

>> 对于结构体类型，Value提供了Field系列方法。在上面的示例中，我们通过下标的方式（Field方法）获取结构体字段所对应的Value对象，从而获取字段的值信息。

>> 通过反射对象，我们还可以调用函数或对象的方法：
// chapter9/sources/go-reflect/call_func_and_method.go...func Add(i, j int) int {    return i + j}type Calculator struct{}func (c Calculator) Add(i, j int) int {    return i + j}func main() {    // 函数调用    f := reflect.ValueOf(Add)    var i = 5    var j = 6    vals := []reflect.Value{reflect.ValueOf(i), reflect.ValueOf(j)}    ret := f.Call(vals)    fmt.Println(ret[0].Int()) // 11    // 方法调用    c := reflect.ValueOf(Calculator{})    m := c.MethodByName("Add")    ret = m.Call(vals)    fmt.Println(ret[0].Int()) // 11}

>> 务必保证Value参数的类型信息与原函数或方法的参数的类型相匹配，否则会导致运行时panic

>> 59.3　反射世界的出口

>> reflect.Value.Interface()是reflect.ValueOf()的逆过程，通过Interface方法我们可以将reflect.Value对象恢复成一个interface{}类型的变量值。这个离开反射世界的过程实质是将reflect.Value中的类型信息和值信息重新打包成一个interface{}的内部表示。

>> 之后，我们就可以通过类型断言得到一个反射前的类型变量值：
// chapter9/sources/go-reflect/reflect_value_to_interface.go...func main() {    var i = 5    val := reflect.ValueOf(i)    r := val.Interface().(int)    fmt.Println(r) // 5    r = 6    fmt.Println(i, r) // 5 6    val = reflect.ValueOf(&i)    q := val.Interface().(*int)    fmt.Printf("%p, %p, %d\n", &i, q, *q) // 0xc0000b4008, 0xc0000b4008, 5    *q = 7    fmt.Println(i) // 7}

>> 59.4　输出参数、interface{}类型变量及反射对象的可设置性

>> 对于以interface{}类型变量i作为形式参数的reflect.ValueOf和reflect.TypeOf函数来说，i自身是被反射对象的“复制品”，就像上面函数的输入参数那样。而新创建的反射对象又复制了i中所包含的值信息，因此当被反射对象以值类型（T）传递给reflect.ValueOf时，在反射世界中对反射对象值信息的修改不会对被反射对象产生影响。Go的设计者们认为这种修改毫无意义，并禁止了这种行为。一旦发生这种行为，将会导致运行时panic：
var i = 17val := reflect.ValueOf(i)val.SetInt(27) // panic: reflect: reflect.flag.mustBeAssignable using unaddressable value
reflect.Value提供了CanSet、CanAddr及CanInterface等方法来帮助我们判断反射对象是否可设置（Settable）、可寻址、可恢复为一个interface{}类型变量。

>> ◦  当被反射对象以值类型（T）传递给reflect.ValueOf时，所得到的反射对象（Value）是不可设置和不可寻址的。
◦  当被反射对象以指针类型（*T或&T）传递给reflect.ValueOf时，通过reflect.Value的Elem方法可以得到代表该指针所指内存对象的Value反射对象。而这个反射对象是可设置和可寻址的，对其进行修改（比如利用Value的SetInt方法）将会像函数的输出参数那样直接修改被反射对象所指向的内存空间的值。
◦  当传入结构体或数组指针时，通过Field或Index方法得到的代表结构体字段或数组元素的Value反射对象也是可设置和可寻址的。如果结构体中某个字段是非导出字段，则该字段是可寻址但不可设置的（比如上面例子中的age字段）。
◦  当被反射对象的静态类型是接口类型时（就像上面的interface{}类型变量i），该被反射对象的动态类型决定了其进入反射世界后的可设置性。如果动态类型为*T或&T时，就像上面传给变量i的是&Person{}，那么通过Elem方法获得的反射对象就是可设置和可寻址的。
◦  map类型被反射对象比较特殊，它的key和value都是不可寻址和不可设置的。但我们可以通过Value提供的SetMapIndex方法对map反射对象进行修改，这种修改会同步到被反射的map变量中。

>> 小结
reflect包所提供的Go反射能力是一把“双刃剑”，它既可以被用于优雅地解决一类特定的问题，但也会带来逻辑不清晰、性能问题以及难于发现问题和调试等困惑。因此，我们应谨慎使用这种能力，在做出使用的决定之前，认真评估反射是不是问题的唯一解决方案；在确定要使用反射能力后，也要遵循上述三个反射法则的要求。

>> 第60条了解cgo的原理和使用开销

>> 在如下一些场景中，我们很大可能甚至是不可避免地会使用到cgo来实现Go与C的互操作。
◦  为了提升局部代码性能，用C代码替换一些Go代码。在性能方面，C代码之于Go就好比汇编代码之于C。
◦  对Go内存GC的延迟敏感，需要自己手动进行内存管理（分配和释放）；
◦  为一些C语言专有的且没有Go替代品的库制作Go绑定（binding）或包装。比如：Oracle提供了C版本OCI库（Oracle Call Interface），但并未提供Go版本的OCI库以及连接数据库的协议细节，因此我们只能通过包装C语言的OCI版本与Oracle数据库通信。类似的情况还有一些图形驱动程序以及图形化的窗口系统接口（如OpenGL库等）。
◦  与遗留的且很难重写或替换的C代码进行交互。
使用cgo是需要付出一定成本的，且其复杂性高，难以驾驭。

>> 60.1　Go调用C代码的原理

>> // chapter9/sources/go-cgo/how_cgo_works.gopackage main// #include <stdio.h>// #include <stdlib.h>//// void print(char *str) {//     printf("%s\n", str);// }import "C"import "unsafe"func main() {    s := "Hello, Cgo"    cs := C.CString(s)    defer C.free(unsafe.Pointer(cs))    C.print(cs) // Hello, Cgo}
与常规的Go代码相比，上述代码有几处特殊的地方：
◦  C代码直接出现在Go源文件中，只是都以注释的形式存在；
◦  紧邻注释了的C代码块之后（中间没有空行），我们导入了一个名为C的包；
◦  在main函数中通过C这个包调用了C代码中定义的函数print。
这就是在Go源码中调用C代码的语法。首先，Go源码文件中的C代码是需要用注释包裹的，就像上面的include头文件以及print函数定义那样。其次，import "C"这行语句是必须有的，而且其与上面的C代码之间不能用空行分隔，必须紧密相连。这里的“C”不是包名，而是一种类似名字空间的概念，也可以理解为伪包名，C语言所有语法元素均在该伪包下面。最后，访问C语法元素时都要在其前面加上伪包C的前缀，比如C.uint和上面代码中的C.print、C.free等。
如何编译这个带有C代码的Go源文件呢？其实与常规的Go源文件没什么区别，依旧可以直接通过go build或go run来编译和执行。可以通过go build -x -v输出带有cgo代码的Go源文件的构建细节：
$go build -x -v  how_cgo_works.go

>> go build调用了名为cgo的工具，cgo会识别和读取Go源文件（how_cgo_works.go）中的C代码，并将其提取后交给外部的C编译器（clang或gcc）编译，最后与Go源码编译后的目标文件链接成一个可执行程序。这样我们就不难理解为何Go源文件中的C代码要用注释包裹并放在C这个伪包下面了，这些特殊的语法都是可以被cgo识别并使用的。

>> 60.2　在Go中使用C语言的类型

>> 1. 原生类型
（1）数值类型

>> （2）指针类型

>> （3）字符串类型

>> s := "Hello, Cgo\n"cs := C.CString(s)C.print(cs)
不过这个转型相当于在C语言世界的堆上分配一块新内存空间，这样转型后所得到的C字符串cs并不能由Go的GC（垃圾回收器）管理，我们必须在使用后手动释放cs所占用的内存，这就是例子中通过defer调用C.free释放掉cs的原因。再次强调，对于在C内部分配的内存，Go中的GC是无法感知到的，因此要记着在使用后手动释放。

>> （4）数组类型

>> 2. 自定义类型
除了原生类型外，我们还可以访问C代码中的自定义类型。
（1）枚举（enum）

>> （2）结构体（struct）

>> （3）联合体（union）

>> （4）别名类型（typedef）

>> 3. Go中获取C类型大小

>> 为了方便获得C世界中的类型的大小，Go提供了C.sizeof_T来获取C.T类型的大小。

>> 60.3　在Go中链接外部C库

>> 从代码结构上来讲，在Go源文件中大量编写C代码并不是Go推荐的惯用法。那么如何将C函数和变量定义从Go源码中分离出去单独定义呢？我们很容易想到将C的代码以共享库的形式提供给Go源码。

>> Go提供了#cgo指示符，可以用它指定Go源码在编译后与哪些共享库进行链接。

>> // go-cgo/foo.gopackage main// #cgo CFLAGS: -I${SRCDIR}// #cgo LDFLAGS: -L${SRCDIR} -lfoo// #include <stdio.h>// #include <stdlib.h>// #include "foo.h"import "C"import "fmt"func main() {    fmt.Println(C.count)    C.foo()}
我们看到在上面的例子中，通过#cgo指示符告诉Go编译器在当前源码目录（${SRCDIR}会在编译过程中自动转换为当前源码所在目录的绝对路径）下查找头文件foo.h，并链接当前源码目录下的libfoo共享库。C.count变量和C.foo函数的定义都在libfoo共享库中。

>> 我们来创建这个共享库：
// chapter9/sources/go-cgo/foo.hextern int count;void foo();// chapter9/sources/go-cgo/foo.c#include "foo.h"int count = 6;void foo() {    printf("I am foo!\n");}$gcc -c foo.c$ar rv libfoo.a foo.o
我们用ar工具成功创建了一个静态共享库文件libfoo.a。接下来构建并运行foo.go：
$go build foo.go$./foo6I am foo!
我们看到foo.go成功链接到libfoo.a并生成最终的二进制文件foo。

>> Go同样支持链接动态共享库，我们用下面的命令将上面的foo.c编译为一个动态共享库：
$gcc -c foo.c//$gcc -shared -Wl,-soname,libfoo.so -o libfoo.so  foo.o (在linux上)$gcc -shared -o libfoo.so  foo.o
重新编译foo.go，并查看（在Linux上可以使用ldd，在macOS上使用otool）重新生成的二进制文件foo的动态共享库依赖情况：
$> go build foo.go$otool -L foofoo:    libfoo.so (compatibility version 0.0.0, current version 0.0.0)    /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1252.250.1)
有一点值得注意的是，Go支持多返回值，而C并不支持，因此当将C函数用在多返回值的Go调用中时，C的errno将作为函数返回值列表中最后那个error返回值返回。下面是个例子：
// chapter9/sources/go-cgo/c_errno.gopackage main// #include <stdlib.h>// #include <stdio.h>// #include <errno.h>// int foo(int i) {//     errno = 0;//     if (i > 5) {//         errno = 8;//         return i - 5;//     } else {//         return i;//     }//}import "C"import "fmt"func main() {    i, err := C.foo(C.int(8))    if err != nil {        fmt.Println(err)    } else {        fmt.Println(i)    }}
运行这个例子：
$go run c_errno.goexec format error

>> exec format error就是errno为8时的错误描述信息。我们可以在C运行时库的errno.h中找到errno=8与这段描述信息的联系：
#define ENOEXEC      8  /* Exec format error */

>> 60.4　在C中使用Go函数

>> 在C中使用Go函数的场合极少。在Go中，可以使用export + 函数名来导出Go函数为C所用。

>> 60.5　使用cgo的开销

>> 1. 不能忽视的调用开销

>> 在Go代码中调用C函数看起来似乎很平滑，但实际上这种调用的开销要比调用Go函数多出一个甚至多个数量级。

>> 我们使用Go自带的性能基准测试来定量看看这种开销：
// chapter9/sources/go-cgo/cgo-perf/cgo_call.gopackage main//// void foo() {// }//import "C"func CallCFunc() {    C.foo()}func foo() {}func CallGoFunc() {    foo()}// chapter9/sources/go-cgo/cgo-perf/cgo_call_test.gofunc BenchmarkCGO(b *testing.B) {    for i := 0; i < b.N; i++ {        CallCFunc()    }}func BenchmarkGo(b *testing.B) {    for i := 0; i < b.N; i++ {        CallGoFunc()    }}
运行这个基准测试，注意务必通过-gcflags '-l'关闭内联优化，这样才能得到公平的测试结果：
$go test -bench . -gcflags '-l'goos: darwingoarch: amd64pkg: go-cgo/cgo-perfBenchmarkCGO-8   21359138         56.5 ns/opBenchmarkGo-8    509841430        2.37 ns/opPASSok      go-cgo/cgo-perf           2.716s
通过结果我们看到：在这个例子中，通过cgo调用C函数付出的开销是调用Go函数的将近30倍。因此如果一定要使用cgo，一个不错的方案是将代码尽量下推到C中以减少语言间交互调用的次数，从而降低平均调用开销。
注意，import "C"不支持放在xx_test.go文件中。

>> 2. 增加线程数量暴涨的可能性

>> Go以轻量级goroutine应对高并发而闻名，goroutine和内核线程之间通过多路复用方式对应，这样通常Go应用会启动很多goroutine，但创建的线程数量是有限的。下面的例子可以印证这一点：
// chapter9/sources/go-cgo/go_sleep.gofunc goSleep() {    time.Sleep(time.Second * 1000)}func main() {    var wg sync.WaitGroup    wg.Add(100)    for i := 0; i < 100; i++ {        go func() {            goSleep()            wg.Done()        }()    }    wg.Wait()}
我们在主goroutine之外还创建100个goroutine，每个goroutine都睡眠1000秒。编译运行这个程序后，查看一下该进程中当前存在的线程数量：
//　以下在Ubuntu 18.04下执行（Go 1.14）$go build go_sleep.go$./go_sleep// 另一个命令窗口输入$ps -ef|grep go_sleeproot     15829 10033  0 10:15 pts/0    00:00:00 ./go_sleep$cat /proc/15829/status|grep -i threadThreads:    3

>> 我们看到虽然额外启动了100个goroutine，但进程使用的线程数仅为3。这是因为Go优化了一些原本会导致线程阻塞的系统调用，比如上面的Sleep及部分网络I/O操作，通过运行时调度在不创建新线程的情况下依旧能达到同样的效果。
但是Go调度器无法掌控C世界，如果将上面的Sleep换成C空间内的sleep函数调用，那么结果会是什么呢？我们来改编一下上面的程序，让goroutine调用C空间的sleep函数：
// chapter9/sources/go-cgo/cgo_sleep.gopackage main//#include <unistd.h>//void cgoSleep() { sleep(1000); }import "C"import (    "sync")func cgoSleep() {    C.cgoSleep()}func main() {    var wg sync.WaitGroup    wg.Add(100)    for i := 0; i < 100; i++ {        go func() {            cgoSleep()            wg.Done()        }()    }    wg.Wait()}
编译运行这一改为调用C代码的示例程序：
$go build cgo_sleep.go$./cgo_sleep// 另一个命令窗口输入$ps -ef|grep cgo_sleeproot     15939 10033  0 10:17 pts/0    00:00:00 ./cgo_sleep$cat /proc/15939/status|grep -i threadThreads:    103
新创建的goroutine得到调度后，会执行C空间的sleep函数进入睡眠状态，执行这段代码的线程（M）也随之挂起，这之后Go运行时调度代码只能创建新的线程以供其他没有绑定M的P上的goroutine使用（关于P、M的概念参考第32条），于是100个新线程被创建了出来。
虽然这是一种比较极端的情况，但在日常开发中，我们很容易在C空间中写出导致线程阻塞的C代码，这会使得Go应用进程内线程数量暴涨的可能性大增，这与Go承诺的轻量级并发有背离。

>> 3. 失去跨平台交叉构建能力

>> 通过下面的命令查看Go支持的操作系统和平台列表（这里使用Go 1.14）：
$go tool dist list

>> 在Go 1.5及以后版本中，使用Go进行跨平台交叉编译是极其简单的，我们仅需指定目标平台的操作系统类型（GOOS）和处理器架构类型（GOARCH）即可，就像下面的例子这样：
// 在macOS/amd64上$GOOS=linux GOARCH=amd64 go build go_sleep.go
但这种跨平台编译能力仅限于纯Go代码。如果我们跨平台编译使用了cgo技术的Go源文件，我们将得到如下结果：
$GOOS=linux GOARCH=amd64 go build cgo_sleep.gogo: no Go source files

>> 当Go编译器执行跨平台编译时，它会将CGO_ENABLED置为0，即关闭cgo，这也是上面找不到cgo_sleep.go的原因。下面我们显式开启cgo并再来跨平台编译一下上面的cgo_sleep.go文件：
$CGO_ENABLED=1 GOOS=linux GOARCH=amd64 go build ./cgo_sleep.go# command-line-arguments$GOROOT/pkg/tool/darwin_amd64/link: running clang failed: exit status 1ld: warning: ignoring file /var/folders/cz/sbj5kg2d3m3c6j650z0qfm800000gn/T/go-link-231346986/go.o, file was built for unsupported file format ( 0x7F 0x45 0x4C 0x46 0x02 0x01 0x01 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00 ) which is not the architecture being linked (x86_64): /var/folders/cz/sbj5kg2d3m3c6j650z0qfm800000gn/T/go-link-231346986/go.oUndefined symbols for architecture x86_64:  "_main", referenced from:     implicit entry/start for main executableld: symbol(s) not found for architecture x86_64clang: error: linker command failed with exit code 1 (use -v to see invocation)
显然，即便显式开启cgo，cgo调用的macOS上的外部链接器clang也会因无法识别目标平台的目标文件格式而报错，macOS上的clang默认并不具备跨平台编译Linux应用的能力。
注：上述跨平台构建的错误输出信息可能因Go和macOS版本不同而异。

>> 4. 其他开销
前面提到过，Go代码与C代码分别位于两个世界，中间竖立了高大的屏障，任何一方都无法轻易跨过，这让它们无法很好地利用对方的优势。
首先是内存管理，Go世界采用垃圾回收机制，而C世界采用手工内存管理，开发人员在GC与“记着释放内存”的规则间切换，极易产生bug，给开发人员带来很大心智负担。
Go所拥有的强大工具链在C代码面前无处施展，Go的竞态检测工具、性能剖析工具、测试覆盖率工具、模糊测试以及源码竞态分析工具再怎么强大，也无法跨越Go与C之间的这个屏障。
Go工具无法轻易访问C世界代码，这使得代码调试更加困难。辅助调试的运行时信息、行号、堆栈跟踪等信息一旦跨越屏障便消失得无影无踪。

>> 60.6　使用cgo代码的静态构建

>> 所谓静态构建就是指构建后的应用运行所需的所有符号、指令和数据都包含在自身的二进制文件当中，没有任何对外部动态共享库的依赖。静态构建出的二进制文件由于包含所有符号、指令和数据，因而通常要比非静态构建的应用大许多。默认情况下，Go没有采用静态构建。

>> 一个Go实现的文件服务器在默认情况下构建的例子：
// chapter9/sources/go-cgo/server.gofunc main() {    cwd, err := os.Getwd()    if err != nil {        log.Fatal(err)    }    srv := &http.Server{        Addr:    ":8000",        Handler: http.FileServer(http.Dir(cwd)),    }    log.Fatal(srv.ListenAndServe())}

>> $go build -o server_default server.go$ldd server_default    linux-vdso.so.1 (0x00007ffde17ef000)    libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f721b0f4000)    libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f721ad03000)    /lib64/ld-linux-x86-64.so.2 (0x00007f721b313000)
默认构建出的Go应用有多个对外部动态共享库的依赖，这些依赖是怎么产生的呢？Go应用由用户Go代码和Go标准库/运行时库组成，在这个程序中我们只能从标准库着手查找产生对外依赖的源头。
默认情况下，Go的运行时环境变量CGO_ENABLED=1（通过go env命令可以查看），即默认开启cgo，允许你在Go代码中调用C代码。Go的预编译标准库的.a文件也是在这种情况下编译出来的。在$GOROOT/pkg/linux_amd64中，我们遍历所有预编译好的标准库.a文件，并用nm输出每个.a文件中的未定义符号（状态为U），我们看到下面一些包是对外部有依赖的（动态链接）：
=> net.a    U _cgo_topofstack    U __errno_location    U getnameinfo    U _GLOBAL_OFFSET_TABLE_    U _cgo_topofstack    U __errno_location    U freeaddrinfo    U gai_strerror    U getaddrinfo    U _GLOBAL_OFFSET_TABLE_=> os/user.a    U _GLOBAL_OFFSET_TABLE_    U malloc    U _cgo_topofstack    U free    U getgrgid_r    U getgrnam_r    U getpwnam_r    U getpwuid_r    U _GLOBAL_OFFSET_TABLE_    U realloc    U sysconf    U _cgo_topofstack    U getgrouplist    U _GLOBAL_OFFSET_TABLE_...

>> 以os/user为例，在CGO_ENABLED=1，即cgo开启的情况下，os/user包中的lookup-UserXXX系列函数采用了cgo版本的实现。我们看到$GOROOT/src/os/user/cgo_lookup_unix.go源文件中的build tag中包含了+build cgo的构建指示器。这样在CGO_ENABLED=1的情况下该文件才会被编译，该文件中的cgo版本实现的lookupUser将被使用：
// $GOROOT/src/os/user/cgo_lookup_unix.go (Go 1.14)// +build aix darwin dragonfly freebsd !android,linux netbsd openbsd solaris// +build cgo,!osusergopackage user...func lookupUser(username string) (*User, error) {    var pwd C.struct_passwd    var result *C.struct_passwd    nameC := C.CString(username)    defer C.free(unsafe.Pointer(nameC))    ...}
这样一来，凡是依赖上述包的Go代码最终编译的可执行文件都要有外部依赖，这就是默认情况下编译出的server_default有外部依赖的原因（server_default至少依赖net.a）。

>> 这些cgo版本实现都有对应的Go版本实现。还是以user包为例，user包的lookupUser函数的Go版本实现如下：
// $GOROOT/src/os/user/lookup_unix.go (Go 1.14)// +build aix darwin dragonfly freebsd js,wasm !android,linux netbsd openbsd solaris// +build !cgo osusergofunc lookupUser(username string) (*User, error) {    f, err := os.Open(userFile)    if err != nil {        return nil, err    }    defer f.Close()    return findUsername(username, f)}
那么如何让编译器选择Go版本实现呢？从lookup_unix.go开头处的build tag中我们看到，通过设置CGO_ENABLED=0来关闭cgo是促使编译器选用Go版本实现的前提条件：
$CGO_ENABLED=0 go build -o server_static server.go$ldd server_static    not a dynamic executable$nm server_static |grep " U "
关闭cgo后，我们编译得到的server_static是一个静态编译的程序，它没有对外部的任何依赖。
如果使用go build的-x -v选项，你将看到Go编译器会重新编译依赖的包的静态版本（包括net等），并将编译后的.a（以包为单位）放入编译器构建缓存目录下（比如~/.cache/go-build/xxx，后续可复用），然后再静态链接这些版本。
那么有一个问题：在CGO_ENABLED=1这个默认值的情况下，是否可以实现纯静态链接呢？答案是可以的。其原理很简单，就是告诉链接器在最后的链接时采用静态链接方式，哪怕依赖的Go标准库中某些包使用的是C版本的实现。
根据Go官方文档（$GOROOT/cmd/cgo/doc.go），Go链接器支持两种工作模式：内部链接（internal linking）和外部链接（external linking）。

>> 如果用户代码中仅仅使用了net、os/user等几个标准库中的依赖cgo的包，Go链接器默认使用内部链接，而无须启动外部链接器（如gcc、clang等）。不过Go链接器功能有限，仅仅将.o和预编译好的标准库的.a写到最终二进制文件中。因此如果标准库中是在CGO_ENABLED=1的情况下编译的，那么编译出来的最终二进制文件依旧是动态链接的，即便在go build时传入-ldflags 'extldflags "-static"'也是如此，因为根本没有用到外部链接器。
$go build -o server_internal_linking -ldflags '-extldflags "-static"' server.go$ldd server_internal_linking    linux-vdso.so.1 (0x00007ffc58fab000)    libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007ff704544000)    libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007ff704153000)    /lib64/ld-linux-x86-64.so.2 (0x00007ff704763000)
而外部链接机制则是Go链接器将所有生成的.o都写到一个.o文件中，再将其交给外部链接器（比如gcc或clang）去做最终的链接处理。如果此时在go build的命令行参数中传入-ldflags ‘extldflags “-static”’，那么gcc/clang将会做静态链接，将.o中未定义（undefined）的符号都替换为真正的代码指令。可以通过-linkmode=external来强制Go链接器采用外部链接。还是以server.go的编译为例：
$go build -o server-external-linking  -ldflags '-linkmode "external" -extldflags "-static"' server.go$ldd server-external-linking    not a dynamic executable
就这样，我们在CGO_ENABLED=1的情况下也编译和构建出了一个纯静态链接的Go程序。如果你的用户层Go代码中使用了cgo代码，那么Go链接器将会自动选择外部链接机制。以本条开始处的how_cgo_works.go为例：
$go build -o how_cgo_works_static  -ldflags '-extldflags "-static"' how_cgo_works.go$ldd how_cgo_works_static    not a dynamic executable

>> 小结
本条探讨了cgo的用途和原理、在Go中如何访问C语言的类型并分析了cgo的使用开销，最后了解了如何在开启cgo的情况下实现Go程序的静态构建。
本条要点：
◦  了解cgo的使用场景，如非必须，尽量不使用cgo；
◦  了解构建带有cgo的程序的原理；
◦  掌握Go中访问C元素的方法；
◦  cgo是一柄“双刃剑”，要使用cgo，就要先了解你要为此付出的开销；
◦  了解cgo代码的构建要点：
▪  你的程序用了哪些标准库包？如果是net、os/user等几个依赖cgo实现的包之外的Go包，那么你的程序默认将是纯静态的，不依赖任何C运行时库等外部动态链接库；
▪  如果使用了net这样的包含cgo实现版本的标准库包，那么CGO_ENABLED的值将影响你的程序编译后的属性（是静态的还是动态链接的）；
▪  如果CGO_ENABLED=1且仅使用了net、os/user等依赖cgo实现的包，那么internal linking机制将被默认采用，编译过程不会采用静态链接；但如若依然要强制静态编译，需向-ldflags '-linkmode "external" -extldflags "-static"'传递go build命令。


◆ 第十部分 工具链与工程实践

>> 第十部分工具链与工程实践

>> 第61条使用module管理包依赖

>> 使用go module管理包依赖已经成为Go项目包依赖管理的唯一标准，并成为高质量Go代码的必要条件。

>> 61.1　Go语言包管理演进回顾

>> 1. go getGo在构建设计方面深受Google内部开发实践的影响，比如go get的设计就深受Google内部单一代码仓库（single monorepo）和基于主干（trunk/mainline）的开发模型的影响，采用了只获取主干代码和版本无感知的设计策略

>> Gopher希望自己项目所依赖的第三方包能受自己的控制，而不是随意变化，于是godep、gb、glide等一批第三方包管理工具便出现了。以当时（Go 1.5版本之前）应用最为广泛的godep为例。为了能让第三方依赖包稳定下来，实现项目的可重现构建，godep将项目当前依赖包的版本信息记录在Godeps/Godeps.json中，并将依赖包的相关版本存放在Godeps/_workspace中。在编译源码时（godep go build），godep通过临时修改GOPATH环境变量的方法让Go编译器使用缓存在Godeps/_workspace下的项目依赖的特定版本的第三方包，这样保证了项目不再受制于所依赖的第三方包主分支上的最新代码变动。

>> 不过，godep的版本管理本质上是通过缓存第三方库的某个revision的快照实现的，这种方式依然让人感觉难于管理。同时，通过对GOPATH的“偷梁换柱”的方式实现使用Godeps/_workspace中的第三方库的快照进行编译也无法使用Go原生编译器，项目构建必须使用godep go xxx来进行。为此，Go进一步引入vendor机制来减少Gopher在包管理问题上的心智负担。

>> 2. vendor机制Go核心团队一直在关注Go的包依赖问题，并在Go 1.5版本实现自举（变动较大）的情况下，依然在1.5版本中推出了vendor机制。vendor机制是Russ Cox在Go 1.5发布前期以试验特性身份紧急加入Go中的。vendor标准化了项目依赖的第三方库的存放位置（不再像godep那样需要Godeps/_workspace了），同时也无须对GOPATH环境变量进行“偷梁换柱”，Go编译器将原生优先感知和使用vendor目录下缓存的第三方包版本。即便有了vendor的支持，vendor内第三方依赖包的代码的管理（包括添加、更新和删除）也依旧是不规范的：要么是手动的，要么是借助godep这样的第三方包管理工具。自举后的Go语言项目本身也引入了vendor

>> 3. dep2016年GopherCon技术大会后，Go官方组织成立了一个委员会，该委员会旨在改善Go包管理，共同应对Go在包依赖管理上遇到的各种问题。经过各种开脑洞和讨论后，该委员会在若干月后发布了“包依赖管理技术提案”（Package Management Proposal），并启动了最有可能被接纳为官方包管理工具的项目dep（https://github.com/golang/dep）的设计和开发。2017年年初，dep项目正式对外开放。2017年5月，dep发布了v0.1.0版本，并进入alpha测试阶段。

>> 4. vgo（go module的前身）2018年年初，正当广大Gopher认为dep将顺理成章地升级为Go官方工具链的一部分的时候，Russ Cox在其个人博客上连续发表了7篇文章[1]，系统阐述了Go团队解决包依赖管理问题的技术方案：vgo。vgo的主要思路包括语义导入版本（Semantic Import Versioning）、最小版本选择（Minimal Version Selection）和引入Go module概念等。这7篇文章的发布引发了Go社区的激烈争论，尤其是最小版本选择与目前主流的依赖版本选择方法相悖以及在包导入路径上引入版本号让很多传统Go包管理工具的维护者不满，当然也包括“准官方包管理工具”dep的作者和拥趸。

>> 2018年5月，Russ Cox的vgo技术提案被接纳，后Russ Cox将vgo的代码合并到Go项目主干，并将这套机制正式命名为go module。由于vgo项目本身就是一个实验原型项目，合并到主干后，vgo这个术语以及vgo项目的使命就此结束，后续Go module机制将直接在Go项目主干上继续演进。Go module的诞生也意味着dep项目生命周期的结束。[1]https://research.swtch.com/vgo

>> 61.2　Go module：Go包依赖管理的生产标准

>> 1. Go module定义以及包依赖管理的工作模式在chapter10/sources/go-module下建立hello目录（注意：此时$GOPATH=~/go，显然hello目录并不在GOPATH下面）。hello.go的代码如下：// hello.gopackage mainimport "bitbucket.org/bigwhite/c"func main() {    c.CallC()}在GO111MODULE="off"的前提下，构建hello.go这个源码文件：$go run hello.gohello.go:3:8: cannot find package "bitbucket.org/bigwhite/c" in any of:    $GOROOT/src/bitbucket.org/bigwhite/c (from $GOROOT)    /Users/tonybai/Go/src/bitbucket.org/bigwhite/c (from $GOPATH)构建错误！错误原因很明了：在本地的GOPATH下并没有找到bitbucket.org/bigwhite/c路径下的包c。传统上修复这个问题的方法是手动将包c通过go get下载到本地，go get会自动下载包c所依赖的包d：$ go get bitbucket.org/bigwhite/c$ go run hello.gocall C: master branch    --> call D:     call D: master branch    --> call D end这种传统的也是我们最熟悉的Go编译器从$GOPATH下（及vendor目录下）搜索目标程序依赖包的模式称为gopath mode。

>> GOPATH是Go早期设计的产物，在Go语言快速发展的今天，人们日益发现GOPATH似乎不那么重要了，尤其是在引入vendor机制以及诸多包管理工具之后。GOPATH的设置还会让Go语言新手感到些许困惑，提高了入门的门槛。Go核心团队一直在寻求“去GOPATH”的方案，当然这一过程是循序渐进的。从Go 1.8版本开始，如果开发者没有显式设置GOPATH，Go会赋予GOPATH一个默认值（比如：在Linux上这个默认值为$HOME/go）。虽说不用再设置GOPATH，但GOPATH还是真实存在的，它在Go工具链中依旧发挥着至关重要的作用。Go module的引入在“去GOPATH”之路上更进了一步，它引入了一种新的依赖管理工作模式：module-aware模式。在该模式下，通常一个仓库的顶层目录下会放置一个go.mod文件，每个go.mod文件唯一定义了一个module。一个module就是由一组相关包组成的一个独立的版本单元。module是有版本的，module下的包也就有了版本属性。而放置go.mod文件的目录被称为module root目录。module root目录及其子目录下的所有Go包均归属于该module，除了那些自身包含go.mod文件的子目录。虽然Go支持在一个仓库中定义多个module，但通常Go惯用法是一个仓库只定义一个module。非常不建议在一个仓库中定义多个module的用法，因为这不仅会给你自己带来麻烦，也很大可能会让你的module的使用者感到困惑。

>> 在module-aware模式下，Go编译器将不会在GOPATH及vendor下搜索目标程序依赖的第三方Go包。我们来看一下在module-aware模式下hello.go的构建过程。

>> Go编译器并没有使用之前已经下载到GOPATH下的bitbucket.org/bigwhite/c包和bitbucket.org/bigwhite/d包，而是重新下载了这两个包并成功编译。

>> Go编译器分析出了hello module的依赖包，将其写入go.mod的require区域。由于c、d两个包均没有发布版本（建立其他分支或打标签），因此Go编译器使用了包c和d的当前最新版，并以伪版本（pseudo-version）的形式作为这两个包的当前版本号。此外，hello module并没有直接依赖包d，并且bitbucket.org/bigwhite/c下没有建立go.mod、记录包c的依赖，因此在d包的记录后面用注释标记了indirect，即间接依赖。

>> 在module-aware模式下，Go编译器将下载的依赖包缓存在$GOPATH/pkg/mod下

>> GO111MODULE这个临时的环境变量就是go module特性的试验开关。GO111MODULE有三个值——auto、on和off，默认值为auto。GO111MODULE的值会直接影响Go编译器的包依赖管理工作模式的选择：是gopath模式还是module-aware模式。

>> ◦  当GO111MODULE的值为off时，go module试验特性关闭，Go编译器会始终使用gopath模式，即无论要构建的源码目录是否在GOPATH路径下，Go编译器都会在传统的GOPATH和vendor目录下搜索目标程序依赖的Go包；

>> ◦  当GO111MODULE的值为on时，go module试验特性始终开启，Go编译器会始终使用module-aware模式，即不管要构建的源码目录是否在GOPATH路径下，Go编译器都不会在传统的GOPATH和vendor目录下搜索目标程序依赖的Go包，而是在go module的缓存目录（默认$GOPATH/pkg/mod）下搜索对应版本的依赖包；
◦  当GO111MODULE的值为auto时（不显式设置即为auto），使用gopath模式还是module-aware模式取决于要构建的源码目录所在位置以及是否包含go.mod文件。如果要构建的源码目录不在以GOPATH/src为根的目录体系下且包含go.mod文件（两个条件缺一不可），那么Go编译器将使用module-aware模式；否则使用传统的gopath模式。

>> 在Go 1.13中，module-aware模式的优先级得到提升，虽然GO111MODULE的默认值依然为auto，但auto值下Go编译器的行为模式发生了变化：无论是在GOPATH/src下还是在GOPATH之外的仓库中，只要目录下有go.mod，Go编译器都会使用module-aware模式来管理包依赖。

>> 在Go 1.14中，go module的运作机制、命令及其参数形式、行为特征已趋稳定，可用于生产环境了。GO111MODULE的值对包依赖管理工作模式的选择及行为模式变动如下。
◦  在module-aware模式下，如果go.mod中go version是Go 1.14及以上，且当前仓库顶层目录下有vendor目录，那么Go工具链将默认使用vendor（-mod=vendor）中的包，而不是module cache中的（$GOPATH/pkg/mod下）。同时在这种模式下，Go工具会校验vendor/modules.txt与go.mod文件以确保它们保持同步；如果一定要使用module cache中的包进行构建，则需要为Go工具链显式传入-mod=mod ，比如go build -mod=mod ./...。
◦  在module-aware模式下，如果没有建立go.mod或Go工具链，无法找到go.mod，那么你必须显式传入要处理的Go源文件列表，否则Go工具链将需要你明确建立go.mod。比如：在一个没有go.mod的目录下，要编译hello.go，我们需要使用go build hello.go，即hello.go需要显式放在命令后面。如果你执行go build .，就会得到类似下面的错误信息：
$go build .go: cannot find main module, but found .git/config in /Users/tonybai    to create a module there, run:    cd .. && go mod init
也就是说，在没有go.mod的情况下，Go工具链的功能是受限的。

>> 在Go 1.16中，Go module-aware模式成为默认模式，即GO111MODULE的值默认为on。

>> 2. go module的依赖包版本的选择
（1）build list和main module

>> 我们可以通过下面的命令查看到这些信息：
$go list -m -json all

>> go list -m输出的信息被称为build list，也就是构建当前module所需的所有相关包信息的列表。在输出信息中我们看到"Main"：true这一行信息，它标识当前的module为main module。main module即go build命令执行时所在当前目录所归属的那个module。go命令会在当前目录、当前目录的父目录、父目录的父目录等下面寻找go.mod文件，所找到的第一个go.mod文件对应的module即为main module。如果没有找到go.mod，go命令会提示下面的错误信息：
$go build test/hello/hello.gogo: cannot find main module root; see 'go help modules'

>> 当然我们也可以使用下面的命令来简略输出build list：
$go list -m all

>> （2）go.mod中的require

>> 清除掉$GOPATH/pkg/mod目录下的内容（可用go clean -modcache命令）

>> 可以通过go mod -require来显式更新go.mod文件中的require段的信息：
$go mod -require=bitbucket.org/bigwhite/c@v1.0.0$go mod -require=bitbucket.org/bigwhite/d@v1.1.0

>> go mod还支持query表达式，比如：
$go mod -require='bitbucket.org/bigwhite/c@>=v1.1.0'

>> （3）最小版本选择

>> 当前其他主流语言以及go module之前的Go包依赖管理工具选择的算法都试图识别任何依赖项的“最新最大”（latest greatest）版本。在语义版本控制（sematic versioning）被正确应用并且得到遵守的情况下，这是有道理的。在这样的情况下，依赖项的“最新最大”版本应该是最稳定和最安全的版本，并且应与较早版本具有向后兼容性。至少在相同的主版本（major version）依赖树中是如此。

>> Go则采用了最小版本选择（Minimal Version Selection，MVS）算法。

>> （4）依赖一个包的不同版本

>> 按照语义化版本规范，当代码出现与之前版本的不兼容性变化时，需要升级版本中的major版本号。而Go module允许在包导入路径中带有major版本号，比如："import github.com/user/repo/v2"表示所用的包为v2版本下的实现。甚至可以在一个项目中同时依赖同一个包的不同版本。依旧使用上面的例子来实操一下如何在hello module中使用包d的两个版本的代码。

>> 按照语义化版本规范，当代码出现与之前版本的不兼容性变化时，需要升级版本中的major版本号。而Go module允许在包导入路径中带有major版本号，比如："import github.com/user/repo/v2"表示所用的包为v2版本下的实现。甚至可以在一个项目中同时依赖同一个包的不同版本。

>> 依旧使用上面的例子来实操一下如何在hello module中使用包d的两个版本的代码。首先需要为包d建立module文件Go.mod，并标识出当前的module为bitbucket.org/bigwhite/d/v2。（为了保持与v0/v1各自独立演进，可通过建立分支的方式来实现，然后基于该版本打v2.0.0标签。）// bitbucket.org/bigwhite/d$cat go.modmodule bitbucket.org/bigwhite/d/v2改造一下hello module，这次导入包d的v2版本：// sources/go-module/hello/hello.gopackage mainimport "bitbucket.org/bigwhite/c"import "bitbucket.org/bigwhite/d/v2"func main() {    c.CallC()    d.CallD()}清理hello module的go.mod，仅保留对包c的依赖约束：// sources/go-module/hello/go.modmodule hellorequire (    bitbucket.org/bigwhite/c v1.3.0)重新构建hello module：$go build hello.gogo: finding bitbucket.org/bigwhite/c v1.3.0go: finding bitbucket.org/bigwhite/d v1.2.0go: downloading bitbucket.org/bigwhite/c v1.3.0go: downloading bitbucket.org/bigwhite/d v1.2.0go: finding bitbucket.org/bigwhite/d/v2 v2.0.0go: downloading bitbucket.org/bigwhite/d/v2 v2.0.0$cat go.modmodule hellorequire (    bitbucket.org/bigwhite/c v1.3.0    bitbucket.org/bigwhite/d/v2 v2.0.0)$./hellocall C: v1.3.0    --> call D:     call D: v1.2.0    --> call D endcall D: v2.0.0我们看到包c依然使用的是d的v1.2.0版本，而main中使用的包d已经是v2.0.0版本了。

>> 3. Go module与vendor

>> 4. go.sum

>> go.sum记录每个依赖库的版本和对应内容的校验和。每当增加一个依赖项时，如果go.sum中没有，则会将该依赖项的版本和内容校验和添加到go.sum中。go命令会使用这些校验和与缓存在本地的依赖包副本元信息进行比对校验。

>> 如果没有“恶意”修改，则verify会报成功：# go mod verifyall modules verified

>> go.sum文件不应被用于理解依赖关系，它只是一个元信息数据库。随着项目依赖的演进与变更，go.sum文件中会存储一个module的多个版本信息，即使某个版本已经不再被当前module所依赖。

>> 5. 清理go.mod

>> 在将代码提交/推回存储库之前，请运行go mod tidy以确保module文件（go.mod）是最新且准确的。在本地构建、运行或测试代码将随时影响Go对module文件中内容的更新。运行go mod tidy可以确保项目具有所需内容的准确且完整的快照，这对团队中的其他人或持续集成/交付环境大有裨益。

>> 6. 升降级依赖关系

>> 在module-aware模式下，由于go.mod和go.sum都是由Go工具链维护和管理的，不建议手动修改go.mod中require中的包版本号。我们可以通过go get命令来实现我们的目的。

>> 我们可以先用go list命令查看一下某个module有哪些版本可用。以gocmpp这个项目（github.com/bigwhite/gocmpp）依赖的golang.org/x/text为例：$go list -m -versions golang.org/x/textgolang.org/x/text v0.1.0 v0.2.0 v0.3.0 v0.3.1 v0.3.2 v0.3.3

>> 如果要将gocmpp依赖的golang.org/x/text从v0.3.0降级到v0.1.0，可以在gocmpp的项目顶层目录下执行下面的命令：# go get golang.org/x/text@v0.1.0go: finding golang.org/x/text v0.1.0go: downloading golang.org/x/text v0.1.0

>> 在module-aware模式下，go get-u会将当前module的所有依赖的包版本（无论直接依赖还是间接依赖）都升级到最新的兼容版本。

>> 如果仅升级patch号，而不升级minor号，可以使用go get -u=patch A。比如：如果golang. org/x/text有v0.1.1版本，那么go get -u=patch golang.org/x/text会将go.mod中text后面的版本号变为v0.1.1，而不是v0.3.3。并且，处于module-aware模式下的go get在更新某个依赖（无论是升版本还是降版本）时，会自动计算并更新其间接依赖的包的版本。

>> 61.3　Go module代理

>> 1. GOPROXY环境变量

>> go get命令默认都是直接从代码托管服务器（如GitHub、GitLab等）下载Go module的。但是在Go 1.11中，我们可以通过设置GOPROXY环境变量让Go命令从其他module代理服务器下载module。比如：export GOPROXY=https://goproxy.cn一旦上面的设置生效，后续Go命令就会通过Go module下载协议与module代理交互下载特定版本的module。有了module proxy，之前的那些包无法通过go get命令成功下载（如golang.org/x下面的包）或者获取缓慢（比如：有时GitHub访问很慢）的问题就都得到了解决。同时，module proxy也让Gopher在module和包的获取上增加了一定的控制和干预能力。

>> Go核心团队也希望Go世界能有一个像Node.js那样的中心化的module仓库为大家提供服务，于是在Go 1.13中将https://proxy.golang.org设为GOPROXY环境变量的默认值之一，这也是Go提供的官方module代理服务。

>> 同样是从Go 1.13版本开始，GOPROXY环境变量支持设置多个代理的列表（多个代理之间采用逗号分隔）。Go编译器会按顺序尝试从列表中的代理服务获取依赖包数据，当有代理服务不可达或者返回的HTTP状态码既不是404也不是410时，Go会终止数据获取，否则会尝试向列表中的下一个代理服务获取数据。在Go 1.13中，GOPROXY的默认值为https://proxy.golang.org,direct。当官方代理返回404或410时，Go编译器会尝试直接连接依赖module的代码托管站点以获取数据。但是当列表中的代理服务返回其他错误时，Go命令不会向GOPROXY列表中的下一个值所代表的代理服务发起请求。这种行为模式没能让所有Gopher满意，很多Gopher认为Go工具链应该向后面的代理服务请求，直到所有代理服务都返回失败。Go 1.15版本满足了Go社区的需求，新增以管道符“|”为分隔符的代理列表值。如果GOPROXY配置的代理服务列表值以管道符分隔，则无论某个代理服务返回什么错误码，Go命令都会向列表中的下一个代理服务发起新的尝试请求。（Go 1.15版本中GOPROXY环境变量的默认值依旧为https://proxy.golang.org,direct。）

>> 下面是目前世界各地的一些知名module代理服务。proxy.golang.org：Go官方提供的module代理服务。mirrors.tencent.com/go：腾讯公司提供的module代理服务。mirrors.aliyun.com/goproxy：阿里云提供的module代理服务。goproxy.cn：开源module代理，由七牛云提供主机，是目前中国最为稳定的module代理服务。goproxy.io：开源module代理，由中国Go社区提供的module代理服务。Athens：开源module代理，可基于该代理自行搭建module代理服务。

>> 2. GOSUMDB

>> 在日常开发中，特定module版本的校验和永远不会改变。每次运行或构建时，Go命令都会通过本地的go.sum检查其本地缓存副本的校验和是否一致。如果校验和不匹配，则Go命令将报告安全错误，并拒绝运行构建或运行。在这种情况下，重要的是找出正确的校验和，确定是go.sum错误还是下载的代码有误。如果go.sum中尚未包含已下载的module，并且该模块是公共module，则go命令将查询Go校验和数据库以获取正确的校验和数据并存入go.sum。如果下载的代码与校验和不匹配，则Go命令将报告不匹配并退出。Go 1.13提供了GOSUMDB环境变量来配置Go校验和数据库的服务地址（和公钥），其默认值为"sum.golang.org"，这也是Go官方提供的校验和数据库服务（也可以使用sum.golang.google.cn）。出于安全考虑，建议保持GOSUMDB开启。但如果因为某些因素无法访问GOSUMDB，也可以通过下面的命令将其关闭：$go env -w GOSUMDB=off在GOSUMDB关闭后，Go编译器就仅能使用本地的go.sum进行包的校验和校验了。

>> 3. 获取私有module

>> 但是如果依赖的是企业内部代码服务器或公共代码托管站点上的私有module，通过配置公共module代理服务来获取数据显然不能达到预期效果。以我在GitHub上建立的私有仓库github.com/bigwhite/privatemodule为例（实验环境的GOPROXY设置为https://goproxy.cn,direct）：

>> 在本地没有缓存GitHub用户名/密码的情况下，go get会报上述错误。我们可以使用.netrc的方式配置访问GitHub的凭证。创建～/.netrc，其内容如下：// ~/.netrcmachine github.comlogin bigwhitepassword [personal access tokens]GitHub的personal access tokens可以在https://github.com/settings/tokens下自助生成。配置好~/.netrc，再来获取privatemodule

>> Go 1.13提供了GOPRIVATE环境变量用于指示哪些仓库下的module是私有的，不需要通过GOPROXY下载，也不需要通过GOSUMDB验证其校验和。不过要注意的是，GONOPROXY和GONOSUMDB可以覆盖GOPRIVATE变量中的设置，因此设置时要谨慎

>> 可以单独设置GOPRIVATE来实现go get不使用GOPROXY下载privatemodule并且无须GOSUMDB校验：export GOPRIVATE=github.com/bigwhite/privatemodule

>> 除了使用～/.netrc实现配置访问github.com的凭证信息，我们也可以通过SSH方式访问GitHub上的私有仓库。

>> ~/.gitconfig中添加下面两行配置：// ~/.gitconfig[url "ssh://git@github.com/"]    insteadOf = https://github.com/其他操作与通过.netrc获取私有module的步骤一样，这里就不赘述了。

>> 61.4　升级module的主版本号

>> 1. go module的语义导入版本

>> 在“Semantic Import Versioning”一文中，Russ Cox说明了Go import包兼容性的总原则：如果新旧版本的包使用相同的导入路径，那么新包与旧包是兼容的。也就是说，如果新旧两个包不兼容，那么应该采用不同的导入路径。因此，Russ Cox采用了将主版本作为导入路径一部分的设计。这种设计支持在同一个项目的Go源文件中导入同一个包的不同版本：同一个包虽然包名相同，但是导入路径不同。vN作为导入路径的一部分将用于区分包的不同版本。同时在同一个源文件中，我们可以使用包别名来区分同一个包的不同版本，比如：import (    "github.com/bigwhite/foo/bar"    barV2 "github.com/bigwhite/foo/v2/bar")go module的这种设计虽然没有给Go包的使用者带来多少额外工作，但却给Go包的维护者带来了一定的复杂性，他们需要考虑在go module机制下如何升级自己的go module的主版本号（major version）。稍有不慎，很可能就会导致自身代码库的混乱或者包使用者侧无法通过编译或执行行为混乱。

>> 2. 使用major branch方案

>> 不过在最新的go module机制中从pre-v1到v1还算不上主版本升级，接下来看看foo包的作者应该如何对modules-major-branch module进行不兼容的升级：v1→v2。当modules-major-branch module即将进行不兼容升级时，一般会为当前版本建立维护分支（比如v1分支，并在v1分支上继续对v1版本进行维护和打补丁），然后在master分支上进行不兼容的修改。$ git checkout -b v1$ git checkout master$ cat foo/foo.gopackage fooimport "fmt"func Foo2() {    fmt.Println("foo.Foo2 of module: bitbucket.org/bigwhite/modules-major-branch v2.0.0")}从以上代码中可以看到，在master分支上，我们删除了foo包中的Foo函数，新增了Foo2函数。但仅做这些还不够。前文提到过一个原则：如果新旧两个包不兼容，那么应该采用不同的导入路径。我们对modules-major-branch module进行了不兼容的修改，modules-major-branch module要有不同的导入路径，因此需要修改modules-major-branch module的module路径：$ cat go.modmodule bitbucket.org/bigwhite/modules-major-branch/v2go 1.12$ git tag v2.0.0$ git push --tag origin master我们在module根路径后面加上了v2，并基于master建立了标签 v2.0.0。我们再来看看消费者端应该如何应对modules-major-branch module的不兼容修改。如果消费者要使用最新的Foo2函数，我们需要对消费者项目的main.go做出如下改动：//modules-major-branch-test/main.gopackage mainimport (    "bitbucket.org/bigwhite/modules-major-branch/v2/foo")func main() {    foo.Foo2()}接下来我们不需要手动修改modules-major-branch-test的go.mod中的依赖，直接运行go run即可：$ go run main.gogo: finding bitbucket.org/bigwhite/modules-major-branch/v2/foo latestgo: finding bitbucket.org/bigwhite/modules-major-branch/v2 v2.0.0go: downloading bitbucket.org/bigwhite/modules-major-branch/v2 v2.0.0go: extracting bitbucket.org/bigwhite/modules-major-branch/v2 v2.0.0foo.Foo2 of module: bitbucket.org/bigwhite/modules-major-branch v2.0.0我们看到Go编译器会自动发现依赖变更，下载对应的包并更新go.mod和go.num

>> modules-major-branch-test此时已经不再需要依赖modules-major-branch的v1.0.0版本，我们可以通过go mod tidy清理一下go.mod中的依赖

>> 后续modules-major-branch可以在master分支上持续演进，直到又有不兼容改动时，可以基于master建立v2维护分支，同时master分支将升级为v3版本。

>> 在该方案中，对包的作者而言，升级主版本号需要：在go.mod中升级module的根路径，增加vN；建立vN.x.x形式的标签（可选，如果不打标签，Go会在消费者的go.mod中使用伪版本号，比如bitbucket.org/bigwhite/modules-major-branch/v2 v2.0.0-20190603050009-28a5b8da279e）。如果modules-major-branch内部有相互的包引用，那么在升级主版本号的时候，这些包的导入路径也要增加vN，否则就会出现在高版本号的代码中引用低版本号包代码的情况，这也是包作者极容易忽略的事情。

>> github.com/marwan-at-work/mod是一个为module作者提供的升降级主版本号的工具，它可以帮助包作者方便地自动修改项目内所有源文件中的导入路径。有Gopher已经提出希望Go官方提供升降级的支持（https://github.com/golang/go/issues/32014），但目前Go核心团队尚未明确是否增加。对于包的消费者而言，升级依赖包的主版本号，只需要在导入包时在导入路径中增加vN即可，当然代码中也要针对不兼容的部分进行修改，然后go工具就会自动下载相关包了。

>> 3. 使用major subdirectory方案Go module还提供了一种用起来不那么自然的方案，那就是利用子目录分割不同主版本。在这种方案下，如果某个module目前已经演进到v3版本，那么这个module所在仓库的目录结构应该是这样的：$ tree modules-major-subdirmodules-major-subdir├── bar│   └── bar.go├── go.mod├── v2│   ├── bar│   │   └── bar.go│   └── go.mod└── v3    ├── bar    │   └── bar.go    └── go.mod这里直接用vN作为子目录名字，在代码仓库中将不同版本module放置在不同的子目录中，这样即便不建分支、不打标签，Go编译器通过子目录名也能找到对应的版本。以上面的v2子目录为例，该子目录下的go.mod如下：$ cat go.modmodule bitbucket.org/bigwhite/modules-major-subdir/v2go 1.12v3也是类似。在各自的子目录中，module的根路径都是带有vN扩展的。

>> 这种通过子目录方式来实现主版本升级的方式似乎更简单一些，但笔者总感觉这种方式有些“怪”，尤其是在与分支和标签交叉使用时可能会带来一些困惑，其他主流语言也鲜有使用这种方式进行主版本升级的。一旦使用这种方式，利用Git等工具在各个不同主版本之间自动同步代码变更将变得很困难。另外和major branch方案一样，如果module内部有相互的包引用，那么在升级module的主版本号的时候，这些包的导入路径也要增加vN，否则也会出现在高版本号的代码中引用低版本号包代码的情况。

>> 本条要点：了解Go包依赖管理的演进历史以及不同方案的问题；掌握Go module的定义及工作模式；掌握Go module的核心思想，即语义导入版本和最小版本选择；掌握Go module的常用操作命令；熟悉Go module代理的工作原理及相关环境变量设置；掌握Go module主版本号升级的方案、步骤及注意事项。

>> 第62条 构建最小Go程序容器镜像

>> 62.1　镜像：继承中的创新

>> 62.2　镜像是个筐：初学者的认知“镜像是个筐，什么都往里面装。”

>> 62.3　理性回归：builder模式的崛起

>> 在Docker使用者在接触新技术初期的热情冷却下来之后，迎来了理性的回归。根据图62-2的分层镜像，我们发现最终镜像中包含构建环境是多余的，只需要在最终镜像中包含足够支撑httpd应用运行的运行环境即可，而Base Image就可以满足。于是我们应该如图62-3所示，去除不必要的中间层。[插图]图62-3　去除不必要的中间层现在问题来了！如果不在同一镜像中完成应用构建，那么在哪里、由谁来构建应用呢？至少有两种方法：在本地构建并复制到镜像中；借助构建者镜像（builder image）构建。本地构建有很多局限性，比如本地环境无法复用、无法很好地融入持续集成/持续交付流水线等。借助builder image进行构建成为Docker社区的最佳实践，Docker官方为此推出了各种主流编程语言（比如Go、Java、Python及Ruby等）的官方基础镜像（base image）。借助builder image进行镜像构建的流程如图62-4所示。[插图]图62-4　借助builder image进行镜像构建的流程图整个目标镜像的构建被分为两个阶段：第一阶段，构建负责编译源码的构建者镜像；第二阶段，将第一阶段的输出作为输入，构建出最终的目标镜像。我们选择golang:1.9.2作为builder base image，构建者镜像的Dockerfile如下：// chapter10/sources/tiny-image/Dockerfile.buildFROM golang:1.9.2WORKDIR /go/srcCOPY ./httpserver.go .RUN go build -o httpd ./httpserver.go执行构建：$ docker build -t repodemo/httpd-builder:latest -f Dockerfile.build .

>> 构建好的应用程序httpd被放在了镜像repodemo/httpd-builder中的/go/src目录下，我们需要一些“胶水”命令来连接两个构建阶段，这些命令将httpd从构建者镜像中取出并作为下一阶段构建的输入：$ docker create --name extract-httpserver repodemo/httpd-builder$ docker cp extract-httpserver:/go/src/httpd ./httpd$ docker rm -f extract-httpserver$ docker rmi repodemo/httpd-builder通过上面的命令，我们将编译好的httpd程序复制到了本地。下面是目标镜像的Dockerfile：// chapter10/sources/tiny-image/Dockerfile.targetFrom ubuntu:14.04COPY ./httpd /root/httpdRUN chmod +x /root/httpdWORKDIR /rootENTRYPOINT ["/root/httpd"]接下来构建目标镜像：$ docker build -t repodemo/httpd:latest -f Dockerfile.target .我们来看看这个镜像的“体格”：$ docker imagesREPOSITORY           TAG         IMAGE ID         CREATED             SIZErepodemo/httpd       latest      e3d009d6e919     12 seconds ago      200MB200MB！目标镜像的大小才不到原来的一半。

>> 62.4　“像赛车那样减重”：追求最小镜像

>> 如图62-5所示，前面我们构建出的镜像已经缩小到200MB，但这还不够。200MB的“体格”在我们的网络环境下缓存和传输仍然很难令人满意。我们要为镜像进一步减重，减到尽可能小，就像赛车那样，为了减轻重量将所有不必要的东西都拆掉：仅保留能支撑我们的应用运行的必要库、命令，其余的一律不纳入目标镜像。当然这不仅仅是基于尺寸上的考量，小镜像还有额外的好处，比如：内存占用小，启动速度快，更加高效；不会因其他不必要的工具、库的漏洞而被攻击，减少了攻击面，更加安全。

>> 一般应用开发者不会从头构建自己的base image以及目标镜像，而会挑选合适的base image。如图62-6所示，一些蝇量级甚至是草量级的官方base image的出现为这种情况提供了条件。

>> alpine是另一种蝇量级base image，它使用了比glibc更小、更安全的musl libc库。不过和busybox相比，alpine体格略大。除了因为musl比uClibc大一些之外，alpine还在镜像中添加了自己的包管理系统apk。开发者可以使用apk在基于alpine的镜像中添加需要的包或工具。因此，对于普通开发者而言，alpine显然是更佳的选择。不过alpine使用的libc实现为musl，与基于glibc上编译出来的应用程序不兼容。如果直接将前面构建出的httpd应用塞入alpine，在容器启动时会遇到下面的错误（因为加载器找不到glibc这个动态共享库文件）：standard_init_linux.go:185: exec user process caused "no such file or directory"对于Go程序来说，我们可以静态编译的程序，但一旦采用静态编译，也就意味着我们将失去一些libc提供的原生能力，比如：在Linux上，你无法使用系统提供的DNS解析能力，只能使用Go自实现的DNS解析器（具体可参考第60条）。我们还可以采用基于alpine的builder image，golang base image就提供了alpine版本。我们就用这种方式构建出一个基于alpine base image的极小目标镜像

>> 新建两个用于alpine版本目标镜像构建的Dockerfile：Dockerfile.build.alpine和Dockerfile.target.alpine：// chapter10/sources/tiny-image/Dockerfile.build.alpineFROM golang:alpineWORKDIR /go/srcCOPY ./httpserver.go .RUN go build -o httpd ./httpserver.go// chapter10/sources/tiny-image/Dockerfile.target.alpineFrom alpineCOPY ./httpd /root/httpdRUN chmod +x /root/httpdWORKDIR /rootENTRYPOINT ["/root/httpd"]构建builder镜像：$ docker build -t repodemo/httpd-alpine-builder:latest -f Dockerfile.build.alpine .$ docker imagesREPOSITORY                      TAG      IMAGE ID       CREATED              SIZErepodemo/httpd-alpine-builder   latest   d5b5f8813d77   About a minute ago   275MB执行“胶水”命令：$ docker create --name extract-httpserver repodemo/httpd-alpine-builder$ docker cp extract-httpserver:/go/src/httpd ./httpd$ docker rm -f extract-httpserver$ docker rmi repodemo/httpd-alpine-builder构建目标镜像：$ docker build -t repodemo/httpd-alpine -f Dockerfile.target.alpine .$ docker imagesREPOSITORY              TAG      IMAGE ID       CREATED          SIZErepodemo/httpd-alpine   latest   895de7f785dd   13 seconds ago   16.2MB16.2MB！目标镜像的大小降为不到原来的十分之一，我们得到了预期的结果！

>> 62.5　“要有光”：对多阶段构建的支持

>> 虽然我们实现了目标镜像的最小化，但是整个构建过程却十分烦琐，我们需要准备两个Dockerfile，需要准备“胶水”命令，需要清理中间产物等。作为Docker用户，我们希望用一个Dockerfile解决所有问题，于是就有了Docker引擎对多阶段构建（multi-stage build）的支持。注意多阶段构建这个特性只有Docker 17.05.0-ce及以后的版本才支持。现在我们就按照“多阶段构建”的语法将上面的Dockerfile.build.alpine和Dockerfile.target.alpine合并到一个Dockerfile中：// chapter10/sources/tiny-image/Dockerfile.multistageFROM golang:alpine as builderWORKDIR /go/srcCOPY httpserver.go .RUN go build -o httpd ./httpserver.goFrom alpine:latestWORKDIR /root/COPY --from=builder /go/src/httpd .RUN chmod +x /root/httpdENTRYPOINT ["/root/httpd"]Dockerfile的语法还是很简明和易理解的。即使是第一次看到这个语法，你也能大致猜出六成含义。与之前Dockefile最大的不同在于，在支持多阶段构建的Dockerfile中我们可以写多个From baseimage的语句，每个From语句开启一个构建阶段，并且可以通过as语法为此阶段构建命名（比如这里的builder）。我们还可以通过COPY命令在两个阶段构建产物之间传递数据，比如这里传递的httpd程序，这项工作之前我们是使用“胶水”代码完成的。

>> 构建目标镜像：$ docker build -t repodemo/httpd-multi-stage -f Dockerfile.multistage .$ docker imagesREPOSITORY                   TAG      IMAGE ID       CREATED         SIZErepodemo/httpd-multi-stage   latest   35e494aa5c6f   2 minutes ago   16.2MB我们看到，通过多阶段构建特性构建的Docker镜像与我们之前通过builder模式构建的镜像在效果上是等价的。小结Docker镜像构建走到今天，追求又快又小的镜像已成为云原生开发者的共识。Go程序有着（静态）编译为单一可执行文件的“先天特性”，这使我们可以结合最新容器构建技术为其构建出极小的镜像，使其在云原生生态系统中能发挥出更大的优势，得以更为广泛地应用。

>> 第63条 自定义Go包的导入路径

>> 在日常开发中，我们使用最多的Go包的go get导入路径主要是基于一些代码托管站点的域名，比如github.com、bitbucket.org、gitlab.com等。以知名Go Web框架beego包为例，它的go get导入路径就是github.com/astaxie/beego。我们还经常看到一些包，它们的导入路径很特殊，比如go get golang.org/x/net、go get gopkg.in/yaml.v2等，这些包使用了自定义的包导入路径。这种自定义包go get导入路径的实践有诸多好处。第一，可以作为Go包的权威导入路径（canonical import path）权威导入路径是在Go 1.4版本中加入的概念。前面说过，Go包多托管在几个知名的代码管理站点，比如github.com、bitbucket.org等，这样默认情况下Go包的导入路径就是github.com/user/repo/package、bitbucket.org/user/repo/package等。如果以这样的导入路径作为Go包的权威导入路径，那么一旦某个站点关闭，则该Go包势必要迁移到其他站点，这样该Go包的导入路径就要发生改变，这会给Go包的用户造成诸多不便。比如之前code.google.com的关闭就给广大Gopher带来了一定的“伤害”。采用自定义包导入路径作为权威导入路径可以解决这个问题。Go包的用户只需要使用包的权威导入路径，无论Go包的实际托管站点在哪，Go包迁移到哪个托管站点，对Go包的用户都不会带来实质性的影响。第二，便于组织和个人对Go包的管理。组织和个人可以将其分散托管在不同代码管理站点上的Go包统一聚合到组织的官网名下或个人的域名下，比如golang.org/x/net、gopkg.in/xxx等。第三，Go包的导入路径可以更短、更简洁。有些时候，代码托管站点上的Go包的导入路径很长，不便于查找和书写，通过自定义包导入路径，我们可以使用更短、更简洁的域名来代替代码托管站点下仓库的多级路径。在本条中，我们就来介绍一种自定义Go包导入路径的有效实践。

>> 63.1　govanityurls

>> 前Go核心团队成员Jaana B. Dogan曾开源过一个工具——govanityurls（https://github.com/GoogleCloudPlatform/govanityurls），这个工具可以帮助Gopher快速实现自定义Go包的go get导入路径。

>> 不过govanityurls仅能运行于Google的App Engine上，这对于国内的Gopher来说是十分不便的。于是笔者基于Jaana B. Dogan的govanityurls仓库分叉（fork）了一个新仓库——https://github.com/bigwhite/govanityurls，并做了些许修改，让govanityurls可以运行于App Engine之外的普通虚拟主机/裸金属主机上。govanityurls的原理十分简单，见图63-1。[插图]图63-1　govanityurls工作原理我们看到govanityurls本身就好比一个导航服务器。当go get向自定义包地址发起请求时，实则是将请求发送给了govanityurls服务，之后govanityurls将请求中的包所在仓库的真实地址（从vanity.yaml配置文件中读取）返回给go get，go get再从真实的仓库地址获取包数据。

>> 以图63-1中的示例为例，go get第一步是尝试向govanityurls获取自定义路径的包的真实地址，govanityurls将返回一个类似如下内容的HTTP应答：<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><meta name="go-import" content="tonybai.com/gowechat git https://github.com/bigwhite/gowechat"><meta name="go-source" content="tonybai.com/gowechat "><meta http-equiv="refresh" content="0; url=https://godoc.org/tonybai.com/gowechat"></head><body>Nothing to see here; <a href="https://godoc.org/tonybai.com/gowechat">see the package on godoc</a>.</body></html>得到该应答后，go get会再次向存储gowechat包的真实仓库地址github.com/bigwhite/gowechat发起包获取请求。

>> 63.2　使用govanityurls1. 安装govanityurls

>> 2. 配置vanity.yaml

>> 3. 配置反向代理

>> 4. 验证通过govanityurls自定义包导入路径

>> 5. 通过HTTPS获取包数据

>> 小结在这一条中，我们了解到自定义包导入路径具有诸多优点（如通过权威导入路径减少对包用户的影响、便于管理、路径简短等），并学习了一种基于govanityurls实现的自定义包导入路径的可行方案。该方案支持通过HTTPS访问并支持获取私有module。

>> 第64条 熟练掌握Go常用工具

>> 1. go getgo get用于获取Go包及其依赖包。

>> （1）go get -d：仅获取包源码

>> （2）标准go get和go get -d相比，标准go get（无命令行标志选项）不仅要下载项目及其依赖的源码，还要对下载的源码进行编译和安装。

>> 如果目标源码仅是库（不包含main包），则编译后的库目标文件将以.a文件的形式被安装到$GOPATH/pkg/$GOOS_$GOARCH下。在module-aware模式下，编译出的可执行二进制文件也会被安装到$GOBIN或$GOPATH/bin下；如果目标源码是库，则只编译并将编译结果缓存下来

>> （3）go get -u：更新依赖版本

>> （4）go get -t：获取测试代码依赖的包

>> （5）gopath模式和module-aware模式下的go get行为对比

>> 2. go installgo get知名度太高且涵盖了对目标包/module及依赖的安装功能，以至于在日常开发中，我们很少直接使用go install。

>> 但go install仍然是重要的工具命令，尤其是在仅进行本地安装时，它可以将本地构建出的可执行文件安装到$GOBIN（默认值为$GOPATH/bin）下，将包目标文件（.a）安装到$GOPATH/pkg/$GOOS_$GOARCH下。

>> （1）引入go module之前的gopath模式

>> （2）引入go module后的gopath模式

>> （3）module-aware模式在module-aware模式下（GO111MODULE=on），go install仅会将编译为可执行二进制文件的目标module安装到$GOBIN下，而不会将其依赖的module安装到$GOPATH/pkg/$GOOS_$GOARCH下。即便加上-i命令行标志选型，依赖包或不能编译成可执行二进制文件的目标module也都不会被安装，而仅会被缓存到$GOCACHE下。

>> 64.2　包或module检视

>> Go提供了一个原生工具go list，用于列出关于包/module的各类信息。这里把输出这类信息的行为称为检视。go list的检视功能甚为灵活和强大，它也因此被Go社区称为“Go工具链中的瑞士军刀”。它规整的输出信息常常被作为一些功能脚本的输入以实现某些更为高级的、自动化的检视和处理功能。

>> 1. go list基础

>> Go原生保留了几个代表特定包或包集合的路径关键字：main、all、cmd和std。这些保留的路径关键字不要用于Go包的构建中。
1）main：表示独立可执行程序的顶层包。
2）all：在gopath模式下，它可以展开为标准库和GOPATH路径下的所有包；在module-aware模式下，它展开为主module（当前路径下的module）下的所有包及其所有依赖包，包括测试代码的依赖包。

>> 3）std：代表标准库所有包的集合。
4）cmd：代码Go语言自身项目仓库下的src/cmd下的所有包及internal包。

>> 默认情况下，go list输出的都是包的导入路径信息，如果要列出module信息，可以为list命令传入-m命令行标志选项

>> 2. 定制输出内容的格式
go list提供了一个-f的命令行标志选项，用于定制其输出内容的格式。-f标志选项的值是一个格式字符串，采用的是Go template包的语法。go list的默认输出等价于：
$go list -f '{{.ImportPath}}'

>> ImportPath这个字段来自$GOROOT/src/cmd/go/internal/pkg.go文件中的结构体类型PackagePublic，其结构如下：
// $GOROOT/src/cmd/go/internal/pkg.go 

>> 利用模板语法中的内置函数输出上述结构体的所有信息。以标准库的fmt包为例：
$GOROOT/src/fmt$ go list -f '{{printf "%#v" .}}' 

>> 重点介绍这些字段中几个常用的字段。
（1）ImportPath
ImportPath表示当前路径下的包的导入路径，该字段唯一标识一个包。

>> 如果项目使用了vendor机制，默认情况下，go list会忽略vendor路径下的包

>> 如果要列出vendor下的包信息，可以显式将vendor路径传给go list，比如：
~/go/src/github.com/bigwhite/gocmpp$ go list ./vendor/...

>> 包的ImportPath唯一性要求使得vendor下的包的导入路径都带有vendor路径前缀。

>> （2）Target
Target表示包的安装路径，该字段采用绝对路径形式。

>> // 在GOROOT/src/fmt目录下执行$go list -f '{{.Target}}'/root/.bin/go1.14/pkg/linux_amd64/fmt.a// 在$GOPATH/src/github.com/bigwhite/gocmpp目录下执行$go list -f '{{.Target}}'/root/go/pkg/linux_amd64/github.com/bigwhite/gocmpp.a// 在$GOPATH/src/bitbucket.org/bigwhite/s目录下执行，该module下仅存在一个main包$ go list -f '{{.Target}}'/root/go/bin/s

>> （3）Root

>> Root表示包所在的GOROOT或GOPATH顶层路径，或者包含该包的module根路径。

>> （4）GoFiles
GoFiles表示当前包包含的Go源文件列表，不包含导入“C”的cgo文件、测试代码源文件。

>> （5）CgoFiles

>> CgoFiles表示当前包下导入了“C”的cgo文件。

>> （6）IgnoredGoFiles

>> IgnoredGoFiles表示当前包中在当前构建上下文约束条件下被忽略的Go源文件。

>> （7）Imports
Imports表示当前包导入的依赖包的导入路径集合。

>> （8）Deps

>> Deps表示当前包的所有依赖包导入路径集合。和Imports不同的是，Deps是递归查询当前包的所有依赖包。

>> （9）TestGoFiles
TestGoFiles表示当前包的包内测试代码的文件集合。

>> （10）XTestGoFiles
XTestGoFiles表示当前包的包外测试代码的文件集合。

>> 除了-f标志选项之外，go list还可以通过传入-json标志选项以将包的全部信息以JSON格式输出

>> 以JSON形式输出的包检视信息更为详尽也更容易被其他支持JSON格式解析的工具作为输入。

>> 3. 有关module的可用升级版本信息

>> 通过-m标志选项，我们可以让go list列出module信息，-m就像是一个从包到module的转换开关。基于该开关，我们还可以通过传入其他标志选项来获得更多有关module的信息。比如：通过传入-u标志选项，我们可以获取到可用的module升级版本：
// 在$GOPATH/src/github.com/bigwhite/gocmpp目录下执行$ go list -m -u allgithub.com/bigwhite/gocmppgithub.com/dvyukov/go-fuzz v0.0.0-20190516070045-5cc3605ccbb6 [v0.0.0-20201003075337-90825f39c90b]golang.org/x/text v0.3.0 [v0.3.3]
-u标志选项分析了gocmpp module自身及其依赖的module是否有新的版本可以升级。在结果中我们看到，gocmpp依赖的go-fuzz和text两个module都有可升级的版本（列在了方括号中）。

>> 64.3　构建

>> 1. -x -v：让构建过程一目了然

>> -v用于输出当前正在编译的包，而-x则用于输出go build执行的每一个命令。

>> go build执行命令的顺序大致如下：
1）创建用于构建的临时目录；
2）下载构建module s依赖的module t和u；
3）分别编译module t和u，将编译后的结果存储到临时目录及GOCACHE目录下；
4）编译module s；
5）定位和汇总module s的各个依赖包构建后的目标文件（.a文件）的位置，形成importcfg.link文件，供后续链接器使用；
6）链接成可执行文件；
7）清理临时构建环境。

>> 从上面build -x -v 的输出中我们还看到，go build过程主要调用了go tool compile（$GOROOT/pkg/tool/linux_amd64/compile）和go tool link（$GOROOT/pkg/tool/linux_amd64/link）分别进行包编译和最终的链接操作。编译及链接命令中的每个标志选项都会对最终结果产生影响，比如：-goversion的值会影响Go编译器的行为，而这个值可能来自go.mod中的Go版本指示标记。笔者就遇到过一次因goversion值版本过低而导致的问题[1]。而-v -x选项对这类问题的解决会起到关键作用。

>> 2. -a：强制重新构建所有包

>> 3. -race：让并发bug无处遁形
-race命令行选项会在构建的结果中加入竞态检测的代码。在程序运行过程中，如果发现对数据的并发竞态访问，这些代码会给出警告，这些警告信息可以用来辅助后续查找和解决竞态问题。不过由于插入竞态检测的代码这个动作，带有-race的构建过程会比标准构建略慢一些。

>> Go社区的一个最佳实践是在正式发布到生产环境之前的调试、测试环节使用带有-race构建选项构建出的程序，以便于在正式发布到生产环境之前尽可能多地发现程序中潜在的并发竞态问题并快速将其解决。

>> 4. -gcflags：传给编译器的标志选项集合

>> go build采用下面的模式将标志选项列表传递给Go编译器：
go build -gcflags[=标志应用的包范围]='空格分隔的标志选项列表'

>> go build -gcflags='-N -l'      // 仅将传递的编译选项应用于当前包go build -gcflags=all='-N -l'  // 将传递的编译选项应用于当前包及其所有依赖包go build -gcflags=std='-N -l'  // 仅将传递的编译选项应用于标准库包
这些命令行标志选项是传递给Go编译器的，所以我们可以通过下面的命令查看可以传递的所有选项集合：
$go tool compile -help
下面介绍一些常用的编译器命令行标志选项。
◦  -l：关闭内联。
◦  -N：关闭代码优化。
◦  -m：输出逃逸分析（决定哪些对象在栈上分配，哪些对象在堆上分配）的分析决策过程。
◦  -S：输出汇编代码。

>> 在运行调试器对程序进行调试之前，我们通常使用“-N -l”两个选项关闭对代码的内联和优化，这样能得到更多的调试信息。

>> 以-m为例，我们可以通过下面的命令输出更为详尽的逃逸分析过程信息：
go build -gcflags='-m'go build -gcflags='-m -m'      // 输出比上一条命令更为详尽的逃逸分析过程信息go build -gcflags='-m=2'       // 与上一条命令等价go build -gcflags='-m -m -m'   // 输出最为详尽的逃逸分析过程信息go build -gcflags='-m=3'       // 与上一条命令等价

>> 5. -ldflags：传给链接器的标志选项集合
go build在支持为编译器传递标志选项集合的同时，也支持通过-ldflags为链接器（以Linux系统为例，该工具对应的是$GOROOT/pkg/tool/linux_amd64/link）传递链接选项集合。我们可以通过下面的命令查看链接器支持的所有链接选项：
$go tool link -help
链接器支持的选项有很多，这里不能一一详细说明。下面是笔者日常开发中常用的3个链接器选项，简要说明一下。
1）-X：设定包中string类型变量的值（仅支持string类型变量）。
通过-X选项，我们可以在编译链接期间动态地为程序中的字符串变量进行赋值，这个选项的一个典型应用就是在构建脚本中设定程序的版本值。我们通常会为应用程序添加version命令行标志选项，用来输出当前程序的版本信息，就像Go自身那样：
$go versiongo version go1.14 darwin/amd64
如果将版本信息写死到程序代码中，显然不够灵活，耦合太紧。而将版本信息在程序构建时注入则是一个不错的方案。-X选项就可以用来实现这个方案：
// chapter10/sources/go-tools/linker_x_flag.govar (    version string)func main() {    if os.Args[1] == "version" {        fmt.Println("version:", version)        return    }}
注意，在这个源文件中，我们并未显式初始化version这个变量。接下来，构建这个程序，在构建时为version这个string类型变量动态地注入新值：
$go build -ldflags "-X main.version=v0.7.0" linker_x_flag.go$./linker_x_flag versionversion: v0.7.0

>> 我们看到，在-X后面的式子中我们使用包导入路径.变量名=新值的形式为main包中的version变量赋予了新值。
2）-s：不生成符号表（symbol table）。
3）-w：不生成DWARF（Debugging With Attributed Record Formats）调试信息。
默认情况下，go build构建出的可执行二进制文件中都是包含符号表和DWARF格式的调试信息的，这虽然让最终二进制文件的体积增加了，但是符号表和调试信息对于生产环境下程序异常时的现场保存和在线调试都有着重要意义。但如果你不在意这些信息或者对应用的大小十分敏感，那么可以通过-s和-w选项将符号表和调试信息从最终的二进制文件中剔除。我们还以上面的linker_x_flag为例，通过下面命令再来构建一次：
$go build -ldflags "-X main.version=v0.7.0 -s -w" -o linker_x_flag_without_symboltable_and_dwarf linker_x_flag.go
对比一下两次生成的二进制文件的大小（macOS，Go 1.14）：
-rwxr-xr-x  1 tonybai  staff  2169976 10 25 08:17 linker_x_flag*-rwxr-xr-x  1 tonybai  staff  1674360 10 25 08:34 linker_x_flag_without_symboltable_and_dwarf*
去除了符号表和调试信息的可执行文件要比以默认标准构建的小20%左右。

>> 6. -tags：指定构建约束条件
go build可以通过-tags指定构建的约束条件，以决定哪些源文件被包含在包内进行构建。tags的值为一组逗号分隔（老版本为空格分隔）的值：
$go build -tags="tag1,tag2,..." ...
与tags值列表中的tag1、tag2等呼应的则是Go源文件中的build tag（亦称为build constraint）。Go源文件中的build tag实际上就是某种特殊形式的注释，它通常放在Go源文件的顶部区域，以一行注释或连续的（中间无空行）多行注释形式存在。build tag与前后的包注释或包声明语句的中间要有一行空行。下面是标准库os包的file_unix.go源文件中build tag的格式：
// +build aix darwin dragonfly freebsd js,wasm linux netbsd openbsd solarispackage os
build tag行也是注释，它以+build作为起始标记，与前面的注释符号//中间有一个空格。+build后面就是约束标记字符串，比如上面例子中的aix、darwin等。每一行的build tag实质上会被求值为一个布尔表达式。表64-3简单总结了布尔表达式的求值方式。

>> 当一个Go源文件带有build tag时，只有当该组tag被求值为true时，该源文件才会被包含入对应的包中参与构建。

>> 下面用一个例子来演示一下。在这个例子中，我们售卖一种软件产品，该产品分为社区版（community）、专业版（professional）和旗舰版（ultimate）。其中，社区版是免费的，功能也是最少的，专业版和旗舰版的功能逐渐增强。该产品的开发人员决定采用Go的build tag技术来区分构建不同的版本。

>> 64.4　运行与诊断

>> 1. GOMAXPROCS
GOMAXPROCS环境变量可用于设置Go程序启动后的逻辑处理器P的数量，如果每个P都绑定一个操作内核线程，那么该值将决定有多少个内核线程一起并行承载该Go程序的业务运行。

>> Go 1.5版本将GOMAXPROCS默认值调整为CPU核数（一个2核4线程的CPU在Go运行时眼中的CPU核数为4，以下CPU核数均等同于此含义）。

>> 2. GOGC

>> Go的垃圾回收（GC）何时触发？除了显式调用runtime.GC强制运行GC，Go还提供了一个可以调节GC触发时机的环境变量：GOGC。GOGC是一个整数值，默认为100。这个值代表一个比例值，100表示100%。这个比例值的分子是上一次GC结束后到当前时刻新分配的堆内存大小（设为M），分母则是上一次GC结束后堆内存上的活动对象内存数据（live data，可达内存）的大小（设为N）。
Go运行时实时监控当前堆内存状态，如果当前堆内存的N/M的值等于GOGC/100，则会再次触发运行GC

>> 默认情况下GOGC=100，即如果自上一次GC结束后到当前时刻新分配的堆内存大小等于堆内存上的活动对象内存数据的大小，则GC会再次被触发。

>> 说明
在两次GC之间新分配的堆内存在第二次GC启动的时候不一定都是活动对象占用的内存，也可能是刚分配后不久就处于非活动状态了（没有指针指向这个内存对象）。

>> 在1.5版本中，Go抛弃了GC延迟过大且无法扩展的STW垃圾回收器，引入了基于三色标记清除的并发垃圾回收器，该并发垃圾收集器大幅降低了垃圾回收过程的延迟，将延迟从几百毫秒降低至几十毫秒。Go 1.6更是将GC延迟降到10ms以下。
并发垃圾回收器与用户程序一起执行带来了GC延迟的大幅下降，但也导致了Go运行时无法精确控制堆内存大小，因为在并发标记过程中，只要没有停止程序，用户程序就可以继续分配内存。计算新分配内存时不仅要考虑两次GC之间用户程序请求分配的内存，还要考虑新一轮GC开始后的并发标记过程中用户新分配的内存，见图64-4。

>> 可以通过设置环境变量GODEBUG='gctrace=1'让位于Go程序中的运行时在每次GC执行时输出此次GC相关的跟踪信息。

>> $go build -o gctrace gctrace.go$GODEBUG='gctrace=1' GOGC=100 ./gctracegc 1 @0.008s 3%: 0.005+2.7+0.017 ms clock, 0.042+0.056/3.6/3.7+0.14 ms cpu, 5->5->4 MB, 6 MB goal, 8 Pgc 2 @0.028s 5%: 0.007+8.4+0.024 ms clock, 0.057+0.074/11/11+0.19 ms cpu, 9->9->8 MB, 10 MB goal, 8 Pgc 3 @0.067s 5%: 0.005+14+0.023 ms clock, 0.040+0.38/19/18+0.18 ms cpu, 19->19->16 MB, 20 MB goal, 8 Pgc 4 @0.141s 6%: 0.011+25+0.021 ms clock, 0.093+0.26/46/82+0.17 ms cpu, 38->38->33 MB, 39 MB goal, 8 P

>> ◦  gc 1：表示程序启动后运行的第几次GC，即GC的序号，每次加1。
◦  @0.008s：程序启动至今运行的秒数。
◦  3%：程序启动后用于GC运行的CPU时间占用于该程序运行总CPU时间的百分比。
◦  0.005+2.7+0.017（挂钟时间）
▪  0.005：设置GC清除停止及GC标记开始（需停止程序）所用的挂钟时间。
▪  2.7：并发的GC标记所用的挂钟时间。
▪  0.017：设置GC标记结束（需停止程序）所用的挂钟时间。
◦  0.042+0.056/3.6/3.7+0.14（CPU时间）
▪  0.042：设置GC清除停止及GC标记开始（需停止程序）所用的CPU时间。
▪  0.056/3.6/3.7：并发的GC标记的各个阶段所用的CPU时间。
▪  0.14：设置GC标记结束（需停止程序）所用的CPU时间。
◦  5->5->4 MB
▪  5：此次GC标记前堆内存的大小。
▪  5：此次GC标记后堆内存的大小。（注意：由于是不停止程序的并发标记，在这个过程中内存分配依旧在进行。）
▪  4：此次GC标记后堆上活动对象（live data）内存大小。
◦  6 MB goal：在完成此次GC的标记过程后，GC对堆内存大小的期望目标值。
◦  8 P：用于运行该程序的8个逻辑处理器（P）。

>> 由于并发标记及Pacing算法的存在，我们很难像在使用STW垃圾回收器时那样看到两次GC之间堆内存大小的精确关系了。唯一能看到GOGC值参与的痕迹就是每轮GC的goal值与上一轮GC后堆大小的关系

>> 调整GOGC值后的GC跟踪信息，以GOGC=200和GOGC=500为例

>> 随着GOGC值的增加，GC启动的次数逐渐减少：在4s左右的时间跨度里，当GOGC=100时，GC启动了10次以上；当GOGC=200时，GC启动7次；当GOGC=500时，GC仅启动4次。不过随着GOGC值的增大，GC启动后面对的堆内存大小也是成比例快速增加的。如果GOGC设置不合理，很可能出现GC还未来得及启动，堆内存就被耗尽、导致程序崩溃的情况。

>> 综上，和Java等支持GC的主流编程语言提供了丰富的GC调优参数不同，Go对外提供的垃圾回收器调优手段极少，GOGC就是其中为数不多且最重要的一个。实践证明，默认的GOGC值能适合多数Go程序和场合，但对于在特定场景运行的Go程序来说，它并不一定是最优值。如果你的程序在性能和响应延迟方面遇到瓶颈，可以大胆地通过调整GOGC的值进行调优，直到找到最适合你的Go程序的GOGC值。此外，还要验证在该最优GOGC值下你的Go程序可以稳定运行，即便长期处于流量峰值，GC也会及时得到触发，堆内存大小受控。

>> 3. GODEBUG

>> 除了通过gctrace=1在GC启动时输出GC相关信息外，GODEBUG还可以结合其他值输出很多有用的诊断信息，并且可以将一些试验特性关闭。

>> （1）schedtrace与scheddetail
在第32条中，我们就曾通过GODEBUG=schedtrace=1000输出过godoc程序运行时的goroutine调度信息

>> $GODEBUG=schedtrace=1000 godoc -http=:6060

>> schedtrace=1000中的1000的单位是毫秒，即每1000毫秒（1秒）输出一次goroutine调度器的内部信息。输出信息的各字段含义在第32条中也有明确说明。结合scheddetail=1，Go运行时还会将更为详尽的调度器信息输出到标准错误，但这些信息更多用于Go核心团队调试调度器，大多数Gopher是不用关心的。
（2）asyncpreemptoff（Go 1.14及之后版本）

>> Go长期以来不支持真正的抢占式调度

>> ，下面的代码是一个典型例子：
// chapter10/sources/go-tools/preemption_scheduler.gofunc deadloop() {    for {    }}func main() {    runtime.GOMAXPROCS(1)    go deadloop()    for {        time.Sleep(time.Second * 1)        fmt.Println("I got scheduled!")    }}
在只有一个P（GOMAXPROCS=1）的情况下，上面代码中deadloop函数所在的goroutine将持续占据该P，使得main goroutine中的代码得不到调度，我们无法看到“I got scheduled!”字样输出。这是因为Go 1.13及以前版本的抢占是协作式的，只在有函数调用的地方才能插入抢占代码（埋点），而deadloop没有给编译器插入抢占代码的机会。Go 1.14版本增加了基于系统信号的异步抢占调度，这样上面的deadloop所在的goroutine也可以被抢占了。使用Go 1.14版本编译器运行上述代码：
$go run preemption_scheduler.goI got scheduled!I got scheduled!I got scheduled!

>> 由于系统信号可能在代码执行到任意地方发生，在Go运行时能顾及的地方，Go运行时自然会处理好这些系统信号。但如果你是通过syscall包或golang.org/x/sys/unix在Unix/Linux/macOS上直接进行系统调用，那么一旦在系统调用执行过程中进程收到系统中断信号，这些系统调用就会失败，并以EINTR错误返回，尤其是低速系统调用，包括读写特定类型文件（管道、终端设备、网络设备）、进程间通信等。在这样的情况下，我们就需要自己处理EINTR错误。最常见的错误处理方式是重试。对于可重入的系统调用来说，在收到EINTR信号后的重试是安全的。如果你没有自己调用syscall包，那么异步抢占调度对你已有的代码几乎无影响。
相反，当异步抢占调度对你的代码有影响，并且你还没法及时修正时，可以通过GODEBUG= asyncpreemptoff=1关闭这一新增的特性。
$GODEBUG=asyncpreemptoff=1 go run preemption_scheduler.go // 这里不会输出I got scheduled!
除了上面这些，GODEBUG还可以被赋予其他值，鉴于很多值我们平时很少使用，这里就不介绍了。随着Go的演进，GODEBUG的取值还在增加和变化中，其最新更新可参见https://tip.golang.org/pkg/runtime/#hdr-Environment_Variables。

>> 64.5　格式化与静态代码检查

>> 1. 人人都爱的gofmt

>> goimports的其余格式化功能与gofmt并无二致，甚至连命令行选项都完全一样。目前goimports也被吸纳到go官方扩展工具仓库的下面了，地址为golang.org/x/tools/cmd/goimports

>> 2. 提交代码前请使用go vet对代码进行静态检查

>> 在语法层面，上述代码通过了编译器的检查；但在语义层面静态代码检测器go vet发现传给Printf函数的参数有个数不匹配的问题。

>> go vet是官方Go工具链提供的静态代码检查工具，它内置了多条静态代码检查规则，这里简要介绍几个常见的规则。
1）assign规则：检查代码中是否有无用的赋值操作。

>> 2）atomic规则：检查代码中是否有对sync.atomic包中函数的误用情况。

>> 3）bools规则：检查代码中是否存在对布尔操作符的误用情况。

>> 4）buildtag规则：检查源文件中+build tag是否正确定义。

>> 5）composites规则：检查源文件中是否有未使用“field:value”格式的复合字面值形式对struct类型变量进行值构造的问题。

>> 6）copylocks规则：检查源文件中是否存在lock类型变量的按值传递问题。

>> 7）loopclosure规则：检查源文件中是否存在循环内的匿名函数引用循环变量的问题。

>> 8）unmarshal规则：检查源码中是否有将非指针或非接口类型值传给unmarshal的问题。

>> 9）unsafeptr规则：检查源码中是否有非法将uintptr转换为unsafe.Pointer的问题。

>> 可以通过go tool vet help查看更多检查规则。默认情况下，go vet内置的所有检查规则均开启。

>> 3. 第三方linter聚合：golangci-lint

>> 第三方lint工具是对官方go vet工具的一个很好的补充。第三方lint工具中有通用类型的，如staticcheck，但更多的是聚焦于某特定主题的，如用于检查未用代码的deadcode、用于检查未处理错误的errcheck等。

>> golangci-lint聚合了几十种Go lint工具，但默认仅开启如下几种。
◦  deadcode：查找代码中的未用代码。
◦  errcheck：检查代码中是否存在未处理的错误。
◦  gosimple：专注于发现可以进一步简化的代码的lint工具。
◦  govet：go官方工具链中的vet工具。
◦  ineffassign：检查源码中是否存在无效赋值的情况（赋值了，但没有使用）。
◦  staticcheck：通用型lint工具，增强的“go vet”，对代码进行很多go vet尚未进行的静态检查。
◦  structcheck：查找未使用的结构体字段。
◦  typecheck：像Go编译器前端那样去解析Go代码并进行类型检查。
◦  unused：检查源码中是否存在未使用的常量、变量、函数和类型。
◦  varcheck：检查源码中是否存在未使用的全局变量和常量。
除了上述默认开启的lint工具，我们还可以通过golangci-lint linters命令查看所有内置lint工具列表，包括默认不开启的。

>> 64.6　重构

>> 1. gofmt -r：纯字符串替换

>> 2. gorename：安全的标识符替换
由于gofmt -r是基于字符串的替换，它并不关心替换后的代码在Go语法层面是否正确，因此我们需要用肉眼和Go编译器去验证替换后的结果。Go在扩展工具链中提供了gorename工具，该工具可以用来进行语法层面安全的标识符替换。

>> （1）替换包级类型名

>> （2）替换包级结构体类型下的字段名

>> （3）替换包级变量和常量名

>> （4）替换包级函数名和包级类型的方法名

>> （5）替换函数和方法内的本地变量名

>> 3. gomvpkg：移动包并更新包导入路径

>> 我们在日常开发中时常会调整项目结构，其中会涉及包位置的移动以及包的改名。包一旦发生移动，其导入路径就会发生变化，那么导入该包的源文件就需要同步修改包导入路径。如果包发生改名，那么不仅包导入路径要同步修改，其他源文件中对该包的引用名也要同步变化。
Go扩展工具链中的gomvpkg是专门用来实现包移动/改名并同步更新项目所有导入该包的源文件的包导入路径和包引用名的工具。

>> 64.7　查看文档

>> Go还将整个Go项目文档加入Go发行版中，这样开发人员在本地安装Go的同时也拥有了一份完整的Go项目文档。

>> 1. go doc

>> go doc在命令行上接受的参数使用了Go语法的格式，这使得go doc的上手使用几乎是零门槛：
go doc <pkg>go doc <sym>[.<methodOrField>]go doc [<pkg>.]<sym>[.<methodOrField>]go doc [<pkg>.][<sym>.]<methodOrField>

>> （1）查看标准库文档

>> 查看标准库net/http包文档：

>> $go doc net/http// 或$go doc http

>> 查看http包的Get函数的文档：
$ go doc net/http.Get// 或$ go doc http.Get
查看http包中结构体类型Request中字段Form的文档：
$go doc net/http.Request.Form// 或$go doc http.Request.Form

>> （2）查看当前项目文档

>> 查看当前路径下的包的文档：
$go doc

>> （3）查看第三方项目文档

>> 在go module开启的情况下，go doc会首先确定包所在module，定位该module根路径。由于module可能存在于任意路径下，因此在module-aware模式下要查看第三方项目文档，只能先切换到该第三方项目的module根路径下，再使用查看当前路径下包的方法查看该项目的相关包文档。

>> （4）查看源码

>> 如果要查看包的源码，我们没有必要将目录切换到该包所在路径并通过编辑器打开源文件查看，通过go doc我们一样可以查看包的完整源码或包的某个元素的源码。
查看标准库包源码：
$go doc -src fmt.Printfpackage fmt // import "fmt"func Printf(format string, a ...interface{}) (n int, err error) {    return Fprintf(os.Stdout, format, a...)}
查看当前路径包中导出元素的源码：
$go doc -src NewClientpackage cmpp // import "."func NewClient(typ Type) *Client {    return &Client{        typ: typ,    }}
查看当前路径包中未导出元素的源码：
$go doc -u -src newPacketWriterpackage cmpp // import "github.com/bigwhite/gocmpp"func newPacketWriter(initSize uint32) *packetWriter {    buf := make([]byte, 0, initSize)    return &packetWriter{        wb: bytes.NewBuffer(buf),    }}

>> 2. godoc：Web化的文档中心

>> （1）建立Web形式的文档中心
和命令行go doc工具不同的是，godoc实质上是一个Web服务，它会在本地建立起一个Web形式的Go文档中心，当我们执行下面的命令时这个文档中心服务就启动了：
$godoc -http=localhost:6060
在浏览器地址栏中输入http://localhost:6060，打开Go文档中心首页

>> Go包参考文档页面将包分为标准库包（Standard library）、第三方包（Third party）和其他包（Other packages），其中第三方包就是本地$GOPATH下的各个包。

>> （2）查看Go旧版本的文档
godoc建立的Go文档中心对应的文档版本默认是当前Go的版本，即如果当前本地安装的Go版本为Go 1.14，那么godoc所呈现的就是Go 1.14稳定版对应的文档。而Go官方网站上的文档版本对应的是最新Go稳定版的版本，tip.golang.org上的文档版本则是当前Go项目主线分支（master）上的文档版本。
如果想查看一下旧版本的文档，比如Go 1.9版本的文档，我们该如何做呢？首先我们需要下载Go 1.9版本的安装包，将其解压到本地目录下（如/Users/tonybai/.bin/go1.9），接着执行如下命令：
$godoc -goroot /Users/tonybai/.bin/go1.9 -http=localhost:6060
我们用-goroot命令行选项显式告诉godoc从哪个路径加载Go文档数据，这样godoc建立的文档中心中的文档版本就是Go 1.9的了。

>> （3）查看Go官方博客
Go官方博客是学习和理解Go语言的重要资料，Go核心团队为了方便Gopher查阅博客资料，单独在Go扩展工具链项目中创建了一个内容服务程序——blog。我们可以通过下面的命令安装该工具：
$go get golang.org/x/blog
Go官方博客的内容数据并没有放在Go安装包中，而是单独存放在github.com/golang/blog仓库下，我们需要先将该仓库下载到本地（如/Users/tonybai/.bin/goblog/blog），再切换到该路径下来启动blog服务程序：
$cd /Users/tonybai/.bin/goblog$git clone https://github.com/golang/blog.git$cd blog$blog2020/10/31 05:14:47 Listening on addr localhost:8080
用浏览器打开localhost:8080页面，我们能看到与Go官方博客首页相同的页面

>> 之后点击Blog index链接就能看到Go的历史博客了

>> 3. 查看present格式文档

>> 很多初接触Go语言的Gopher可能很好奇，为何Go团队在世界各地进行技术演讲和Go语言布道时总是喜欢使用图64-9这样风格的幻灯片？
这类幻灯片文件不能通过传统的幻灯片软件PowerPoint或Keynote打开，但Go官方提供了一个服务站点talks.golang.org，只要让该服务定位并打开某特定格式的幻灯片文件，比如https://talks.golang.org/2012/splash.slide，我们就可以在浏览器中直接操作和演示该幻灯片。对于非Go官方团队的幻灯片，我们可以用另一个服务站点go-talks.appspot.com打开和演示特定位置的幻灯片文件，比如https://go-talks.appspot.com/github.com/davecheney/presentations/performance-without-the-event-loop.slide。
这是Go团队用一种自定义的轻量级标记语言编写的文件，官方称之为present文件。这类文件可以以文章形式呈现（一般后缀名为.article，多用于官方博客），也可以以幻灯片的形式呈现（一般后缀名为.slide，多用于技术演讲时做幻灯片使用）。

>> 除了通过上面两个网站可以渲染呈现这类present文件之外，Go团队还在Go的扩展工具链中提供了一个名为present的工具，该工具支持本地安装并查看present格式文件，其安装方法如下：
$go get golang.org/x/tools/cmd/present
和godoc一样，present工具也会在本地启动一个Web服务。present支持module-aware模式，在该模式下，present工具会定位go.mod文件的路径，一旦定位成功，就会将该路径作为其所服务内容的根路径。以查看Go团队近几年的技术演讲幻灯片为例。执行下面的步骤可以在本地建立起一个Web服务，用于列举Go团队多年的技术演讲记录并支持查看每一个演讲的幻灯片（Go团队的演讲资料单独存放在github.com/golang/talks下）：
$cd /Users/tonybai/.bin/gotalks$git clone https://github.com/golang/talks.git$cd talks$present2020/10/31 20:44:34 Open your web browser and visit http://127.0.0.1:3999
用浏览器访问http://127.0.0.1:3999/content，可以看到如图64-10所示的页面。
这个页面和官方的talks.golang.org一模一样。之后，我们就可以点击代表各个年份的子目录，并浏览该年份下的Go团队技术演讲的幻灯片或文字资料了。
每个Gopher都可以使用present格式编写Go团队风格的幻灯片并使用present操作和演示。以笔者存储个人演讲的仓库（github.com/bigwhite/talks）为例，通过下面的步骤我们就可以浏览该仓库下存储的present幻灯片文件（效果见图64-11）：
$git clone https://github.com/bigwhite/talks.git$cd talks$present2020/11/01 06:54:15 Open your web browser and visit http://127.0.0.1:3999

>> 64.8　代码导航与洞察

>> 常见的工具有gocode、gorename、godef、gopkgs、go-symbols、go-outline、guru及staticcheck等。

>> 2019年Go官方启动了Go语言服务器的实现项目gopls，旨在替代上面那些由不同个体开发人员维护的工具，为Go编辑器/IDE提供高质量、高性能的语言服务器标准协议的Go实现。

>> 语言服务器协议旨在使语言服务器和开发工具之间的通信协议标准化。这样，单个语言服务器就可以在多个开发工具中重复使用，从而避免以往必须为每个开发工具都单独进行一次自动代码补全、定义跳转、悬停提示等功能特性的开发，大幅节省了IDE/编辑器（及插件）作者的精力

>> 第65条使用go generate驱动代码生成

>> 65.1　go generate：Go原生的代码生成“驱动器”

>> // chapter10/sources/go-generate/protobuf-make$tree protobuf-makeprotobuf-make├── IDL│    └── msg.proto├── Makefile├── go.mod├── go.sum├── main.go└── msg     └── msg.pb.go // 待生成的Go源文件// chapter10/sources/go-generate/protobuf-make/Makefileall: buildbuild: gen-protobuf    go buildgen-protobuf:    protoc -I ./IDL msg.proto --gofast_out=./msg
在这个示例中，我们通过Makefile目标（target）之间的依赖关系实现了在真正构建（go build）之前先生成msg这个包并将其源码文件写入protobuf-make/msg目录中，这样go build执行时就能正常找到msg包的源文件了。
说明
上述示例基于protobuf描述文件（msg.proto）生成Go源码（msg.pb.go）。这个生成过程依赖两个工具：一个是protobuf编译器protoc（https://github.com/protocolbuffers/protobuf），另一个是protobuf go插件protoc-gen-gofast（https://github.com/gogo/protobuf/protoc-gen-gofast）。运行上述示例之前，请先行安装这两个工具。

>> Go核心团队在Go 1.4版本的Go工具链中也增加了这种在构建之前驱动执行前置动作的能力，这就是go generate命令。为了更直观地感受到go generate的特性，我们先对上面的示例进行一些改造，将生成Go源码的“驱动器”由make工具改为go generate：
// chapter10/sources/go-generate/protobuf$tree protobufprotobuf├── IDL│    └── msg.proto├── go.mod├── go.sum├── main.go└── msg     └── msg.pb.go// chapter10/sources/go-generate/protobuf/main.gopackage mainimport (    "fmt"    msg "github.com/bigwhite/protobuf-demo/msg")//go:generate protoc -I ./IDL msg.proto --gofast_out=./msgfunc main() {    var m = msg.Request{        MsgID:  "xxxx",        Field1: "field1",        Field2: []string{"field2-1", "field2-2"},    }    fmt.Println(m)}
在改造后的例子中，我们删除了Makefile，然后在依赖msg包的main包的源文件中添加了如下一行特殊的注释：
//go:generate protoc -I ./IDL msg.proto --gofast_out=./msg
这就是预先“埋”在代码中的可以被go generate命令识别的指示符（directive）。当我们在示例的目录下执行go generate命令时，上面这行指示符中的命令将被go generate识别并被驱动执行，执行的结果就是protoc基于IDL目录下的msg.proto生成了main包所需要的msg包源码。为了看清楚go generate的执行过程，我们为go generate命令加上了-x和-v这两个命令行标志选项：
$go generate -x -vmain.goprotoc -I ./IDL msg.proto --gofast_out=./msg

>> 代码生成后，我们就可以构建并运行这个示例程序了：
$go build$./protobuf-demo{xxxx field1 [field2-1 field2-2] {} [] 0}
可以看到，Go原生的go generate成功地替换了make并驱动了构建前置动作的执行。

>> 65.2　go generate的工作原理

>> go generate的能力和特性比较单一，像make这样的工具不仅具备这些特性而且更为强大，那么Go核心团队为什么还要在Go工具链加入go generate呢？正如Go语言之父Rob Pike所说的那样：“它是Go工具链内置的，天然适配Go生态系统，无须额外安装其他工具。”

>> go generate指示符可以放在Go源文件中的任意位置，并且一个Go源文件中可以有多个go generate指示符，go generate命令会按其出现的顺序逐个识别和执行

>> // chapter10/sources/go-generate/multi_go_generate_directive.go//go:generate echo "top"package mainimport "fmt"//go:generate echo "middle"func main() {    fmt.Println("hello, go generate")}//go:generate echo "tail"$go generate multi_go_generate_directive.gotopmiddletail

>> go generate在处理子路径下的包时，其执行命令时的当前工作路径已经切换到该包的路径了，因此在go generate指示符中使用相对路径时首先要明确当前的工作路径。

>> go generate还可以通过-run使用正则式去匹配各源文件中go generate指示符中的命令，并仅执行匹配成功的命令：
// 未匹配到任何go generate指示符中的命令$go generate -x -v -run "protoc" ./...main.gosubpkg1/subpkg1.gosubpkg2/subpkg2.go

>> 65.3　go generate的应用场景

>> go generate目前主要用在目标构建之前驱动代码生成动作的执行。上面基于protobuf定义文件（*.proto）生成Go源码文件的示例就是go generate一个极为典型的应用。

>> 除此之外，比较广泛的应用还有利用stringer工具（go get golang.org/x/tools/cmd/stringer）自动生成枚举类型的String方法以及利用go-bindata工具（go get -u github.com/go-bindata/go-bindata/...）将数据文件嵌入Go源码中。

>> 1. go generate驱动生成枚举类型的String方法

>> 在第10条中，我们提到利用自定义类型、const与iota可以模拟实现枚举常量类型，比如下面示例中的Weekday：
// chapter10/sources/go-generate/enum-demo/main.gotype Weekday intconst (    Sunday Weekday = iota    Monday    Tuesday    Wednesday    Thursday    Friday    Saturday)
通常我们会为Weekday类型手写String方法，这样在打印上面枚举常量时能输出有意义的内容：
// chapter10/sources/go-generate/enum-demo/main.gofunc (d Weekday) String() string {    switch d {    case Sunday:        return "Sunday"    case Monday:        return "Monday"    case Tuesday:        return "Tuesday"    case Wednesday:        return "Wednesday"    case Thursday:        return "Thursday"    case Friday:        return "Friday"    case Saturday:        return "Saturday"    }    return "Sunday" //default 0 -> "Sunday"}
如果一个项目中枚举常量类型有很多，逐个为其手写String方法费时费力。当枚举常量有变化的时候，手动维护String方法十分烦琐且易错。对于这种情况，使用go generate驱动stringer工具为这些枚举类型自动生成String方法的实现不失为一个较为理想的方案。下面就是利用go generate对上面示例的改造：
// chapter10/sources/go-generate/stringer-demo/main.go...type Weekday intconst (    Sunday Weekday = iota    Monday    Tuesday    Wednesday    Thursday    Friday    Saturday)//go:generate stringer -type=Weekdayfunc main() {    var d Weekday    fmt.Println(d)    fmt.Println(Weekday(1))}

>> 接下来利用go generate驱动生成代码：
$go generate main.go$cat weekday_string.go// Code generated by "stringer -type=Weekday"; DO NOT EDIT.package mainimport "strconv"func _() {    // An "invalid array index" compiler error signifies that the constant values have  changed.    // Re-run the stringer command to generate them again.    var x [1]struct{}    _ = x[Sunday-0]    _ = x[Monday-1]    _ = x[Tuesday-2]    _ = x[Wednesday-3]    _ = x[Thursday-4]    _ = x[Friday-5]    _ = x[Saturday-6]}const _Weekday_name = "SundayMondayTuesdayWednesdayThursdayFridaySaturday"var _Weekday_index = [...]uint8{0, 6, 12, 19, 28, 36, 42, 50}func (i Weekday) String() string {    if i < 0 || i >= Weekday(len(_Weekday_index)-1) {        return "Weekday(" + strconv.FormatInt(int64(i), 10) + ")"    }    return _Weekday_name[_Weekday_index[i]:_Weekday_index[i+1]]}
编译执行：
$go build$./stringer-demoSundayMonday

>> 2. go generate驱动从静态资源文件数据到Go源码的转换

>> Go语言的优点之一是可以将源码编译成一个对外部没有任何依赖或只有较少依赖的二进制可执行文件，这大大降低了Gopher在部署阶段的心智负担。而为了将这一优势发挥到极致，Go社区甚至开始着手将静态资源文件也嵌入可执行文件中，尤其是在Web开发领域，Gopher希望将一些静态资源文件（比如CSS文件等）嵌入最终的二进制文件中一起发布和部署。而go generate结合go-bindata工具（https://github.com/go-bindata/go-bindata）常被用于实现这一功能。
说明
Go 1.16版本内置了静态文件嵌入（embedding）功能，我们可以直接在Go源码中通过go:embed指示符将静态资源文件嵌入，无须再使用本方法。
下面通过一个将静态图片资源嵌入可执行文件中的例子来说明go generate是如何驱动go-bindata实现这一功能的。先准备一张图片go-mascot.jpg放在示例的static/img目录下，然后编写main.go如下：
// chapter10/sources/go-generate/bindata-demo//go:generate go-bindata -o static.go static/img/go-mascot.jpg...func main() {    data, err := Asset("static/img/go-mascot.jpg")    if err != nil {        fmt.Println("Asset invoke error:", err)        return    }    http.HandleFunc("/", func(w http.ResponseWriter, req *http.Request) {        w.Write(data)    })    http.ListenAndServe(":8080", nil)}
我们看到，main函数以试图调用生成代码中的Asset函数以获取签入的图片数据，并将其作为应答结果返回给HTTP服务的请求方。

>> 在示例目录下执行go generate，generate命令会执行main.go中指示符中的命令，即基于static/img/go-mascot.jpg文件数据生成static.go源文件。go-bindata生成的Go源文件的默认包名为main。
接下来，构建并运行该程序：
$cd chapter10/sources/go-generate/bindata-demo$go generate$go build$./bindata-demo
构建出的程序是一个在8080端口提供服务的HTTP服务器。用浏览器打开localhost:8080，你就能看到如图65-1所示的返回结果。

>> 这时即便你删除bindata-demo/static/img目录下的go-mascot.jpg也不会影响到bindata-demo的应答返回结果，因为图片数据已经嵌入bindata-demo这个二进制程序当中了，go-mascot.jpg将随着bindata-demo这个二进制程序一并分发与部署。

>> 小结
go generate这个工具通常是由Go包的作者使用和执行的，其生成的Go源码一般会提交到代码仓库中，这个过程对生成的包的使用者来说是透明的。为了提醒使用者这是一个代码自动生成的源文件，我们通常会在源文件的开始处以注释的形式写入类似下面的文字：
// Code generated by XXX. DO NOT EDIT.
本条要点：
◦  尽量使用Go原生的go generate驱动代码生成；
◦  明确go generate应在go build、go run或go test等命令之前执行；
◦  go generate不会按照Go语法解析源文件，它只是将Go源码文件当成普通文本读取并识别其中的go generate指示符；
◦  go generate多用于生成枚举常量类型的String方法、protobuf文件对应的Go源文件，以及将静态资源文件数据嵌入二进制可执行文件中等场景；
◦  go generate多数情况仅被Go包的作者使用，对Go包的使用者透明。

>> 第66条牢记Go的常见“陷阱”

>> C语言像一把雕刻刀，锋利，在技师手中非常有用。但和任何锋利的工具一样，C语言也会伤到那些不能掌握它的人。
——Andrew Koenig
20世纪80年代中期，还在大名鼎鼎的贝尔实验室任职的C语言专家Andrew Koenig发表了一篇名为“C Traps and Pitfalls”（C语言陷阱与缺陷）[1]的论文。若干年后，他以这篇论文为基础，结合自己的工作经验，出版了日后对C程序员影响甚大且极具价值的经典著作《C语言陷阱与缺陷》。无论是论文还是图书，作者Koenig的出发点都不是批判C语言，而是帮助C程序员绕过C语言编程中的陷阱和障碍。

>> 没有哪一种编程语言是完美和理想的，Go语言也不例外。尽管Go语言很简单，但有过一定Go使用经验的开发人员或多或少都掉进过Go的“陷阱”。之所以将“陷阱”二字加上双引号，是因为它们并非真正的语言缺陷，而是一些因对Go语言规范、运行时、标准库及工具链等了解不够全面、深入和透彻而容易犯的错误，或是因语言间的使用差异而导致的误用问题。

>> Go语言虽有“陷阱”，但其数量和影响力与C相比相差甚远，还没有严重到需要将其整理成册出版的地步，

>> 66.1　语法规范类

>> 1. 短变量声明相关的“坑”

>> （1）短变量声明不总是会声明一个新变量

>> 在同一个代码块（block）中，使用多变量短声明语句重新声明已经声明过的变量时，短变量声明语句不会为该变量声明一个新变量，而只会对其重新赋值。

>> （2）短变量声明会导致难于发现的变量遮蔽

>> // chapter10/sources/go-trap/short_declaration_variable_shadowing_2.gofunc foo() (int, error) {    return 11, nil}func bar() (int, error) {    return 21, errors.New("error in bar")}func main() {    var err error    defer func() {        if err != nil {            println("error in defer:", err.Error())        }    }()    a, err := foo()    if err != nil {        return    }    println("a=", a)    if a == 11 {        b, err := bar()        if err != nil {            return        }        println("b=", b)    }    println("no error occurs")}

>> go vet（Go 1.14版）默认已经不再支持变量遮蔽检查了，我们可以单独安装位于Go扩展项目中的shadow工具来实施检查：
$go install golang.org/x/tools/go/analysis/passes/shadow/cmd/shadow$go vet -vettool=$(which shadow) -strict short_declaration_variable_shadowing_2.go./short_declaration_variable_shadowing_2.go:28:6: declaration of "err" shadows declaration at line 14

>> 很多Gopher看到b, err := bar()这行代码后会误以为err不会被重新声明为一个新变量，仅会进行赋值操作，就像前面短声明变量的第一个“坑”中描述的那样。但实际上，由于不在同一个代码块中，编译器没有在同一代码块里找到与b, err := bar()这行代码中err同名的变量，因此会声明一个新err变量，该err变量也就顺理成章地遮蔽了main函数代码块中的err变量。

>> 修正这个问题的方法有很多，最直接的方法就是去掉if代码块中的多变量短声明形式并提前单独声明变量b：
// chapter10/sources/go-trap/short_declaration_variable_shadowing_3.gofunc main() {    ...    var b int    if a == 11 {        b, err = bar()        if err != nil {            return        }        println("b=", b)    }    println("no error occurs")}
这是一个在实际开发过程中经常出现的问题。在不同代码块层次上使用多变量短声明形式会带来难以发现的变量遮蔽问题，从而导致程序运行异常。通过go vet+shadow工具可以很快捷方便地发现这一问题。

>> 2. nil相关的“坑”

>> （1）不是所有以nil作为零值的类型都是零值可用的
这句话读起来有些拗口，我们可以将其分成两部分来理解。
◦  以nil为零值的类型：根据Go语言规范，诸如切片（slice）、map、接口类型和指针类型的零值均为nil。
◦  零值可用的类型：在第11条中，我们学习过什么是零值可用的类型，常见的有sync.Mutex和bytes.Buffer等。Go原生的切片类型只在特定使用方式下才可以被划到零值可用的范畴。

>> 我们看到只有这两部分的交集中的类型才是零值可用的，这个集合中包含特定使用方式下的切片类型、特定的自定义类型指针（仅可以调用没有对自身进行指针解引用的方法）以及特定使用方式下的接口类型，见下面的示例：
// chapter10/sources/go-trap/nil_type_1.gotype foo struct {    name string    age  int}func (*foo) doSomethingWithoutChange() {    fmt.Println("doSomethingWithoutChange")}type MyInterface interface {    doSomethingWithoutChange()}func main() {    // 切片仅在调用append操作时才是零值可用的    var strs []string = nil    strs = append(strs, "hello", "go")    fmt.Printf("%q\n", strs)    // 自定义类型的方法中没有对自身实例解引用的操作时    // 我们可以通过该类型的零值指针调用其方法    var f *foo = nil    f.doSomethingWithoutChange()    // 为接口类型赋予显式类型转换后的nil(并非真正的零值)    // 我们可以通过该接口调用没有解引用操作的方法    var i MyInterface = (*foo)(nil)    i.doSomethingWithoutChange()}
而其他以nil为类型零值的类型（或未在特定使用方式下的上述类型）则不是零值可用的

>> （2）值为nil的接口类型变量并不总等于nil

>> 下面是Go语言中的一个令新手非常迷惑的例子：
// chapter10/sources/go-trap/nil_interface_1.gotype TxtReader struct{}func (*TxtReader) Read(p []byte) (n int, err error) {    // ...    return 0, nil}func NewTxtReader(path string) io.Reader {    var r *TxtReader    if strings.Contains(path, ".txt") {        r = new(TxtReader)    }    return r}func main() {    i := NewTxtReader("/home/tony/test.png")    if i == nil {        println("fail to init txt reader")        return    }    println("init txt reader ok")}
我们一般会以为上述程序执行后会输出“fail to init txt reader”，因为传入的文件并非一个后缀为.txt的文件，函数NewTxtReader会将此时值为nil的变量r作为返回值直接返回。但执行上述程序得到的输出结果却是“init txt reader ok”。
难道值为nil的接口变量i与nil真的不相等？在第26条中我们已经回答了这个问题，接口类型在运行时的表示分为两部分，一部分是类型信息，一部分是值信息。只有当接口类型变量的这两部分的值都为nil时，该变量才与nil相等。为了便于理解，将上述例子简化为下面的代码：
// chapter10/sources/go-trap/nil_interface_2.govar r *TxtReader = nilvar i io.Reader = rprintln(i == nil) // falseprintln(i) // (0x1089720,0x0)
我们看到在接口类型变量i被赋值为值为nil的变量r后，变量i的类型信息部分并不是nil。上面例子中的println(i)输出中的第一个值为0x1089720，这样变量i就与nil不等了。
这个“坑”在我们的日常Go编码过程中会经常出现，而且很难排查，一旦遗留到生产环境中，其造成的后果会很严重。

>> 3. for range相关的“坑”

>> （1）你得到的是序号值而不是元素值

>> // chapter10/sources/go-trap/for_range_1.gofunc main() {    fruits := []string{"banana", "apple", "mango"}    for fruit := range fruits {        println(fruit)    }}
编译并运行上述Go代码，你将看到如下输出：
012

>> （2）针对string类型的for range迭代不是逐字节迭代

>> // chapter10/sources/go-trap/for_range_2.gofunc main() {    for _, s := range "Hi,中国" {        fmt.Printf("0x%X\n", s)    }}
编译并运行上述Go代码，你将看到如下输出结果：
0x480x690x2C0x4E2D0x56FD
输出的结果“似曾相识”啊。没错！在第52条中，我们曾介绍过0x4E2D和0x56FD分别是“中”和“国”这两个汉字的码点。在Go语言中每个Unicode字符码点对应的是一个rune类型的值，也就是说在Go中对字符串运用for range操作，每次返回的是一个码点，而不是一个字节。

>> 那么要想进行逐字节迭代，应该怎么编写代码呢？我们需要先将字符串转换为字节类型切片后再运用for range对字节类型切片进行迭代：
// chapter10/sources/go-trap/for_range_2.gofunc main() {    for _, b := range []byte("Hi,中国") {        fmt.Printf("0x%X\n", b)    }}

>> 在第15条中我们还提到了Go编译器对上述代码中字符串到字节切片转换的优化处理，即Go编译器不会为[]byte进行额外的内存分配，而是直接使用string的底层数据。

>> （3）对map类型内元素的迭代顺序是随机的

>> Go的设计就是如此，要想有序迭代map内的元素，我们需要额外的数据结构支持，比如使用一个切片来有序保存map内元素的key值：
// chapter10/sources/go-trap/for_range_3.gofunc main() {    var indexes []int    heros := map[int]string{        1: "superman",        2: "batman",        3: "spiderman",        4: "the flash",    }    for k, v := range heros {        indexes = append(indexes, k)    }    sort.Ints(indexes)    for _, idx := range indexes {        fmt.Println(heros[idx])    }}

>> （4）在“复制品”上进行迭代

>> 下面是一个对切片进行迭代的例子：
// chapter10/sources/go-trap/for_range_4.gofunc main() {    var a = []int{1, 2, 3, 4, 5}    var r = make([]int, 0)    fmt.Println("a = ", a)    for i, v := range a {        if i == 0 {            a = append(a, 6, 7)        }        r = append(r, v)    }    fmt.Println("r = ", r)    fmt.Println("a = ", a)}
在上面的示例代码中，我们在迭代过程中向切片a中动态添加了新元素6和7，期望这些改变可以反映到新切片r上。但该示例程序的输出如下：
$go run for_range_4.goa =  [1 2 3 4 5]r =  [1 2 3 4 5]a =  [1 2 3 4 5 6 7]
我们看到对原切片a的动态扩容并未在r上得到体现。对a的迭代次数依旧是5次，也没有因a的扩容而变为7次。这是因为range表达式中的a实际上是原切片a的副本（暂称为a'），在该表达式初始化后，副本切片a'内部表示中的len字段就是5，并且在整个for range循环过程中并未改变，因此for range只会循环5次，也就只获取到原切片a所对应的底层数组的前5个元素。
更多关于该“陷阱”的描述和例子可以参见第19条。

>> （5）迭代变量是重用的

>> 在for i, v := range xxx这条语句中，i、v都被称为迭代变量。迭代变量总是会参与到每次迭代的处理逻辑中，就像下面的示例代码这样：
// chapter10/sources/go-trap/for_range_5.gofunc main() {    var a = []int{1, 2, 3, 4, 5}    var wg sync.WaitGroup    for _, v := range a {        wg.Add(1)        go func() {            time.Sleep(time.Second)            fmt.Println(v)            wg.Done()        }()    }    wg.Wait()}
我们期望上面的示例中每个goroutine输出切片a中的一个元素，但实际运行后却发现输出结果如下：
55555
我们之所以会写出上述示例中那样的代码，很可能是因为被for range表达式中的:=迷惑了，认为每次迭代都会重新声明一个循环变量v，但实际上这个循环变量v仅仅被声明了一次并在后续整个迭代过程中被重复使用：
for _, v := range a {}// 等价于v := 0for _, v = range a {}
这样上面示例的输出结果也就不那么令人意外了。新创建的5个goroutine在睡眠（Sleep）1秒后所看到的是同一个变量v，而此时变量v的值为5，所以5个goroutine输出的v值也就都是5。我们可以通过以下方法修正这个示例：
for _, v := range a {    wg.Add(1)    go func(v int) {        time.Sleep(time.Second)        fmt.Println(v)        wg.Done()    }(v)}
在修改后的示例中，每个goroutine输出的是每轮迭代时传入的循环变量v的副本，这个值不会随着迭代的进行而变化。

>> 4. 切片相关的“坑”

>> Go切片相比数组更加高效和灵活，尽量使用切片替代数组是Go语言的惯用法之一

>> Go支持基于已有切片创建新切片（reslicing）的操作，新创建的切片与原切片共享底层存储，这个操作在给Go开发者带来高灵活性和内存占用小等好处的同时，也十分容易让开发者掉入相关“陷阱”。

>> （1）对内存的过多占用

>> 基于已有切片创建的新切片与原切片共享底层存储，这样如果原切片占用较大内存，新切片的存在又使原切片内存无法得到释放，这样就会占用过多内存，如下面的示例：
// chapter10/sources/go-trap/slice_1.gofunc allocSlice(min, high int) []int {    var b = []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 99: 100}    fmt.Printf("slice b: len(%d), cap(%d)\n",        len(b), cap(b))    return b[min:high]}func main() {    b1 := allocSlice(3, 7)    fmt.Printf("slice b1: len(%d), cap(%d), elements(%v)\n",        len(b1), cap(b1), b1)}
在这个例子中，我们基于一个长度（len）和容量（cap）均为100的切片b创建一个长度仅为4的小切片b1，这样通过b1我们仅仅能操纵4个整型值，但b1的存在却使额外的96个整型数占用的空间无法得到及时释放。
我们可以通过内建函数copy为新切片建立独立的存储空间以避免与原切片共享底层存储，从而避免空间的浪费：
// chapter10/sources/go-trap/slice_2.gofunc allocSlice(min, high int) []int {    var b = []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 99: 100}    fmt.Printf("slice b: len(%d), cap(%d)\n",        len(b), cap(b))    nb := make([]int, high-min, high-min)    copy(nb, b[min:high])    return nb}

>> （2）隐匿数据的暴露与切片数据篡改

>> 除了过多的内存占用，slice_1.go这个示例还可能导致隐匿数据的暴露。我们将slice_1.go示例做一下改动：
// chapter10/sources/go-trap/slice_3.gofunc allocSlice(min, high int) []int {    var b = []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}    fmt.Printf("slice b: len(%d), cap(%d), elements(%v)\n",        len(b), cap(b), b)    return b[min:high]}func main() {    b1 := allocSlice(3, 7)    fmt.Printf("slice b1: len(%d), cap(%d), elements(%v)\n",        len(b1), cap(b1), b1)    b2 := b1[:6]    fmt.Printf("slice b2: len(%d), cap(%d), elements(%v)\n",        len(b2), cap(b2), b2)}
在该示例中，通过allocSlice函数分配的切片b1又被做了一次reslicing，由于b1的容量为7，因此对其进行reslicing时采用b1[:6]并不会出现越界问题。上述示例的运行结果如下：
$go run slice_3.goslice b: len(10), cap(10), elements([1 2 3 4 5 6 7 8 9 10])slice b1: len(4), cap(7), elements([4 5 6 7])slice b2: len(6), cap(7), elements([4 5 6 7 8 9])
以上示例显然期望通过reslicing创建的b2是这样的：[4 5 6 7 0 0]。但事与愿违，由于b1、b2、b三个切片共享底层存储，使得原先切片b对切片b1隐匿的数据在切片b2中暴露了出来。
但切片b2对这种隐匿数据的存在可能毫不知情，这样当切片b2操作这两个位置的数据时，实际上会篡改原切片b本不想暴露给切片b1的那些数据。
我们依然可以采用通过内建函数copy为新切片建立独立存储空间的方法来应对这个“陷阱”。它避免了利用容量漏洞对新分配的切片进行扩张式的reslicing操作导致的隐匿数据暴露，看不到隐匿数据，自然也就无法实施篡改操作了：
// chapter10/sources/go-trap/slice_4.gofunc allocSlice(min, high int) []int {    var b = []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}    fmt.Printf("slice b: len(%d), cap(%d), elements(%v)\n",        len(b), cap(b), b)    nb := make([]int, high-min, high-min)    copy(nb, b[min:high])    return nb}

>> func main() {    b1 := allocSlice(3, 7)    fmt.Printf("slice b1: len(%d), cap(%d), elements(%v)\n",        len(b1), cap(b1), b1)    b2 := b1[:6]    fmt.Printf("slice b2: len(%d), cap(%d), elements(%v)\n",        len(b2), cap(b2), b2) // panic: runtime error: slice bounds out of range [:6] with capacity 4}

>> （3）新切片与原切片底层存储可能会“分家”

>> Go中的切片支持自动扩容。当扩容发生时，新切片与原切片底层存储便会出现“分家”现象。一旦发生“分家”，后续对新切片的任何操作都不会影响到原切片：
// chapter10/sources/go-trap/slice_5.gofunc main() {    var b = []int{1, 2, 3, 4}    fmt.Printf("slice b: len(%d), cap(%d), elements(%v)\n",        len(b), cap(b), b)    b1 := b[:2]    fmt.Printf("slice b1: len(%d), cap(%d), elements(%v)\n",        len(b1), cap(b1), b1)    fmt.Println("\nappend 11 to b1:")    b1 = append(b1, 11)    fmt.Printf("slice b1: len(%d), cap(%d), elements(%v)\n",        len(b1), cap(b1), b1)    fmt.Printf("slice b: len(%d), cap(%d), elements(%v)\n",        len(b), cap(b), b)    fmt.Println("\nappend 22 to b1:")    b1 = append(b1, 22)    fmt.Printf("slice b1: len(%d), cap(%d), elements(%v)\n",        len(b1), cap(b1), b1)    fmt.Printf("slice b: len(%d), cap(%d), elements(%v)\n",        len(b), cap(b), b)    fmt.Println("\nappend 33 to b1:")    b1 = append(b1, 33)    fmt.Printf("slice b1: len(%d), cap(%d), elements(%v)\n",        len(b1), cap(b1), b1)    fmt.Printf("slice b: len(%d), cap(%d), elements(%v)\n",        len(b), cap(b), b)    b1[0] *= 100    fmt.Println("\nb1[0] multiply 100:")    fmt.Printf("slice b1: len(%d), cap(%d), elements(%v)\n",        len(b1), cap(b1), b1)    fmt.Printf("slice b: len(%d), cap(%d), elements(%v)\n",        len(b), cap(b), b)}

>> 运行该示例：
$go run slice_5.goslice b: len(4), cap(4), elements([1 2 3 4])slice b1: len(2), cap(4), elements([1 2])append 11 to b1:slice b1: len(3), cap(4), elements([1 2 11])slice b: len(4), cap(4), elements([1 2 11 4])append 22 to b1:slice b1: len(4), cap(4), elements([1 2 11 22])slice b: len(4), cap(4), elements([1 2 11 22])append 33 to b1:slice b1: len(5), cap(8), elements([1 2 11 22 33])slice b: len(4), cap(4), elements([1 2 11 22])b1[0] multiply 100:slice b1: len(5), cap(8), elements([100 2 11 22 33])slice b: len(4), cap(4), elements([1 2 11 22])
从示例输出结果中我们看到，在将22附加（append）到切片b1后，切片b1的空间已满（len(b1)==cap(b1)）。之后当我们将33附加到切片b1的时候，切片b1与b发生了底层存储的“分家”，Go运行时为切片b1重新分配了一段内存（容量为原容量的2倍）并将数据复制到新内存块中。这次我们看到切片b并没有改变，依旧保持了附加22后的状态。由于存储“分家”，后续我们将b1[0]乘以100的操作同样不会对切片b有任何影响。

>> 5. string相关的“坑”

>> string在Go语言中是原生类型，这与C语言使用字节数组模拟字符串类型不同，并且Go中的string类型没有结尾'\0'，其长度为string类型底层数组中的字节数量：
// chapter10/sources/go-trap/string_1.gos := "大家好"fmt.Printf("字符串\"%s\"的长度为%d\n", s, len(s)) // 长度为9
注意，字符串长度并不等于该字符串中的字符个数：
// chapter10/sources/go-trap/string_1.gos := "大家好"fmt.Printf("字符串\"%s\"中的字符个数%d\n", s, utf8.RuneCountInString(s)) // 字符个数为3

>> string类型支持下标操作符[]，我们可以通过下标操作符读取字符串中的每一字节：
// chapter10/sources/go-trap/string_1.gos1 := "hello"fmt.Printf("s1[0] = %c\n", s1[0]) // s1[0] = hfmt.Printf("s1[1] = %c\n", s1[1]) // s1[1] = e
但如果你将下标操作符表达式作为左值，你将得到如下编译错误：
// chapter10/sources/go-trap/string_1.gos1 := "hello"s[0] = 'j'$go run string_1.go./string_1.go:16:7: cannot assign to s[0]
这是因为在Go中string类型是不可改变的，我们无法改变其中的数据内容。那些尝试将string转换为切片再修改的方案其实修改的都是切片自身，原始string的数据并未发生改变：
// chapter10/sources/go-trap/string_1.gob := []byte(s1)b[0] = 'j'fmt.Printf("字符串s1 = %s\n", s1) // 字符串s1 = hellofmt.Printf("切片b = %q\n", b)     // 切片b = "jello"
string类型的零值是" "，而不是nil，因此判断一个string类型变量是否内容为空，可以将其与" "比较，或将其长度（len(s)）与0比较，而不要将string类型与nil比较：
// chapter10/sources/go-trap/string_1.govar s2 stringfmt.Println(s2 == "")     // truefmt.Println(len(s2) == 0) // truefmt.Println(s2 == nil)    // invalid operation: s2 == nil (mismatched types string and nil)

>> 6. switch语句相关的“坑”

>> 在C语言中，如果没有在case中显式放置break语句，执行流就会从匹配到的case语句开始一直向下执行，于是我们就会在C语言中看到大量break充斥在switch语句中。而在Go中，switch的执行流则并不会从匹配到的case语句开始一直向下执行，而是执行完case语句块代码后跳出switch语句，除非你显式使用fallthrough强制向下一个case语句执行。所以下面的Go代码不会出现上面C语句的问题：
// chapter10/sources/go-trap/switch_1.gofunc main() {    var a = 1    switch a {    case 0:        println("a = 0")    case 1:        println("a = 1") // 输出a = 1    case 2:        println("a = 2")    default:        println("a = N/A")    }}
事实上，这并不能算是Go语言的“坑”，更应该理解为Go语言修正了C语言中switch/case语句的“缺陷”，只是由于“习惯”用法不同而导致的误用。

>> 7. goroutine相关的“坑”

>> （1）无法得到goroutine退出状态

>> 在使用线程作为最小并发调度单元的时代，我们可以通过pthread库的pthread_join函数来阻塞，等待某个线程退出并得到其退出状态：
// pthread_join函数原型// 通过第二个参数可以获得线程的退出状态int pthread_join(pthread_t thread, void **value_ptr);
但当你使用goroutine来架构你的并发程序时，你会发现在没有外部结构支撑的情况下，Go原生并不支持获取某个goroutine的退出状态，因为启动一个goroutine的标准代码是这样的：
go func() {    ...}()
而不是这样的：
ret := go func() {    ...}()
在传统的线程并发模型中，获取线程退出返回值是一种线程间通信，而在Go的并发模型中，这也算是goroutine间通信范畴。提到goroutine间通信，我们首先想到的就是使用channel。没错，利用channel，我们可以轻松获取goroutine的退出状态：
// chapter10/sources/go-trap/goroutine_1.gofunc main() {    c := make(chan error, 1)    go func() {        // 做点什么        time.Sleep(time.Second * 2)        c <- nil // 或c <- errors.New("some error")    }()    err := <-c    fmt.Printf("sub goroutine exit with error: %v\n", err)}
当然，获取goroutine退出状态的手段可不止这一种，更多关于goroutine并发模式和应用的例子可详见第33条，你也许能受到更多启发。

>> （2）程序随着main goroutine退出而退出，不等待其他goroutine

>> Go语言中存在一个残酷的事实，那就是程序退出与否全看main goroutine是否退出，一旦main goroutine退出了，这时即便有其他goroutine仍然在运行，程序进程也会毫无顾忌地退出，其他goroutine正在进行的处理工作就会戛然而止。比如下面这个示例：
// chapter10/sources/go-trap/goroutine_2.gofunc main() {    println("main goroutine: start to work...")    go func() {        println("goroutine1: start to work...")        time.Sleep(50 * time.Microsecond)        println("goroutine1: work done!")    }()    go func() {        println("goroutine2: start to work...")        time.Sleep(30 * time.Microsecond)        println("goroutine2: work done!")    }()    println("main goroutine: work done!")}
运行上面示例，我们可以得到下面的输出结果（注：你的运行结果可能与这里的稍有不同，但极少会有goroutine1和goroutine2在main goroutine退出前已经处理完成的情况）：
$go run goroutine_2.gomain goroutine: start to work...main goroutine: work done!

>> main goroutine丝毫没有顾及正在运行的goroutine1和goroutine2就退出了，这让goroutine1和goroutine2还未输出哪怕是一行日志就被强制终止了。
通常我们可以使用sync.WaitGroup来协调多个goroutine。以上面的代码为例，我们会在main goroutine中使用sync.WaitGroup来等待其他两个goroutine完成工作：
// chapter10/sources/go-trap/goroutine_3.gofunc main() {    var wg sync.WaitGroup    wg.Add(2)    println("main goroutine: start to work...")    go func() {        println("goroutine1: start to work...")        time.Sleep(50 * time.Microsecond)        println("goroutine1: work done!")        wg.Done()    }()    go func() {        println("goroutine2: start to work...")        time.Sleep(30 * time.Microsecond)        println("goroutine2: work done!")        wg.Done()    }()    wg.Wait()    println("main goroutine: work done!")}
运行这段新程序，就会得到我们期望的结果：
$go run goroutine_3.gomain goroutine: start to work...goroutine2: start to work...goroutine1: start to work...goroutine2: work done!goroutine1: work done!main goroutine: work done!

>> （3）任何一个goroutine出现panic，如果没有及时捕获，那么整个程序都将退出

>> Go语言规范在讲述panic时告诉了我们一个更为残酷的现实：如果某个goroutine在函数/方法F的调用时出现panic，一个被称为panicking的过程将被激活。该过程会先调用函数F的defer函数（如果有的话），然后依次向上，调用函数F的调用者的defer函数，直至该goroutine的顶层函数，即启动该goroutine时（go T()）的那个函数T。如果函数T有defer函数，那么defer会被调用。在整个panicking过程的defer调用链中，如果没有使用recover捕获该panic，那么panicking过程的最后一个环节将会发生：整个程序异常退出，并输出panic相关信息，无论发生panic的goroutine是否为main goroutine。看下面的示例：
// chapter10/sources/go-trap/goroutine_4.gofunc main() {    var wg sync.WaitGroup    wg.Add(2)    println("main goroutine: start to work...")    go func() {        println("goroutine1: start to work...")        time.Sleep(5 * time.Second)        println("goroutine1: work done!")        wg.Done()    }()    go func() {        println("goroutine2: start to work...")        time.Sleep(1 * time.Second)        panic("division by zero")        println("goroutine2: work done!")        wg.Done()    }()    wg.Wait()    println("main goroutine: work done!")}
运行这个示例，我们将得到如下结果：
$go run goroutine_4.gomain goroutine: start to work...goroutine2: start to work...goroutine1: start to work...panic: division by zero...
我们看到goroutine2的panic导致goroutine1和main goroutine尚未完成处理就因进程退出而停止了。这个“坑”带来的危害是极大的，你能想象出一个服务端守护程序的进程运行着运行着就消失了的情况吗？同时，由于goroutine的轻量特质，开发者可以在任何代码中随意启动一个goroutine，因此你无法保证你的程序依赖的第三方包中是否启动了存在panic可能性的goroutine，这就像是一颗定时炸弹，随时可能被引爆。

>> 那么如何避免呢？没有好办法，只能采用防御型代码，即在每个goroutine的启动函数中加上对panic的捕获逻辑。对上面的示例的改造如下：
// chapter10/sources/go-trap/goroutine_5.go

func safeRun(g func()) {
	defer func() {
		if e := recover(); e != nil {
			fmt.Println("caught a panic:", e)
		}
	}()
	g()
}
func main() {
	var wg sync.WaitGroup
	wg.Add(2)
	println("main goroutine: start to work...")
	go safeRun(func() {
		defer wg.Done()
		println("goroutine1: start to work...")
		time.Sleep(5 * time.Second)
		println("goroutine1: work done!")
	})
	go safeRun(func() {
		defer wg.Done()
		println("goroutine2: start to work...")
		time.Sleep(1 * time.Second)
		panic("division by zero")
		println("goroutine2: work done!")
	})
	wg.Wait()
	println("main goroutine: work done!")
}


运行该示例：
$go run goroutine_5.gomain goroutine: start to work...goroutine2: start to work...goroutine1: start to work...caught a panic: division by zerogoroutine1: work done!main goroutine: work done!
我们看到goroutine2抛出的panic被safeRun函数捕获，这样panicking过程终止，main goroutine和goroutine1才能得以“善终”。
不过有些时候，panic的确是由自己的代码bug导致的，及时退出程序所产生的影响可能比继续“带病”运行更小，而另一种适合大规模并行处理的高可靠性编程语言Erlang就崇尚“任其崩溃”的设计哲学，因此面对是否要捕获panic的情况，我们也不能“一刀切”，也要视具体情况而定。

>> 8. channel相关的“坑”

>> 日常进行Go开发时，我们一般面对的都是有效状态（已初始化，尚未关闭）下的channel实例，但channel还有另外两种特殊状态：
◦  零值channel（nil channel）；
◦  已关闭的channel（closed channel）。
Go新手面对这两种特殊状态下的channel极易掉入“坑”中。为了避免掉“坑”，建议牢记这两种状态下的channel行为特征，见表66-1。
表66-1　两种特殊状态下的channel行为特征


>> 通过下面的示例我们可以更直观地看到两种特殊状态channel的行为特征：
// chapter10/sources/go-trap/channel_1.gofunc main() {    var nilChan chan int    nilChan <- 5   // 阻塞    n := <-nilChan // 阻塞    fmt.Println(n)    var closedChan = make(chan int)    close(closedChan)    m := <-closedChan    fmt.Println(m)  // int类型的零值：0    closedChan <- 5 // panic: send on closed channel}
更多关于channel的例子可再仔细阅读一下第34条。

>> 9. 方法相关的“坑”

>> （

>> 1）使用值类型receiver的方法无法改变类型实例的状态
Go语言的方法（method）很独特，除了参数和返回值，它还拥有一个代表着类型实例的receiver。receiver有两类：值类型receiver和指针类型receiver。而采用值类型receiver的方法无法改变类型实例的状态。

>> // chapter10/sources/go-trap/mehtod_1.gotype foo struct {    name string    age  int}func (f foo) setNameByValueReceiver(name string) {    f.name = name}func (p *foo) setNameByPointerReceiver(name string) {    p.name = name}func main() {    f := foo{        name: "tony",        age:  20,    }    fmt.Println(f) // {tony 20}    f.setNameByValueReceiver("alex")    fmt.Println(f) // {tony 20}    f.setNameByPointerReceiver("alex")    fmt.Println(f) // {alex 20}}
之所以会如此，是因为方法本质上是一个以receiver为第一个参数的函数。我们知道，通过传值方式传递的参数即便在函数内部被改变，其改变也不会影响到外部的实参。更多关于方法本质的内容可再仔细阅读第23条。

>> （2）值类型实例可以调用采用指针类型receiver的方法，指针类型实例也可以调用采用值类型receiver的方法
Go语言在方法调用时引入了语法糖以支持值类型实例调用采用指针类型receiver的方法，同时支持指针类型实例调用采用值类型receiver的方法。Go会在后台进行对应的转换：
// chapter10/sources/go-trap/mehtod_2.gotype foo struct{}func (foo) methodWithValueReceiver() {    println("methodWithValueReceiver invoke ok")}func (*foo) methodWithPointerReceiver() {    println("methodWithPointerReceiver invoke ok")}func main() {    f := foo{}    pf := &f    f.methodWithPointerReceiver() // 值类型实例调用采用指针类型receiver的方法 ok    pf.methodWithValueReceiver()  // 指针类型实例调用采用值类型receiver的方法 ok}
在上面的示例中，Go编译器会将f.methodWithPointerReceiver()自动转换为(&f).method-WithPointerReceiver()，同理也会将pf.methodWithValueReceiver自动转换为(*pf).methodWithValue-Receiver。
不过这个语法糖的影响范围也就局限在类型实例调用方法这个范畴。当我们将类型实例赋值给某个接口类型变量时，只有真正实现了该接口类型的实例类型才能赋值成功：
// chapter10/sources/go-trap/mehtod_2.gotype fooer interface {    methodWithPointerReceiver()}func main() {    f := foo{}    pf := &f    // var i fooer = f  // 错误：f并未实现methodWithPointerReceiver    var i fooer = pf // ok    i.methodWithPointerReceiver()}
foo值类型并未实现fooer接口的methodWithPointerReceiver方法，因此无法被赋值给fooer类型变量。关于类型方法集合与接口实现的内容，可以再仔细阅读第24条。

>> 10. break语句相关的“坑”

>> 一般break语句都是用来跳出某个for循环的，但在Go中，如果for循环与switch或select联合使用，我们就很可能掉入break的“坑”中，见下面的示例：
// chapter10/sources/go-trap/break_1.gofunc breakWithForSwitch(b bool) {    for {        time.Sleep(1 * time.Second)        fmt.Println("enter for-switch loop!")        switch b {        case true:            break        case false:            fmt.Println("go on for-switch loop!")        }    }    fmt.Println("exit breakWithForSwitch")}func breakWithForSelect(c <-chan int) {    for {        time.Sleep(1 * time.Second)        fmt.Println("enter for-select loop!")        select {        case <-c:            break        default:            fmt.Println("go on for-select loop!")        }    }    fmt.Println("exit breakWithForSelect")}func main() {    go func() {        breakWithForSwitch(true)    }()    c := make(chan int, 1)    c <- 11    breakWithForSelect(c)}
运行该示例：
$go run break_1.goenter for-select loop!enter for-switch loop!enter for-switch loop!enter for-select loop!go on for-select loop!enter for-switch loop!...
我们看到无论是switch内的break还是select内的break，都没有跳出各自最外层的for循环，而仅仅跳出了switch或select代码块，但这就是Go语言break语句的原生语义：不接标签（label）的break语句会跳出最内层的switch、select或for代码块。

>> 如果要跳出最外层的循环，我们需要为该循环定义一个标签，并让break跳到这个标签处。改造后的代码如下（仅以for switch为例）：
// chapter10/sources/go-trap/break_2.gofunc breakWithForSwitch(b bool) {outerloop:    for {        time.Sleep(1 * time.Second)        fmt.Println("enter for-switch loop!")        switch b {        case true:            break outerloop        case false:            fmt.Println("go on for-switch loop!")        }    }    fmt.Println("exit breakWithForSwitch")}
运行改造后的例子，我们能看到输出与我们的预期一致：
$go run break_2.goenter for-switch loop!exit breakWithForSwitchenter for for-select loop!exit breakWithForSelect

>> 66.2　标准库类

>> 标准库也在演进，在这里（Go 1.14）被视为“坑”的用法或行为，在Go后续版本中可能会有所改善甚至被消除。

>> 1. time包相关的“坑”

>> 在第53条中我们曾详细介绍了Go语言采用的参考时间（reference time）方案。使用参考时间构造出的时间格式串与最终输出串是一模一样的，这就省去了程序员再次在大脑中对格式串进行解析的过程：
// chapter10/sources/go-trap/time_1.gofunc main() {    fmt.Println(time.Now().Format("2006年01月02日 15时04分05秒"))        // 输出：2020年06月18日  12时27分32秒}

>> 2. encoding/json包相关的“坑”

>> （1）未导出的结构体字段不会被编码到JSON文本中

>> json包默认仅对结构体中的导出字段（字段名首字母大写）进行编码，非导出字段并不会被编码。解码时亦是如此

>> 除了json，在Go标准库的encoding目录下的各类编解码包（如xml、gob等）也都遵循相同的规则。

>> （2）nil切片和空切片可能被编码为不同文本

>> nil切片就是指尚未初始化的切片，Go运行时尚未为其分配存储空间；而空切片则是已经初始化了的切片，Go运行时为其分配了存储空间，但该切片的长度为0

>> // chapter10/sources/go-trap/json_2.govar nilSlice []intvar emptySlice = make([]int, 0, 5)println(nilSlice == nil)   // trueprintln(emptySlice == nil) // falseprintln(nilSlice, len(nilSlice), cap(nilSlice))       // [0/0]0x0 0 0println(emptySlice, len(emptySlice), cap(emptySlice)) // [0/5]0xc00001e150 0 5
json包在编码时会区别对待这两种切片：
// chapter10/sources/go-trap/json_2.gom := map[string][]int{    "nilSlice":   nilSlice,    "emptySlice": emptySlice,}b, _ := json.Marshal(m)println(string(b))
上面json编码后的文本为：
{"emptySlice":[],"nilSlice":null}
我们看到空切片被编码为[]，而nil切片则被编码为null。

>> （3）字节切片可能被编码为base64编码的文本

>> 一般情况下，字符串与字节切片的区别在于前者存储的是合法Unicode字符的utf-8编码，而字节切片中可以存储任意字节序列。因此，json包在编码时会区别对待这两种类型数据：
func main() {    m := map[string]interface{}{        "byteSlice": []byte("hello, go"),        "string":    "hello, go",    }    b, _ := json.Marshal(m)    fmt.Println(string(b)) // {"byteSlice":"aGVsbG8sIGdv","string":"hello, go"}}
我们看到字节切片被编码为一个base64编码的文本。可以用下面的命令将其还原：
$echo "aGVsbG8sIGdv" | base64 -Dhello, go
笔者觉得这个“坑”有其合理性，毕竟字节切片可以存储任意字节序列，可能会包含控制字符、字符“\0”及不合法Unicode字符等无法显示或导致乱码的内容。如果你的字节切片中存储的仅是合法Unicode字符的utf-8编码字节，又不想将其编码为base64输出，那么可以先将其转换为string类型后再用json包进行编码处理。

>> （4）当JSON文本中的整型数值被解码为interface{}类型时，其底层真实类型为float64

>> 很多时候JSON文本中的字段不确定，我们常用map[string]interface{}来存储json包解码后的数据，这样JSON字段值就会被存储在一个interface{}变量中。通过类型断言来获取其中存储的整型值，改造后的例子如下：
// chapter10/sources/go-trap/json_4.gofunc flexibleJsonUnmarshal() {    s := `{"age": 23, "name": "tony"}`    m := map[string]interface{}{}    _ = json.Unmarshal([]byte(s), &m)    age := m["age"].(int) // panic: interface conversion: interface {} is float64, not int    fmt.Println("age =", age)}
我们看到运行这个示例后出现了panic！panic的内容很清楚：interface{}的底层类型是float64，而不是int。
怎么填这个小“坑”呢？json包提供了Number类型来存储JSON文本中的各类数值类型，并可以转换为整型（int64）、浮点型（float64）及字符串。结合json.Decoder，我们来修正一下上面示例中的问题：
// chapter10/sources/go-trap/json_4.gofunc flexibleJsonUnmarshalImproved() {    s := `{"age": 23, "name": "tony"}`    m := map[string]interface{}{}    d := json.NewDecoder(strings.NewReader(s))    d.UseNumber()    _ = d.Decode(&m)    age, _ := m["age"].(json.Number).Int64()    fmt.Println("age =", age) // age = 23}

>> 3. net/http包相关的“坑”

>> （1）http包需要我们手动关闭Response.Body
通过http包我们很容易实现一个HTTP客户端，比如：
// chapter10/sources/go-trap/http_1.go
func main() {    
	resp, err := http.Get("https://tip.golang.org")    
	if err != nil {        
		fmt.Println(err)        
		return    
	}    
	body, err := ioutil.ReadAll(resp.Body)    
	if err != nil {        
		fmt.Println(err)        
		return    
	}    
	fmt.Println(string(body))
}
这个示例通过http.Get获取某个网站的页面内容，然后读取应答Body字段中的数据并输出到命令行控制台上。但仅仅这么做还不够，因为http包需要我们配合完成一项任务：务必关闭resp.Body。
// chapter10/sources/go-trap/http_1.go
resp, err := http.Get("https://tip.golang.org")
if err != nil {    
	fmt.Println(err)    
	return
}
defer resp.Body.Close()
目前http包的实现逻辑是只有当应答的Body中的内容被全部读取完毕且调用了Body.Close()，默认的HTTP客户端才会重用带有keep-alive标志的HTTP连接，否则每次HTTP客户端发起请求都会单独向服务端建立一条新的TCP连接，这样做的消耗要比重用连接大得多。
注：仅在作为客户端时，http包才需要我们手动关闭Response.Body；如果是作为服务端，http包会自动处理Request.Body。

>> （2）HTTP客户端默认不会及时关闭已经用完的HTTP连接
如果一个HTTP客户端与一个HTTP服务端之间要持续通信，那么向服务端建立一条带有keep-alive标志的HTTP长连接并重用该连接收发数据是十分必要的，也是最有效率的。但是如果我们的业务逻辑是向不同服务端快速建立连接并在完成一次数据收发后就放弃该连接，那么我们需要及时关闭HTTP连接以及时释放该HTTP连接占用的资源。
但Go标准库HTTP客户端的默认实现并不会及时关闭已经用完的HTTP连接（仅当服务端主动关闭或要求关闭时才会关闭），这样一旦连接建立过多又得不到及时释放，就很可能会出现端口资源或文件描述符资源耗尽的异常。

>> 及时释放HTTP连接的方法有两种，第一种是将http.Request中的字段Close设置为true：
// chapter10/sources/go-trap/http_2.govar sites = []string{    "https://tip.golang.org",    "https://www.oracle.com/java",    "https://python.org",}func main() {    var wg sync.WaitGroup    wg.Add(len(sites))    for _, site := range sites {        site := site        go func() {            defer wg.Done()            req, err := http.NewRequest("GET", site, nil)            if err != nil {                fmt.Println(err)                return            }            req.Close = true            resp, err := http.DefaultClient.Do(req)            if err != nil {                fmt.Println(err)                return            }            defer resp.Body.Close()            body, err := ioutil.ReadAll(resp.Body)            if err != nil {                fmt.Println(err)                return            }            fmt.Printf("get response from %s, resp length = %d\n", site, len(body))        }()    }    wg.Wait()}
该示例并没有直接使用http.Get函数，而是自行构造了http.Request，并将其Close字段设置为true，然后通过http包的DefaultClient将请求发送出去，当收到并读取完应答后，http包就会及时关闭该连接。下面是示例的运行结果：
$go run http_2.goget response from https://www.oracle.com/java, resp length = 65458get response from https://python.org, resp length = 49111get response from https://tip.golang.org, resp length = 10599

>> 第二种方法是通过创建一个http.Client新实例来实现的（不使用DefaultClient）：
// chapter10/sources/go-trap/http_3.gofunc main() {    var wg sync.WaitGroup    wg.Add(len(sites))    tr := &http.Transport{        DisableKeepAlives: true,    }    cli := &http.Client{        Transport: tr,    }    for _, site := range sites {        site := site        go func() {            defer wg.Done()            resp, err := cli.Get(site)            if err != nil {                fmt.Println(err)                return            }            defer resp.Body.Close()            body, err := ioutil.ReadAll(resp.Body)            if err != nil {                fmt.Println(err)                return            }            fmt.Printf("get response from %s, resp length = %d\n", site, len(body))        }()    }    wg.Wait()}
在该方案中，新创建的Client实例的字段Transport的DisableKeepAlives属性值为true，即设置了与服务端不保持长连接，这样使用该Client实例与服务端收发数据后会及时关闭两者之间的HTTP连接。

>> 小结
Go语言是云计算时代的C语言，它同样像一把雕刻刀，锋利无比，在熟练的Gopher技师手里非常强大。但Go语言也会伤到那些对它理解不够、还不能掌握它的人。熟知并牢记上述Go的常见“陷阱”将帮助他们免受伤害或将伤害降到最低，直到他们成为熟练掌控Go语言的工程师。

