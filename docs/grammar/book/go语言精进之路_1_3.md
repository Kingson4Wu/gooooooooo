
# 第六部分 并发编程

## 第31条 优先考虑并发设计

+ 优先考虑并发设计并发不是并行，并发关乎结构，并行关乎执行。——Rob Pike，Go语言之父

+ Go语言以原生支持并发（Concurrency）著称，那么到底什么是并发？并发与并行（Parallelism）又有何种联系和区别？


### 31.1 并发与并行


>> 要想充分利用多核的强大计算能力，一般有两种方案。1. 并行方案如图31-1所示，并行方案就是在处理器核数充足的情况下启动多个单线程应用的实例，这样每个实例“运行”在一个核上（如图中的CPU核1～CPU核N），尽可能多地利用多核计算资源。理论上在这种方案下应用的整体处理能力是与实例数量（小于或等于处理器核数）成正比的。但这种方案是有约束的，对于那些不支持在同一环境下部署多实例或同一用户仅能部署一个实例的应用，用传统的部署方式使之并行运行是有难度的甚至是无法实现的。不过近些年兴起的轻量级容器技术（如Docker）可以在一定程度上促成此方案，有兴趣的读者可以深入了解一下。[插图]图31-1　传统单线程应用的并行方案2. 并发方案如图31-2所示，简单来说，并发就是重新做应用结构设计，即将应用分解成多个在基本执行单元（图中这样的执行单元为操作系统线程）中执行的、可能有一定关联关系的代码片段（图中的模块1～模块N）。我们看到与并行方案中应用自身结构无须调整有所不同，并发方案中应用自身结构做出了较大调整，应用内部拆分为多个可独立运行的模块。这样虽然应用仍然以单实例的方式运行，但其中的每个内部模块都运行于一个单独的操作系统线程中，多核资源得以充分利用。[插图]图31-2　传统单线程应用的并发方案

>> 在传统编程语言（如C++、Java）中，基于多线程模型的应用设计就是一种典型的并发程序设计。但传统编程语言并非面向并发而生，没有对并发设计提供过多的帮助，并且这些语言多以操作系统线程作为承载分解后的代码片段（模块）的执行单元，由操作系统执行调度。我们知道传统操作系统线程的创建、销毁以及线程间上下文切换的代价都较大，线程的接口还多以标准库的形式提供，线程间通信原语也不足或比较低级，用户层接口较为晦涩难懂，开发体验自然大打折扣。

+ Go语言的设计哲学之一是“原生并发，轻量高效”。Go并未使用操作系统线程作为承载分解后的代码片段（模块）的基本执行单元，而是实现了goroutine这一由Go运行时负责调度的用户层轻量级线程为并发程序设计提供原生支持。

>> goroutine相比传统操作系统线程而言具有如下优势

>> 1）资源占用小，每个goroutine的初始栈大小仅为2KB。
```go
// $GOROOT/src/runtime/stack.go 
const (    
	...    // Go代码使用的最小栈空间大小    
_StackMin = 2048
)
```

>> 2）由Go运行时而不是操作系统调度，goroutine上下文切换代价较小。3）语言原生支持：goroutine由go关键字接函数或方法创建，函数或方法返回即表示goroutine退出，开发体验更佳。4）语言内置channel作为goroutine间通信原语，为并发设计提供强大支撑。

>> 我们看到，和传统编程语言不同的是，Go语言是面向并发而生的。因此，在应用的结构设计阶段，Go的惯例是优先考虑并发设计。这样做更多是考虑到随着外界环境的变化，经过并发设计的Go应用可以更好、更自然地适应规模化。比如：在应用被分配到更多计算资源，或计算处理硬件增配后，Go应用无须进行结构调整即可充分利用新增的计算资源。此外，经过并发设计的Go应用会更加便于Gopher的开发分工与协作。


### 31.2 Go并发设计实例

>> 1. 第一版：顺序设计

```go
// chapter6/sources/concurrency-design-airport-securitycheck-1.go 
const (    
	idCheckTmCost   = 60    
	bodyCheckTmCost = 120    
	xRayCheckTmCost = 180
)
func idCheck() int {    
	time.Sleep(time.Millisecond * time.Duration(idCheckTmCost))    
	println("\tidCheck ok")    
	return idCheckTmCost
}
func bodyCheck() int {    
	time.Sleep(time.Millisecond * time.Duration(bodyCheckTmCost))    
	println("\tbodyCheck ok")    
	return bodyCheckTmCost
}
func xRayCheck() int {    
	time.Sleep(time.Millisecond * time.Duration(xRayCheckTmCost))    
	println("\txRayCheck ok")    
	return xRayCheckTmCost
}
func airportSecurityCheck() int {    
	println("airportSecurityCheck ...")    
	total := 0        
	total += idCheck()    
	total += bodyCheck()    
	total += xRayCheck()        
	println("airportSecurityCheck ok")    
	return total
}
func main() {    
	total := 0    
	passengers := 30    
	for i := 0; i < passengers; i++ {        
		total += airportSecurityCheck()    
	}    
	println("total time cost:", total)
}
```
机场初期仅开通一条安检通道，如果要对30名旅客进行安检，需要消耗的时间可通过运行上述程序得到：
`$ go run concurrency-design-airport-securitycheck-1.go airportSecurityCheck ...    idCheck ok    bodyCheck ok    xRayCheck okairportSecurityCheck ok...airportSecurityCheck ...    idCheck ok    bodyCheck ok    xRayCheck okairportSecurityCheck oktotal time cost: 10800`

>> 2. 第二版：并行方案

>> 随着机场旅客量日益增大，一条安检通道显得捉襟见肘，旅客开始抱怨安检效率太低，排队等待时间过长。但这时重新设计程序有些来不及了，为了快速满足需求，只能通过开通新安检通道（部署新安检程序）的方式来快速满足旅客快速通检的要求，于是我们就有了下面的并行方案
```go
// chapter6/sources/concurrency-design-airport-securitycheck-2.go 
func idCheck(id int) int {    
	time.Sleep(time.Millisecond * time.Duration(idCheckTmCost))    
	print("\tgoroutine-", id, ": idCheck ok\n")    
	return idCheckTmCost
}
func bodyCheck(id int) int {    
	time.Sleep(time.Millisecond * time.Duration(bodyCheckTmCost))    
	print("\tgoroutine-", id, ": bodyCheck ok\n")    
	return bodyCheckTmCost
}
func xRayCheck(id int) int {    
	time.Sleep(time.Millisecond * time.Duration(xRayCheckTmCost))    
	print("\tgoroutine-", id, ": xRayCheck ok\n")    
	return xRayCheckTmCost
}
func airportSecurityCheck(id int) int {    
	print("goroutine-", id, ": airportSecurityCheck ...\n")    
	total := 0        
	total += idCheck(id)    
	total += bodyCheck(id)    
	total += xRayCheck(id)        
	print("goroutine-", id, ": airportSecurityCheck ok\n")    
	return total
}
func start(id int, f func(int) int, queue <-chan struct{}) <-chan int {    
	c := make(chan int)    
	go func() {        
		total := 0        
		for {            
			_, ok := <-queue            
			if !ok {                
				c <- total                
				return            
			}            
			total += f(id)        
		}    
	}()    
	return c
}
func max(args ...int) int {    
	n := 0    
	for _, v := range args {        
		if v > n {            
			n = v        
		}    
	}    
	return n
}

func main() {    
	total := 0    
	passengers := 30    
	c := make(chan struct{})    
	c1 := start(1, airportSecurityCheck, c)    
	c2 := start(2, airportSecurityCheck, c)    
	c3 := start(3, airportSecurityCheck, c)        
	for i := 0; i < passengers; i++ {        
		c <- struct{}{}    
	}    
	close(c)        
	total = max(<-c1, <-c2, <-c3)    
	println("total time cost:", total)
}
```
为了模拟并行方案，我们对程序作了改动：创建三个goroutine，分别代表三个安检通道，但每个安检通道运行的程序依然是上一版程序中的airportSecurityCheck。三个通道共同处理旅客安检，其运行结果如下：
`$ go run concurrency-design-airport-securitycheck-2.go goroutine-1: airportSecurityCheck ...goroutine-3: airportSecurityCheck ...goroutine-2: airportSecurityCheck ...    goroutine-1: idCheck ok    goroutine-2: idCheck ok    goroutine-3: idCheck ok    goroutine-1: bodyCheck ok    goroutine-3: bodyCheck ok    goroutine-2: bodyCheck ok    goroutine-3: xRayCheck ok    goroutine-1: xRayCheck ok    goroutine-2: xRayCheck okgoroutine-1: airportSecurityCheck okgoroutine-3: airportSecurityCheck okgoroutine-2: airportSecurityCheck ok...total time cost: 3600`
上面程序的输出结果符合我们的预期：开启三个安检通道，运行着相同的安检程序（相当于部署了安检程序的多个实例），安检效率自然是原先的3倍（3600到10800）。

>> 3. 第三版：并发方案

>> 假设机场鉴于现有建设规模，最大只能开通三条安检通道。机场旅客量依旧在增多，即便使用了并行方案，旅客的安检时长也无法再缩短。因为原安检程序采用的是顺序设计，即便机场目前有充足的人手（计算资源）可用，每个安检通道也只能用到一名工作人员。也就是说，原安检程序无法很好地适应工作人员（计算资源）的增加，是时候调整应用的结构了。
原先的安检程序（顺序设计）弊端很明显：当工作人员（计算资源）处于某一个检查环节（如人身检查），其他两个环节便处于“等待”状态。一条很显然的改进思路是让这些环节“同时”运行起来，就像流水线一样，这就是并发（见图31-5）。
```go
// chapter6/sources/concurrency-design-airport-securitycheck-3.go... 
func start(id string, f func(string) int, next chan<- struct{}) (chan<- struct{}, chan<- struct{}, <-chan int) {    
	queue := make(chan struct{}, 10)    
	quit := make(chan struct{})    result := make(chan int)        
	go func() {        
		total := 0        
		for {            
			select {            
				case <-quit:                
				result <- total                
				return            
				case v := <-queue:                
				total += f(id)                
				if next != nil {                    
					next <- v                
				}            
			}        
		}    
	}()    
	return queue, quit, result
}
func newAirportSecurityCheckChannel(id string, queue <-chan struct{}) {    
	go func(id string) {        
		print("goroutine-", id, ": airportSecurityCheckChannel is ready...\n")        // 启动X光检查        
		queue3, quit3, result3 := start(id, xRayCheck, nil)                // 启动人身检查        
		queue2, quit2, result2 := start(id, bodyCheck, queue3)                // 启动身份检查        
		queue1, quit1, result1 := start(id, idCheck, queue2)                
		for {            
			select {            
				case v, ok := <-queue:                
				if !ok {                    
					close(quit1)                    
					close(quit2)                    
					close(quit3)                    
					total := max(<-result1, <-result2, <-result3)                    
					print("goroutine-", id, ": airportSecurityCheckChannel time cost:", total, "\n")                    
					print("goroutine-", id, ": airportSecurityCheckChannel closed\n")                    
					return                
				}                
				queue1 <- v            
			}        
		}    
	}(id)
}

func main() {    
	passengers := 30    
	queue := make(chan struct{}, 30)    
	newAirportSecurityCheckChannel("channel1", queue)    
	newAirportSecurityCheckChannel("channel2", queue)    
	newAirportSecurityCheckChannel("channel3", queue)        
	time.Sleep(5 * time.Second) // 保证上述三个goroutine都已经处于ready状态    
	for i := 0; i < passengers; i++ {        
		queue <- struct{}{}    
	}    
	time.Sleep(5 * time.Second)    
	close(queue) // 为了打印各通道的处理时长    
	time.Sleep(1000 * time.Second) // 防止main goroutine退出
}
```

>> 在这一版程序中，我们模拟开启了三条通道（newAirportSecurityCheckChannel），每条通道创建三个goroutine，分别负责处理idCheck、bodyCheck和xRayCheck，三个goroutine之间通过Go提供的原生channel相连。该程序的运行结果如下：
```
$go run concurrency-design-airport-securitycheck-3.go
goroutine-channel3: airportSecurityCheckChannel is ready...goroutine-channel2: airportSecurityCheckChannel is ready...goroutine-channel1: airportSecurityCheckChannel is ready......goroutine-channel3: airportSecurityCheckChannel time cost:2160goroutine-channel2: airportSecurityCheckChannel time cost:1080goroutine-channel1: airportSecurityCheckChannel time cost:2160goroutine-channel2: airportSecurityCheckChannel closedgoroutine-channel1: airportSecurityCheckChannel closedgoroutine-channel3: airportSecurityCheckChannel closed
```
我们看到，在并发流水线启动预热并正式工作后，30名旅客的安检时长已经从3600下降到2160，并发方案使得安检通道的效率有了进一步提升。如果该流水线持续工作，效率应该会稳定在1200（3600/3）左右。如果计算资源不足，并发方案的每条安检通道的效率最差也就是“回退”到与顺序设计大致等同的水平。
小结
上述机场安检程序的演变过程正契合了Rob Pike的观点：“并发关乎结构，并行关乎执行。”并发和并行是两个阶段的事情。并发在程序的设计和实现阶段，并行在程序的执行阶段。
对并发的原生支持让Go语言更契合云计算时代的硬件，适应现代计算环境。Go语言鼓励在程序设计时优先按并发设计思路组织程序结构，进行独立计算的分解。只有并发设计才能让应用自然适应计算资源的规模化，并显现出更大的威力。


## 第32条 了解goroutine的调度原理


### 32.1 goroutine调度器

>> 传统的编程语言（如C、C++等）的并发实现多是基于线程模型的，即应用程序负责创建线程（一般通过libpthread等库函数调用实现），操作系统负责调度线程。

>> Go采用用户层轻量级线程来解决这些问题，并将之称为goroutine。

>> 由于一个goroutine占用资源很少，一个Go程序中可以创建成千上万个并发的goroutine。而将这些goroutine按照一定算法放到CPU上执行的程序就称为goroutine调度器（goroutine scheduler）。一个Go程序对于操作系统来说只是一个用户层程序，操作系统眼中只有线程，goroutine的调度全要靠Go自己完成。


### 32.2 goroutine调度模型与演进过程

1. G-M模型

2. G-P-M模型

>> 发现了G-M模型的不足后，Dmitry Vyukov亲自操刀改进了goroutine调度器，在Go 1.1版本中实现了G-P-M调度模型和work stealing算法[1]，这个模型一直沿用至今，如图32-1所示。

>> [插图]图32-1　goroutine的G-P-M调度模型

>> 
图32-1　goroutine的G-P-M调度模型

>> 计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决。

>> 他向G-M模型中增加了一个P，使得goroutine调度器具有很好的伸缩性。

>> P是一个“逻辑处理器”，每个G要想真正运行起来，首先需要被分配一个P，即进入P的本地运行队列（local runq）中，这里暂忽略全局运行队列（global runq）那个环节。对于G来说，P就是运行它的“CPU”，可以说在G的眼里只有P。但从goroutine调度器的视角来看，真正的“CPU”是M，只有将P和M绑定才能让P的本地运行队列中的G真正运行起来。这样的P与M的关系就好比Linux操作系统调度层面用户线程（user thread）与内核线程（kernel thread）的对应关系：多对多（N:M）。

>> 3. 抢占式调度

>> Go 1.2版本中实现了抢占式调度。
这个抢占式调度的原理是在每个函数或方法的入口加上一段额外的代码，让运行时有机会检查是否需要执行抢占调度。这种协作式抢占调度的解决方案只是局部解决了“饿死”问题，对于没有函数调用而是纯算法循环计算的G，goroutine调度器依然无法抢占[2]。

>> 4. NUMA调度模型

>> Dmitry Vyukov在2014年9月提出了一个新的设计草案文档“NUMA‐aware scheduler for Go”，作为对未来goroutine调度器演进方向的一个提案，不过这个提案至今也没有被列入开发计划。

>> 5. 其他优化

>> Go运行时已经实现了netpoller，这使得即便G发起网络I/O操作也不会导致M被阻塞（仅阻塞G），因而不会导致大量线程（M）被创建出来。但是对于常规文件的I/O操作一旦阻塞，那么线程（M）将进入挂起状态，等待I/O返回后被唤醒。这种情况下P将与挂起的M分离，再选择一个处于空闲状态（idle）的M。如果此时没有空闲的M，则会新创建一个M（线程），这就是大量文件I/O操作会导致大量线程被创建的原因。
Go开发团队的Ian Lance Taylor在Go 1.9版本中增加了一个针对文件I/O的Poller[3]，它可以像netpoller那样，在G操作那些支持监听的（pollable）文件描述符时，仅阻塞G，而不会阻塞M。不过该功能依然对常规文件无效，常规文件是不支持监听的。但对于goroutine调度器而言，这也算是一个不小的进步了。

>> [2]Go 1.14版本中加入了基于系统信号的goroutine抢占式调度机制，很大程度上解决了goroutine“饿死”的问题。


### 32.3 对goroutine调度器原理的进一步理解

>> 1. G、P、M
关于G、P、M的定义，可以参见$GOROOT/src/runtime/runtime2.go这个源文件。

>> •  G：代表goroutine，存储了goroutine的执行栈信息、goroutine状态及goroutine的任务函数等。另外G对象是可以重用的。
•  P：代表逻辑processor，P的数量决定了系统内最大可并行的G的数量（前提：系统的物理CPU核数>=P的数量）。P中最有用的是其拥有的各种G对象队列、链表、一些缓存和状态。
•  M：M代表着真正的执行计算资源。在绑定有效的P后，进入一个调度循环；而调度循环的机制大致是从各种队列、P的本地运行队列中获取G，切换到G的执行栈上并执行G的函数，调用goexit做清理工作并回到M。如此反复。M并不保留G状态，这是G可以跨M调度的基础。

>> 2. G被抢占调度

>> 与操作系统按时间片调度线程不同，Go中并没有时间片的概念。如果某个G没有进行系统调用（syscall）、没有进行I/O操作、没有阻塞在一个channel操作上，那么M是如何让G停下来并调度下一个可运行的G的呢？答案是：G是被抢占调度的。

>> 前面说过，除非极端的无限循环或死循环，否则只要G调用函数，Go运行时就有了抢占G的机会。在Go程序启动时，运行时会启动一个名为sysmon的M（一般称为监控线程），该M的特殊之处在于它无须绑定P即可运行（以g0这个G的形式）。该M在整个Go程序的运行过程中至关重要

>> ，参见下面代码：
```go
//$GOROOT/src/runtime/proc.go
// The main goroutine.
func main() {     ...    
systemstack(func() 
{        newm(sysmon, nil)    
}
)    ...}
// 运行无须P参与////go:nowritebarrierrec
func sysmon() {    
	// 如果一个heap span在垃圾回收后5分钟内没有被使用    
	// 就把它归还给操作系统    
	scavengelimit := int64(5 * 60 * 1e9)    ...    
	if  ... {        ...        
	// 夺回被阻塞在系统调用中的P        
	// 抢占长期运行的G        
		if retake(now) != 0 {            
			idle = 0        
		} else {            
			idle++        
		}       ...    
	}
}
```
sysmon每20us~10ms启动一次，主要完成如下工作：
•  释放闲置超过5分钟的span物理内存；
•  如果超过2分钟没有垃圾回收，强制执行；
•  将长时间未处理的netpoll结果添加到任务队列；
•  向长时间运行的G任务发出抢占调度；
•  收回因syscall长时间阻塞的P。

>> 我们看到sysmon将向长时间运行的G任务发出抢占调度，这由函数retake实施：
```go
// $GOROOT/src/runtime/proc.go
// forcePreemptNS是在一个G被抢占之前给它的时间片
const forcePreemptNS = 10 * 1000 * 1000 
// 10ms
func retake(now int64) uint32 {    ...    
// 抢占运行时间过长的G    
t := int64(_p_.schedtick)    
	if int64(pd.schedtick) != t {        
		pd.schedtick = uint32(t)        
		pd.schedwhen = now        
		continue   
	}    
	if pd.schedwhen+forcePreemptNS > now {       
		continue    
	}    
	preemptone(_p_)    ...
}
```
可以看出，如果一个G任务运行超过10ms，sysmon就会认为其运行时间太久而发出抢占式调度的请求。一旦G的抢占标志位被设为true，那么在这个G下一次调用函数或方法时，运行时便可以将G抢占并移出运行状态，放入P的本地运行队列中（如果P的本地运行队列已满，那么将放在全局运行队列中），等待下一次被调度。

>> 3. channel阻塞或网络I/O情况下的调度

>> 如果G被阻塞在某个channel操作或网络I/O操作上，那么G会被放置到某个等待队列中，而M会尝试运行P的下一个可运行的G。如果此时P没有可运行的G供M运行，那么M将解绑P，并进入挂起状态。当I/O操作完成或channel操作完成，在等待队列中的G会被唤醒，标记为runnable（可运行），并被放入某个P的队列中，绑定一个M后继续执行。

>> 4. 系统调用阻塞情况下的调度

>> 如果G被阻塞在某个系统调用上，那么不仅G会阻塞，执行该G的M也会解绑P（实质是被sysmon抢走了），与G一起进入阻塞状态。如果此时有空闲的M，则P会与其绑定并继续执行其他G；如果没有空闲的M，但仍然有其他G要执行，那么就会创建一个新M（线程）。当系统调用返回后，阻塞在该系统调用上的G会尝试获取一个可用的P，如果有可用P，之前运行该G的M将绑定P继续运行G；如果没有可用的P，那么G与M之间的关联将解除，同时G会被标记为runnable，放入全局的运行队列中，等待调度器的再次调度。


### 32.4 调度器状态的查看方法


+ Go提供了调度器当前状态的查看方法：使用Go运行时环境变量GODEBUG。

+ 给GODEBUG传入了"schedtrace=1000"，其含义就是每1000ms打印输出一次goroutine调度器的状态，每次一行。

` SCHED 6016ms: gomaxprocs=4 idleprocs=0 threads=26 spinningthreads=0 idlethreads=20 runqueue=1 [3 4 0 10]`

•  SCHED：调试信息输出标志字符串，代表本行是goroutine调度器相关信息的输出。
•  6016ms：从程序启动到输出这行日志经过的时间。
•  gomaxprocs：P的数量。
•  idleprocs：处于空闲状态的P的数量。通过gomaxprocs和idleprocs的差值，我们就可以知道当前正在执行Go代码的P的数量。
•  threads：操作系统线程的数量，包含调度器使用的M数量，加上运行时自用的类似sysmon这样的线程的数量。
•  spinningthreads：处于自旋（spin）状态的操作系统数量。
•  idlethread：处于空闲状态的操作系统线程的数量。
•  runqueue=1：Go调度器全局运行队列中G的数量。
•  [3 4 0 10]：分别为4个P的本地运行队列中的G的数量。

+ 还可以输出每个goroutine、M和P的详细调度信息（对于Gopher来说，在大多数情况下这是不必要的）：
`$ GODEBUG=schedtrace=1000,scheddetail=1 godoc -http=:6060`

+  关于Go调度器调试信息输出的详细信息，可以参考Dmitry Vyukov的文章 “ Debugging Performance Issues in Go Programs”[1]，这也应该是每个Gopher必读的经典文章。更详尽的信息可参考$GOROOT/src/runtime/proc.go中schedtrace函数的实现。

`[1]https://software.intel.com/en-us/blogs/2014/05/10/debugging-performance-issues-in-go-programs`


### 32.5 goroutine调度实例简要分析
```go
>> // chapter6/sources/go-scheduler-model-case1.go 
func deadloop() {    
	for {    }
}
func main() {    
	go deadloop()   
	for {        
		time.Sleep(time.Second * 1)        
		fmt.Println("I got scheduled!")    
	}
}
```

>> Go从1.5版本开始将P的默认数量由1改为CPU核的数量（实际上还乘了每个核上硬线程数量）。

>> 2）如何让deadloop goroutine以外的goroutine无法得到调度？

>> 一种思路是：让Go运行时不要启动那么多P，让所有用户级的goroutine都在一个P上被调度。

>> 实现上述思路的三种办法：
•  在main函数的最开头处调用runtime.GOMAXPROCS(1)；
•  设置环境变量export GOMAXPROCS=1后再运行程序；
•  找一台单核单线程的机器（不过现在这样的机器太难找了，只能使用云服务器实现）。

>> Go 1.14版本中加入了goroutine的抢占式调度，新的调度方式利用操作系统信号机制，因此在Go 1.14及后续版本中，上述例子将不适用。

+ 3）反转：如何在GOMAXPROCS=1的情况下让main goroutine得到调度？

```go
>> // chapter6/sources/go-scheduler-model-case3.go 
func add(a, b int) int {    
	return a + b
}
func deadloop() {    
	for {        
		add(3, 5)    
	}
}
func main() {    
	runtime.GOMAXPROCS(1)    
	go deadloop()    
	for {        
		time.Sleep(time.Second * 1)        
		fmt.Println("I got scheduled!")    
	}
}
```
+ 查看Go程序的汇编代码有多种方法。
•  使用objdump工具：objdump -S go二进制文件。
•  使用gdb disassemble。
•  使用go tool工具生成汇编代码文件：go build -gcflags '-S ' xx.go > xx.s 2>&1。

+ •  将Go代码编译成汇编代码：go tool compile -S xx.go > xx.s。
•  使用go tool工具反编译Go程序：go tool objdump -S go-binary > xx.s。

+ 这里使用最后一种方法：利用go tool objdump反编译（并结合其他输出的汇编形式）。
$go build -o go-scheduler-model-case3 go-scheduler-model-case3.go$go tool objdump -S go-scheduler-model-case3 > go-scheduler-model-case3.s

+ deadloop中对add函数的调用并未出现。这显然是Go编译器在生成代码时执行了内联（inline）优化的结果，因为add的调用对deadloop的行为结果没有任何影响。

+ add函数位于调用树的leaf（叶子）位置，编译器可以确保其不再有新栈帧生成，不会导致栈分裂或超出现有栈边界，于是就不再插入morestack。这样位于morestack中的调度器的抢占式检查也就无法执行。下面是go build -gcflags '-S'方式输出的go-scheduler-model-case3.go的汇编输出

>> 在deadloop和add函数之间再加入一个dummy函数

>> func dummy() {    add(3, 5)}

>> func deadloop() {    for {        dummy()    }}

>> main goroutine果然得到了调度。再来看看Go编译器为该程序生成的汇编代码：
$go build -gcflags '-N -l' -o go-scheduler-model-case4 go-scheduler-model-case4.go$go tool objdump -S go-scheduler-model-case4 > go-scheduler-model-case4.s

>> 我们看到main.add函数依旧是叶子节点（leaf node），没有插入morestack调用；但在新增的dummy函数中我们看到了CALL runtime.morestack_noctxt(SB)的身影。

>> 4）为何runtime.morestack_noctxt(SB)放到了RET后面？

>> 另一种形式的汇编输出（go build -gcflags '-S'方式输出的格式）

>> 这种形式输出的是标准Plan 9的汇编语法，资料很少（比如JLS跳转指令的含义）。最后一行的含义是：如果跳转，则进入runtime.morestack_noctxt，从runtime.morestack_noctxt返回后，再次跳转到开头执行（见最后一行的JMP 0）。
为什么要这么做呢？按照Go语言开发团队的说法，这样做是为了更好地利用现代CPU的“静态分支预测”（static branch prediction）[2]，提升执行性能。

### 小结
goroutine是Go语言并发的基础，也是最基本的执行单元。Go基于goroutine建立了G-P-M的调度模型，了解这个调度模型对于Go代码设计以及Go代码问题的诊断都有很大帮助。

>> 本条要点：
•  了解goroutine调度器要解决的主要问题；
•  了解goroutine调度器的调度模型演进；
•  掌握goroutine调度器当前G-P-M调度模型的运行原理；
•  掌握goroutine调度器状态查看方法；
•  学习goroutine调度实例分析方法


## 第33条 掌握Go并发模型和常见并发模式

+ 不要通过共享内存来通信，而应该通过通信来共享内存。
——Rob Pike，Go语言之父


### 33.1 Go并发模型

+ 传统语言的并发模型是基于共享内存的模型

+ 在新并发模型设计中借鉴了著名计算机科学家Tony Hoare提出的CSP（Communicating Sequential Process，通信顺序进程）模型

>> Tony Hoare的CSP模型旨在简化并发程序的编写，让并发程序的编写与编写顺序程序一样简单。Tony Hoare认为输入/输出应该是基本的编程原语，数据处理逻辑（CSP中的P）仅需调用输入原语获取数据，顺序处理数据，并将结果数据通过输出原语输出即可。因此，在Tony Hoare眼中，一个符合CSP模型的并发程序应该是一组通过输入/输出原语连接起来的P的集合。从这个角度来看，CSP理论不仅是一个并发参考模型，也是一种并发程序的程序组织方法。其组合思想与Go的设计哲学不谋而合。CSP理论中的P（Process，进程）是个抽象概念，它代表任何顺序处理逻辑的封装，它获取输入数据（或从其他P的输出获取），并生产可以被其他P消费的输出数据。
P并不一定与操作系统的进程或线程画等号。在Go中，与Process对应的是goroutine，但Go语言中goroutine的执行逻辑并不一定是顺序的，goroutine也可以创建其他goroutine以并发地完成工作。
为了实现CSP模型中的输入/输出原语，Go引入了goroutine（P）之间的通信原语channel。goroutine可以从channel获取输入数据，再将处理后得到的结果数据通过channel输出。通过channel将goroutine（P）组合与连接在一起，这使得设计和编写大型并发系统变得更为简单和清晰，我们无须再为那些传统共享内存并发模型中的问题而伤脑筋了。

+ 虽然CSP模型已经成为Go语言支持的主流并发模型，但Go也支持传统的基于共享内存的并发模型，并提供基本的低级同步原语（主要是sync包中的互斥锁、条件变量、读写锁、原子操作等）。

+ Go始终推荐以CSP模型风格构建并发程序，尤其是在复杂的业务层面。这将提升程序逻辑的清晰度，大大降低并发设计的复杂性，并让程序更具可读性和可维护性；对于局部情况，比如涉及性能敏感的区域或需要保护的结构体数据，可以使用更为高效的低级同步原语（如sync.Mutex），以保证goroutine对数据的同步访问。


### 33.2 Go常见的并发模式

+ 在语言层面，Go针对CSP模型提供了三种并发原语。
•  goroutine：对应CSP模型中的P，封装了数据的处理逻辑，是Go运行时调度的基本执行单元。
•  channel：对应CSP模型中的输入/输出原语，用于goroutine之间的通信和同步。
•  select：用于应对多路输入/输出，可以让goroutine同时协调处理多个channel操作。

1. 创建模式
Go语言使用go关键字+函数/方法创建goroutine

+ 但在稍复杂一些的并发程序中，需要考虑通过CSP模型输入/输出原语的承载体channel在goroutine之间建立联系。为了满足这一需求，我们通常使用下面的方式来创建goroutine：
```go
type T struct {...}
func spawn(f func()) chan T {    
	c := make(chan T)    
	go func() {        
		// 使用channel变量c(通过闭包方式)与调用spawn的goroutine通信        ...        
		f()        ...    
	}()        
	return c
}
func main() {    
	c := spawn(func(){})    // 使用channel变量c与新创建的goroutine通信
}
```
以上方式在内部创建一个goroutine并返回一个channel类型变量的函数，这是Go中最常见的goroutine创建模式。spawn函数创建的新goroutine与调用spawn函数的goroutine之间通过一个channel建立起了联系：两个goroutine可以通过这个channel进行通信。spawn函数的实现得益于channel作为Go语言一等公民（first-class citizen）的存在：channel可以像变量一样被初始化、传递和赋值。上面例子中的spawn只返回了一个channel变量，大家可以根据需要自行定义返回的channel个数和用途。

2. 退出模式

>> 一些常驻的后台服务程序可能会对goroutine有着优雅退出的要求，在这里我们就分类说明一下goroutine的几种退出模式。

>> （1）分离模式
这里借鉴了一些线程模型中的术语，比如分离（detached）模式。分离模式是使用最为广泛的goroutine退出模式。对于分离的goroutine，创建它的goroutine不需要关心它的退出，这类goroutine在启动后即与其创建者彻底分离，其生命周期与其执行的主函数相关，函数返回即goroutine退出。这类goroutine有两个常见用途。
1）一次性任务：顾名思义，新创建的goroutine用来执行一个简单的任务，执行后即退出。比如下面标准库中的代码：
```go
// $GOROOT/src/net/dial.go 
func (d *Dialer) DialContext(ctx context.Context, network, address string) (Conn, error) {    ...    
	if oldCancel := d.Cancel; oldCancel != nil {        
		subCtx, cancel := context.WithCancel(ctx)        
		defer cancel()        
		go func() {            
			select {            
				case <-oldCancel:      cancel()            
				case <-subCtx.Done():            
			}
		}()        
		ctx = subCtx    
	}    ...
}
```
我们看到在DialContext方法中创建了一个goroutine，用来监听两个channel是否有数据，一旦有数据，处理后即退出。

>> 2）常驻后台执行一些特定任务，如监视（monitor）、观察（watch）等。其实现通常采用for {...}或for { select{...} }代码段形式，并多以定时器（timer）或事件（event）驱动执行。
Go为每个goroutine调度模型中的P内置的GC goroutine就是这种类型的：
```go
// $GOROOT/src/runtime/mgc.go 
func gcBgMarkStartWorkers() {    
	// 每个P都有一个运行在后台的用于标记的G    
	for _, p := range allp {        
		if p.gcBgMarkWorker == 0 {            
			go gcBgMarkWorker(p) 
			// 为每个P创建一个goroutine，以运行gcBgMarkWorker            
			notetsleepg(&work.bgMarkReady, -1)            
			noteclear(&work.bgMarkReady)        
		}    
	}
}
func gcBgMarkWorker(_p_ *p) {    
	gp := getg()    ...    
	for { // 常驻后台处理GC事宜        ...    
	}
}
```
(2）join模式

在Go中，我们有时候也有类似的需求：goroutine的创建者需要等待新goroutine结束。笔者为这样的goroutine退出模式起名为“join模式”。

>> ① 等待一个goroutine退出
```go
func spawn(f func(args ...interface{}), args ...interface{}) chan struct{} {    
	c := make(chan struct{})    
	go func() {        
		f(args...)        
		c <- struct{}{}    
	}()    
	return c
}
func main() {     
	done := spawn(worker, 5)     
	println("spawn a worker goroutine")     
	<-done     
	println("worker done")
}
```

>> main goroutine在创建完新goroutine后便在该channel上阻塞等待，直到新goroutine退出前向该channel发送了一个信号。

>> ② 获取goroutine的退出状态
```go
// chapter6/sources/go-concurrency-pattern-2.go 
var OK = errors.New("ok")
func worker(args ...interface{}) error {    
	if len(args) == 0 {        
		return errors.New("invalid args")    
	}    
	interval, ok := args[0].(int)    
	if !ok {        
		return errors.New("invalid interval arg")    
	}        
	time.Sleep(time.Second * (time.Duration(interval)))    
	return OK
}
func spawn(f func(args ...interface{}) error, args ...interface{}) chan error {    
	c := make(chan error)    
	go func() {        
		c <- f(args...)    
	}()    
	return c
}
func main() {    
	done := spawn(worker, 5)    
	println("spawn worker1")    
	err := <-done    
	fmt.Println("worker1 done:", err)    
	done = spawn(worker)    
	println("spawn worker2")    
	err = <-done    
	fmt.Println("worker2 done:", err)
}
```

>> 我们将channel中承载的类型由struct{}改为了error，这样channel承载的信息就不只是一个信号了，还携带了有价值的信息：新goroutine的结束状态。

>> ③ 等待多个goroutine退出

>> 通过Go语言提供的sync.WaitGroup实现等待多个goroutine退出的模式

```go
func spawnGroup(n int, f func(args ...interface{}), args ...interface{}) chan struct{} {    
	c := make(chan struct{})    
	var wg sync.WaitGroup        
	for i := 0; i < n; i++ {        
		wg.Add(1)        
		go func(i int) {           
			name := fmt.Sprintf("worker-%d:", i)            
			f(args...)            
			println(name, "done")            
			wg.Done() // worker done!        
		}(i)    
	}        
	go func() {        
		wg.Wait()        
		c <- struct{}{}    
	}()        
	return c
}
func main() {    
	done := spawnGroup(5, worker, 3)    
	println("spawn a group of workers")    
	<-done    
	println("group workers done")
}
```

>> ④ 支持超时机制的等待

```go
// chapter6/sources/go-concurrency-pattern-4.go 
func main() {    
	done := spawnGroup(5, worker, 30)    
	println("spawn a group of workers")        
	timer := time.NewTimer(time.Second * 5)    
	defer timer.Stop()    
	select {    
		case <-timer.C:        
		println("wait group workers exit timeout!")    
		case <-done:        println("group workers done")    
	}
}
```

+ （3）notify-and-wait模式
在前面的几个场景中，goroutine的创建者都是在被动地等待着新goroutine的退出。但很多时候，goroutine创建者需要主动通知那些新goroutine退出，尤其是当main goroutine作为创建者时。main goroutine退出意味着Go程序的终止，而粗暴地直接让main goroutine退出的方式可能会导致业务数据损坏、不完整或丢失。我们可以通过notify-and-wait（通知并等待）模式来满足这一场景的要求。虽然这一模式也不能完全避免损失，但是它给了各个goroutine一个挽救数据的机会，从而尽可能减少损失。

>> ① 通知并等待一个goroutine退出

```go
// chapter6/sources/go-concurrency-pattern-5.go 
func worker(j int) {    
	time.Sleep(time.Second * (time.Duration(j)))
}
func spawn(f func(int)) chan string {    
	quit := make(chan string)    
	go func() {        
		var job chan int // 模拟job channel        
		for {            
			select {            
				case j := <-job:      f(j)            
				case <-quit:       quit <- "ok"            
			}        
		}    
	}()    
	return quit
}
func main() {    
	quit := spawn(worker)    
	println("spawn a worker goroutine")        
	time.Sleep(5 * time.Second)        // 通知新创建的goroutine退出    
	println("notify the worker to exit...")    
	quit <- "exit"        
	timer := time.NewTimer(time.Second * 10)    
	defer timer.Stop()    
	select {    
		case status := <-quit:        println("worker done:", status)    
		case <-timer.C:        println("wait worker exit timeout")   
	}
}
```
在上述示例代码中，使用创建模式创建goroutine的spawn函数返回的channel的作用发生了变化，从原先的只是用于新goroutine发送退出信号给创建者，变成了一个双向的数据通道：既承载创建者发送给新goroutine的退出信号，也承载新goroutine返回给创建者的退出状态。

>> ② 通知并等待多个goroutine退出

>> Go语言的channel有一个特性是，当使用close函数关闭channel时，所有阻塞到该channel上的goroutine都会得到通知。
```go
// chapter6/sources/go-concurrency-pattern-6.go 
func worker(j int) {    
	time.Sleep(time.Second * (time.Duration(j)))
}
func spawnGroup(n int, f func(int)) chan struct{} {    
	quit := make(chan struct{})    
	job := make(chan int)    
	var wg sync.WaitGroup        
	for i := 0; i < n; i++ {        
		wg.Add(1)        
		go func(i int) {            
			defer wg.Done() // 保证wg.Done在goroutine退出前被执行            
			name := fmt.Sprintf("worker-%d:", i)            
			for {                
				j, ok := <-job                
				if !ok {                    
					println(name, "done")                    
					return                
				}                
				// 执行这个job                
				worker(j)            
			}        
		}(i)    
	}        
	go func() {        
		<-quit        
		close(job) 
		// 广播给所有新goroutine        
		wg.Wait()        
		quit <- struct{}{}    
	}()        
	return quit
}
func main() {    
	quit := spawnGroup(5, worker)    
	println("spawn a group of workers")        
	time.Sleep(5 * time.Second)    
	// 通知 worker goroutine 组退出    
	println("notify the worker group to exit...")    
	quit <- struct{}{}        
	timer := time.NewTimer(time.Second * 5)    
	defer timer.Stop()    
	select {    
		case <-timer.C:        println("wait group workers exit timeout!")    
		case <-quit:        println("group workers done")    
	}
}
```
>> 上面这段示例代码的关键是创建者直接利用了worker goroutine接收任务（job）的channel来广播退出通知，而实现这一广播的代码就是close(job)。此时各个worker goroutine监听job channel，当创建者关闭job channel时，通过“comma ok”模式获取的ok值为false，也就表明该channel已经被关闭，于是worker goroutine执行退出逻辑（退出前wg.Done()被执行）。

>> （4）退出模式的应用

>> 聚焦在实现一个“超时等待退出”框架，以统一解决各种运行形态goroutine的优雅退出问题。

>> 我们来定义一个接口：
```go
// chapter6/sources/go-concurrency-pattern-7.go 
type GracefullyShutdowner interface {    
	Shutdown(waitTimeout time.Duration) error
}
```
这样，凡是实现了该接口的类型均可在程序退出时得到退出的通知和调用，从而有机会做退出前的最后清理工作。这里还提供了一个类似http.HandlerFunc的类型ShutdownerFunc，用于将普通函数转化为实现了GracefullyShutdowner接口的类型实例（得益于函数在Go中为“一等公民”的特质）：
```go
// chapter6/sources/go-concurrency-pattern-7.go 
type ShutdownerFunc func(time.Duration) errorfunc (f ShutdownerFunc)
Shutdown(waitTimeout time.Duration) error {    
	return f(waitTimeout)
}
```
一组goroutine的退出总体上有两种情况。一种是并发退出，在这类退出方式下，各个goroutine的退出先后次序对数据处理无影响，因此各个goroutine可以并发执行退出逻辑；另一种则是串行退出，即各个goroutine之间的退出是按照一定次序逐个进行的，次序若错了可能会导致程序的状态混乱和错误。

>> 我们先来看并发退出：
```go
// chapter6/sources/go-concurrency-pattern-7.go 
func ConcurrentShutdown(waitTimeout time.Duration, shutdowners ...GracefullyShutdowner) error {    
	c := make(chan struct{})    
	go func() {        
		var wg sync.WaitGroup        
		for _, g := range shutdowners {            
			wg.Add(1)            
			go func(shutdowner GracefullyShutdowner) {                
				defer wg.Done()                
				shutdowner.Shutdown(waitTimeout)            
			}(g)        
		}        
		wg.Wait()        
		c <- struct{}{}   
	}()    
	timer := time.NewTimer(waitTimeout)    
	defer timer.Stop()    
	select {    
		case <-c:        return nil    
		case <-timer.C:        return errors.New("wait timeout")    
	}
}
```
如上述代码所示，我们将各个GracefullyShutdowner接口的实现以一个变长参数的形式传入ConcurrentShutdown函数。ConcurrentShutdown函数的实现也很简单（类似上面的超时等待多个goroutine退出的模式），具体如下：
1）为每个传入的GracefullyShutdowner接口实现的实例启动一个goroutine来执行退出逻辑，并将timeout参数传入每个实例的Shutdown方法中；
2）通过sync.WaitGroup在外层等待每个goroutine的退出；
3）通过select监听一个退出通知channel和一个timer channel，决定到底是正常退出还是超时退出。


下面是该并发退出函数对应的测试用例，通过这个用例我们可以直观了解到该函数的使用方法：

```go
// chapter6/sources/go-concurrency-pattern-7_test.go 

func shutdownMaker(processTm int) func(time.Duration) error {    
	return func(time.Duration) error {        
		time.Sleep(time.Second * time.Duration(processTm))        
		return nil    
	}
}
func TestConcurrentShutdown(t *testing.T) {    
	f1 := shutdownMaker(2)    
	f2 := shutdownMaker(6)        
	err := ConcurrentShutdown(10*time.Second, ShutdownerFunc(f1), ShutdownerFunc(f2))    
	if err != nil {        
		t.Errorf("want nil, actual: %s", err)        
		return    
	}        
	err = ConcurrentShutdown(4*time.Second, ShutdownerFunc(f1), ShutdownerFunc(f2))    
	if err == nil {        
		t.Error("want timeout, actual nil")        return    
	}
}
```
在上面的测试中，我们通过一个工具函数shutdownMaker制作出通过ShutdownerFunc转型即可满足接口GracefullyShutdowner的类型实例，并分别测试了ConcurrentShutdown函数的正常和等待超时两种状况。运行上面的测试用例：
`$ go test -v ./go-concurrency-pattern-7_test.go ./go-concurrency-pattern-7.go=== RUN   TestConcurrentShutdown--- PASS: TestConcurrentShutdown (10.00s)PASSok    command-line-arguments  10.001s`

有了并发退出作为基础，串行退出的实现也就很简单了：
```go
// chapter6/sources/go-concurrency-pattern-7.go
func SequentialShutdown(waitTimeout time.Duration, shutdowners ...GracefullyShutdowner) error {    
	start := time.Now()    
	var left time.Duration    
	timer := time.NewTimer(waitTimeout)        
	for _, g := range shutdowners {        
		elapsed := time.Since(start)        
		left = waitTimeout - elapsed                
		c := make(chan struct{})        
		go func(shutdowner GracefullyShutdowner) {            
			shutdowner.Shutdown(left)            
			c <- struct{}{}        
		}(g)                
		timer.Reset(left)        
		select {        
			case <-c:            // 继续执行        
			case <-timer.C:            return errors.New("wait timeout")        
		}    
	}    
	return nil
}
```
串行退出有个问题是waitTimeout值的确定，因为这个超时时间是所有goroutine的退出时间之和。在上述代码里，将每次的left（剩余时间）传入下一个要执行的goroutine的Shutdown方法中。select同样使用这个left作为timeout的值（通过timer.Reset重新设置timer定时器周期）。对照ConcurrentShutdown，SequentialShutdown更简单，这里就不详细介绍了。

3. 管道模式

+ Go中管道模式被实现成了由channel连接的一条“数据流水线”。在该流水线中，每个数据处理环节都由一组功能相同的goroutine完成。在每个数据处理环节，goroutine都要从数据输入channel获取前一个环节生产的数据，然后对这些数据进行处理，并将处理后的结果数据通过数据输出channel发往下一个环节。

```go
// chapter6/sources/go-concurrency-pattern-8.go 
func newNumGenerator(start, count int) <-chan int {    
	c := make(chan int)    
	go func() {        
		for i := start; i < start+count; i++ {            
			c <- i        
		}        
		close(c)   
	}()    
	return c
}
func filterOdd(in int) (int, bool) {    
	if in%2 != 0 {      
		return 0, false    
	}    
	return in, true
}
func square(in int) (int, bool) {    
	return in * in, true
}
func spawn(f func(int) (int, bool), in <-chan int) <-chan int {    
	out := make(chan int)        
	go func() {        
		for v := range in {            
			r, ok := f(v)            
			if ok {                
				out <- r            
			}        
		}       
		close(out)    
	}()        
	return out
}
func main() {    
	in := newNumGenerator(1, 20)    
	out := spawn(square, spawn(filterOdd, in))        
	for v := range out {        
		println(v)    
	}
}
```

>> 这条流水线管道可以被称为“偶数的平方”。这条流水线管道有4个处理环节。

+ 两种基于管道模式的扩展模式。
（1）扇出模式

>> 在某个处理环节，多个功能相同的goroutine从同一个channel读取数据并处理，直到该channel关闭，这种情况被称为“扇出”（fan-out）。使用扇出模式可以在一组goroutine中均衡分配工作量，从而更均衡地利用CPU。

>> （2）扇入模式
在某个处理环节，处理程序面对不止一个输入channel。我们把所有输入channel的数据汇聚到一个统一的输入channel，然后处理程序再从这个channel中读取数据并处理，直到该channel因所有输入channel关闭而关闭。这种情况被称为“扇入”（fan-in）。

>> 
图33-4　扇出模式和扇入模式

>> 扇出模式和扇入模式的实现示例
```go
// chapter6/sources/go-concurrency-pattern-9.go 
func newNumGenerator(start, count int) <-chan int {    
	c := make(chan int)    
	go func() {        
		for i := start; i < start+count; i++ {            
			c <- i        
		}        
		close(c)    
	}()    
	return c
}
func filterOdd(in int) (int, bool) {    
	if in%2 != 0 {        
		return 0, false   
	}    
	return in, true
}
func square(in int) (int, bool) {    
	return in * in, true
}
func spawnGroup(name string, num int, f func(int) (int, bool), in <-chan int) <-chan int {    
	groupOut := make(chan int)    
	var outSlice []chan int    
	for i := 0; i < num; i++ {        
		out := make(chan int)        
		go func(i int) {            
			name := fmt.Sprintf("%s-%d:", name, i)            
			fmt.Printf("%s begin to work...\n", name)                        
			for v := range in {                
				r, ok := f(v)                
				if ok {                    
					out <- r                
				}            
			}            
			close(out)            
			fmt.Printf("%s work done\n", name)        
		}(i)        
		outSlice = append(outSlice, out)    
	}        
	// 扇入模式    
	//    
	// out --\    
	//        \    
	// out ---- --> groupOut    
	//        /    
	// out --/    
	//    
	go func() {        
		var wg sync.WaitGroup        
		for _, out := range outSlice {            
			wg.Add(1)            
			go func(out <-chan int) {                
				for v := range out {                        
					groupOut <- v                
				}                
				wg.Done()            
			}(out)        
		}        
		wg.Wait()        
		close(groupOut)    
	}()        
	return groupOut
}

func main() {      
	in := newNumGenerator(1, 20)      
	out := spawnGroup("square", 2, square, spawnGroup("filterOdd", 3, filterOdd, in))      
	time.Sleep(3 * time.Second) 
	//为了输出更直观的结果，这里等上面的goroutine都就绪      
	for v := range out {          
		fmt.Println(v)    
	}
}
```
4. 超时与取消模式

>> 编写一个从气象数据服务中心获取气象信息的客户端。该客户端每次会并发向三个气象数据服务中心发起数据查询请求，并以最快返回的那个响应信息作为此次请求的应答返回值。

>> 下面的代码是这个例子的第一版实现：
```go
// chapter6/sources/go-concurrency-pattern-10.go 
type result struct {    
	value string
}
func first(servers ...*httptest.Server) (result, error) {    
	c := make(chan result, len(servers))    
	queryFunc := func(server *httptest.Server) {        
		url := server.URL        
		resp, err := http.Get(url)        
		if err != nil {            
			log.Printf("http get error: %s\n", err)            
			return        
		}        
		defer resp.Body.Close()        
		body, _ := ioutil.ReadAll(resp.Body)        
		c <- result{            
			value: string(body),        
		}    
	}    
	for _, serv := range servers {        
		go queryFunc(serv)    
	}    
	return <-c, nil
}
func fakeWeatherServer(name string) *httptest.Server {    
	return httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter,         r *http.Request) {        
		log.Printf("%s receive a http request\n", name)        
		time.Sleep(1 * time.Second)        
		w.Write([]byte(name + ":ok"))    
	}))
}
func main() {    
	result, err := first(fakeWeatherServer("open-weather-1"),        fakeWeatherServer("open-weather-2"),        
	fakeWeatherServer("open-weather-3"))    
	if err != nil {        
		log.Println("invoke first error:", err)        
		return    
	}        
	log.Println(result)
}
```
以上代码使用httptest包的NewServer函数创建了三个模拟器的气象数据服务中心，然后将这三个气象数据服务中心的实例传入first函数。后者创建了三个goroutine，每个goroutine向一个气象数据服务中心发起查询请求。三个发起查询的goroutine都会将应答结果写入同一个channel中，first获取第一个结果数据后就返回了。
运行下面这段示例代码：
`$go run go-concurrency-pattern-10.go2020/01/21 21:57:04 open-weather-3 receive a http request2020/01/21 21:57:04 open-weather-1 receive a http request2020/01/21 21:57:04 open-weather-2 receive a http request2020/01/21 21:57:05 {open-we　ather-3:ok}`

>> 上述例子运行在一种较为理想的情况下，而现实中的网络情况错综复杂，远程服务的状态也不甚明朗，很可能出现服务端长时间没有响应的情况。这时为了保证良好的用户体验，我们需要对客户端的行为进行精细化控制，比如：只等待500ms，超过500ms仍然没有收到任何一个气象数据服务中心的响应，first函数就返回失败，以保证等待时间在人类的忍耐力承受范围之内。我们在上述例子的基础上对first函数做的调整如下：
```go
// chapter6/sources/go-concurrency-pattern-11.go 
func first(servers ...*httptest.Server) (result, error) {    
	c := make(chan result, len(servers))    
	queryFunc := func(server *httptest.Server) {        
		url := server.URL        
		resp, err := http.Get(url)        
		if err != nil {            
			log.Printf("http get error: %s\n", err)            
			return        
		}        
		defer resp.Body.Close()        
		body, _ := ioutil.ReadAll(resp.Body)        
		c <- result{            
			value: string(body),        
		}    
	}    
	for _, serv := range servers {        
		go queryFunc(serv)    
	}        
	select {    
		case r := <-c:        return r, nil    
		case <-time.After(500 * time.Millisecond):        return result{}, errors.New("timeout")    
	}
}
```
我们增加了一个定时器，并通过select原语监视该定时器事件和响应channel上的事件。如果响应channel上长时间没有数据返回，则当定时器事件触发时，first函数返回超时错误：
`$ go run go-concurrency-pattern-11.go 2020/01/21 22:41:02 open-weather-1 receive a http request2020/01/21 22:41:02 open-weather-2 receive a http request2020/01/21 22:41:02 open-weather-3 receive a http request2020/01/21 22:41:02 invoke first error: timeout`

>> 加上了超时模式的版本依然有一个明显的问题，那就是即便first函数因超时而返回，三个已经创建的goroutine可能依然处在向气象数据服务中心请求或等待应答状态，没有返回，也没有被回收，资源仍然在占用，即使它们的存在已经没有任何意义。一种合理的解决思路是让这三个goroutine支持取消操作。在这种情况下，我们一般使用Go的context包来实现取消模式。context包是谷歌内部关于Go的一个最佳实践，Go在1.7版本将context包引入标准库中。下面是利用context包实现取消模式的代码：

```go
// chapter6/sources/go-concurrency-pattern-12.go 
type result struct {    
	value string
}
func first(servers ...*httptest.Server) (result, error) {    
	c := make(chan result)    
	ctx, cancel := context.WithCancel(context.Background())    
	defer cancel()    
	queryFunc := func(i int, server *httptest.Server) {        
		url := server.URL        
		req, err := http.NewRequest("GET", url, nil)        
		if err != nil {            
			log.Printf("query goroutine-%d: http NewRequest error: %s\n", i, err)            
			return        
		}        
		req = req.WithContext(ctx)                
		log.Printf("query goroutine-%d: send request...\n", i)        
		resp, err := http.DefaultClient.Do(req)        
		if err != nil {            
			log.Printf("query goroutine-%d: get return error: %s\n", i, err)            
			return        
		}        
		log.Printf("query goroutine-%d: get response\n", i)        
		defer resp.Body.Close()        
		body, _ := ioutil.ReadAll(resp.Body)                
		c <- result{            
			value: string(body),        
		}        
		return    
	}        
	for i, serv := range servers {        
		go queryFunc(i, serv)    
	}        
	select {    
		case r := <-c:        return r, nil    
		case <-time.After(500 * time.Millisecond):        return result{}, errors.New("timeout")    
	}
}
func fakeWeatherServer(name string, interval int) *httptest.Server {    
	return httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter,         r *http.Request) {        
		log.Printf("%s receive a http request\n", name)        
		time.Sleep(time.Duration(interval) * time.Millisecond)        
		w.Write([]byte(name + ":ok"))    
	}))
}
func main() {    
	result, err := first(fakeWeatherServer("open-weather-1", 200),        fakeWeatherServer("open-weather-2", 1000),        
	fakeWeatherServer("open-weather-3", 600))    
	if err != nil {        
		log.Println("invoke first error:", err)        
		return    
	}        
	fmt.Println(result)    
	time.Sleep(10 * time.Second)
}
```
+ 在这版实现中，我们利用context.WithCancel创建了一个可以取消的context.Context变量，在每个发起查询请求的goroutine中，我们用该变量更新了request中的ctx变量，使其支持被取消。这样在first函数中，无论是成功得到某个查询goroutine的返回结果，还是超时失败返回，通过defer cancel()设定cancel函数在first函数返回前被执行，那些尚未返回的在途（on-flight）查询的goroutine都将收到cancel事件并退出（http包支持利用context.Context的超时和cancel机制）。下面是运行该示例的结果：
`$go run go-concurrency-pattern-12.go2020/01/21 23:20:32 query goroutine-1: send request...2020/01/21 23:20:32 query goroutine-0: send request...2020/01/21 23:20:32 query goroutine-2: send request...2020/01/21 23:20:32 open-weather-3 receive a http request2020/01/21 23:20:32 open-weather-2 receive a http request2020/01/21 23:20:32 open-weather-1 receive a http request2020/01/21 23:20:32 query goroutine-0: get response{open-weather-1:ok}2020/01/21 23:20:32 query goroutine-1: get return error: Get http://127.0.0.1:56437: context canceled2020/01/21 23:20:32 query goroutine-2: get return error: Get http://127.0.0.1:56438: context canceled`
可以看到，first函数在得到open-weather-1这个气象数据服务中心的响应后，执行了cancel函数，其余两个http.DefaultClient.Do调用便取消了请求，返回了context canceled的错误，于是这两个goroutine得以退出。
小结
在这一条中我们学习了Go的基于CSP理论的并发模型，并将其与传统的基于共享内存的模型做了对比。之后，我们了解了Go提供的并发模型实现原语（goroutine、channel和select），并总结了利用这些原语实现的常见的Go并发模式。

### 本条要点：
•  了解基于CSP的并发模型与传统基于共享内存的并发模型的区别；
•  了解Go为实现CSP模型而提供的并发原语及功能；
•  掌握常见的并发模式，包括创建模式、多种退出模式、管道模式、超时和取消模式等。


## 第34条 了解channel的妙用


+ channel是Go语言提供的一种重要的并发原语。从前文中我们了解到，它在Go语言的CSP模型中扮演着重要的角色：既可以实现goroutine间的通信，又可以实现goroutine间的同步。
```go
c := make(chan int)    // 创建一个无缓冲(unbuffered)的int类型的
channelc := make(chan int, 5) // 创建一个带缓冲的int类型的channel
c <- x        // 向channel c中发送一个值
<- c          // 从channel c中接收一个值
x = <- c      // 从channel c接收一个值并将其存储到变量x中
x, ok = <- c  // 从channel c接收一个值。若channel关闭了，ok将被置为false
for i := range c { ... } // 将for range与channel结合使用
close(c)      // 关闭channel 
cc := make(chan chan int) // 创建一个无缓冲的chan int类型的channel
func stream(ctx context.Context, out chan<- Value) error // 将只发送(send-only) channel作为函数参数
func spawn(...) <-chan T // 将只接收(receive-only)类型channel作为返回值
```

+ 当需要同时对多个channel进行操作时，我们会结合使用Go为CSP模型提供的另一个原语：select。通过select，我们可以同时在多个channel上进行发送/接收操作


### 34.1 无缓冲channel

+ 无缓冲channel兼具通信和同步特性，在并发程序中应用颇为广泛。

+ 对于无缓冲channel而言，我们得到以下结论：
•  发送动作一定发生在接收动作完成之前；
•  接收动作一定发生在发送动作完成之前。

+ 看到的变量a的值一定是"hello, world"，而不是空字符串。
```go
// chapter6/sources/go-channel-case-1.go 
var c = make(chan int)
var a stringfunc f() {    
	a = "hello, world"    
	<-c
}
func main() {   
	 go f()    
	 c <- 5    
	 println(a)
}
```

1. 用作信号传递

（1）一对一通知信号
无缓冲channel常被用于在两个goroutine之间一对一地传递通知信号

```go
// chapter6/sources/go-channel-case-2.go 
type signal struct{}
func worker() {    
	println("worker is working...")    
	time.Sleep(1 * time.Second)
}
func spawn(f func()) <-chan signal {    
	c := make(chan signal)    
	go func() {        
		println("worker start to work...")        
		f()        
		c <- signal(truct{}{})    
	}()    
	return c
}
func main() {    
	println("start a worker...")    
	c := spawn(worker)    
	<-c    
	fmt.Println("worker work done!")
}
```
（2）一对多通知信号
有些时候，无缓冲channel还被用来实现一对多的信号通知机制。这样的信号通知机制常被用于协调多个goroutine一起工作，比如下面的例子：
```go
// chapter6/sources/go-channel-case-3.go 
type signal struct{}
func worker(i int) {    
	fmt.Printf("worker %d: is working...\n", i)    
	time.Sleep(1 * time.Second)    
	fmt.Printf("worker %d: works done\n", i)
}
func spawnGroup(f func(i int), num int, groupSignal <-chan signal) <-chan signal {    
	c := make(chan signal)    
	var wg sync.WaitGroup        
	for i := 0; i < num; i++ {        
		wg.Add(1)        
		go func(i int) {            
			<-groupSignal            
			fmt.Printf("worker %d: start to work...\n", i)            
			f(i)            
			wg.Done()        
		}(i + 1)    
	}        
	go func() {        
		wg.Wait()        
		c <- signal(struct{}{})    
	}()    
	return c
}
func main() {    
	fmt.Println("start a group of workers...")    
	groupSignal := make(chan signal)    
	c := spawnGroup(worker, 5, groupSignal)    
	time.Sleep(5 * time.Second)    
	fmt.Println("the group of workers start to work...")    
	close(groupSignal)    
	<-c    
	fmt.Println("the group of workers work done!")
}
```
>> 在上面的例子中，main goroutine创建了一组5个worker goroutine，这些goroutine启动后会阻塞在名为groupSignal的无缓冲channel上。main goroutine通过close(groupSignal)向所有worker goroutine广播“开始工作”的信号，所有worker goroutine在收到groupSignal后一起开始工作，就像起跑线上的运动员听到了裁判员发出的起跑信号枪声起跑一样。

>> 关闭一个无缓冲channel会让所有阻塞在该channel上的接收操作返回，从而实现一种一对多的广播机制。该一对多的信号通知机制还常用于通知一组worker goroutine退出，比如下面的例子：
```go
// chapter6/sources/go-channel-case-4.go 
type signal struct{}
func worker(i int, quit <-chan signal) {    
	fmt.Printf("worker %d: is working...\n", i)
	LOOP:    
	for {        
		select {        
			default:            
			// 模拟worker工作            
			time.Sleep(1 * time.Second)        
			case <-quit:            break LOOP        
		}    
	}    
	fmt.Printf("worker %d: works done\n", i)
}
func spawnGroup(f func(int, <-chan signal), num int, groupSignal <-chan signal) <-chan signal {    
	c := make(chan signal)    
	var wg sync.WaitGroup        
	for i := 0; i < num; i++ {        
		wg.Add(1)        
		go func(i int) {            
			fmt.Printf("worker %d: start to work...\n", i)            
			f(i, groupSignal)            
			wg.Done()        
		}(i + 1)    
	}        
	go func() {        
		wg.Wait()        
		c <- signal(struct{}{})    
	}()    
	return c
}
func main() {    
	fmt.Println("start a group of workers...")    
	groupSignal := make(chan signal)    
	c := spawnGroup(worker, 5, groupSignal)    
	fmt.Println("the group of workers start to work...")        
	time.Sleep(5 * time.Second)        
	// 通知workers退出    
	fmt.Println("notify the group of workers to exit...")    
	close(groupSignal)    
	<-c    
	fmt.Println("the group of workers work done!")
}
```
2. 用于替代锁机制

+ 无缓冲channel具有同步特性，这让它在某些场合可以替代锁，从而使得程序更加清晰，可读性更好。

>> 下面是一个传统的基于共享内存+锁模式的goroutine安全的计数器实现：
```go
// chapter6/sources/go-channel-case-5.go 
type counter struct {    
	sync.Mutex    i int
}
var cter counterfunc Increase() int {    
	cter.Lock()    
	defer cter.Unlock()    
	cter.i++    
	return cter.i
}
func main() {    
	for i := 0; i < 10; i++ {        
		go func(i int) {            
			v := Increase()            
			fmt.Printf("goroutine-%d: current counter value is %d\n", i, v)        
		}(i)    
	}    
	time.Sleep(5 * time.Second)
}
```
下面是使用无缓冲channel替代锁后的实现：
```go
// chapter6/sources/go-channel-case-6.go
type counter struct {    
	c chan int    
	i int
}
var cter counterfunc InitCounter() {    
	cter = counter{        
		c: make(chan int),    
	}        
	go func() {        
		for {                
			cter.i++                
			cter.c <- cter.i        
		}    
	}()    
	fmt.Println("counter init ok")
}
func Increase() int {    
	return <-cter.c
}
func init() {    
	InitCounter()
}

func main() {    
	for i := 0; i < 10; i++ {        
		go func(i int) {            
			v := Increase()            
			fmt.Printf("goroutine-%d: current counter value is %d\n", i, v)        
		}(i)    
	}    
	time.Sleep(5 * time.Second)
}
```
在这个实现中，我们将计数器操作全部交给一个独立的goroutine处理，并通过无缓冲channel的同步阻塞特性实现计数器的控制。这样其他goroutine通过Increase函数试图增加计数器值的动作实质上就转化为一次无缓冲channel的接收动作。这种并发设计逻辑更符合Go语言所倡导的“不要通过共享内存来通信，而应该通过通信来共享内存”的原则。


### 34.2 带缓冲channel

1. 用作消息队列

（2）多收多发性能基准测试

+ 再来看看在一个channel有多个发送goroutine和多个接收goroutine的情况下，两种channel的收发性能比对数据（这里建立10个发送goroutine和10个接收goroutine）

+ •  无论是单收单发还是多收多发，带缓冲channel的收发性能都要好于无缓冲channel的；
•  对于带缓冲channel而言，选择适当容量会在一定程度上提升收发性能。

2. 用作计数信号量
```go
// chapter6/sources/go-channel-case-7.go 
var active = make(chan struct{}, 3)
var jobs = make(chan int, 10)
func main() {    
	go func() {        
		for i := 0; i < 8; i++ {            
			jobs <- (i + 1)        
		}        
		close(jobs)    
	}()        
	var wg sync.WaitGroup        
	for j := range jobs {        
		wg.Add(1)        
		go func(j int) {            
			active <- struct{}{}            
			log.Printf("handle job: %d\n", j)            
			time.Sleep(2 * time.Second)            
			<-active            
			wg.Done()        
		}(j)    
	}    
	wg.Wait()
}
```
上面的示例创建了一组goroutine来处理job，同一时间最多允许3个goroutine处于活动状态。为达成这一目标，示例使用了一个容量为3的带缓冲channel，active作为计数信号量，这意味着允许同时处于活动状态的最大goroutine数量为3。

3. len(channel)的应用

+ 如果s是chan T类型，那么len(s)针对channel的类型不同，有如下两种语义：
◦  当s为无缓冲channel时，len(s)总是返回0；
◦  当s为带缓冲channel时，len(s)返回当前channel s中尚未被读取的元素个数。

```go
var c chan T = make(chan T, capacity)
// 判空
if len(c) == 0 {    
	// 此时channel c空了？
}
// 判有
if len(c) > 0 {    
	// 此时channel c有数据？
}// 判满
if len(channel) == cap(channel) {    
	// 此时channel c满了？
}
```
上面代码注释中的“空了”“有数据”和“满了”后面都被打上了问号！channel原语用于多个goroutine间的通信，一旦多个goroutine共同对channel进行收发操作，那么len(channel)就会在多个goroutine间形成竞态，单纯依靠len(channel)来判断channel中元素的状态，不能保证在后续对channel进行收发时channel的状态不变。

+ 为了不阻塞在channel上，常见的方法是将判空与读取放在一个事务中，将判满与写入放在一个事务中，而这类事务我们可以通过select实现。
```go
// chapter6/sources/go-channel-case-8.go   
func producer(c chan<- int) {    
	var i int = 1    
	for {        
		time.Sleep(2 * time.Second)        
		ok := trySend(c, i)        
		if ok {            
			fmt.Printf("[producer]: send [%d] to channel\n", i)            
			i++            
			continue        
		}        
		fmt.Printf("[producer]: try send [%d], but channel is full\n", i)    
	}
}
func tryRecv(c <-chan int) (int, bool) {    
	select {    
		case i := <-c:        return i, true    
		default:        return 0, false    
	}
}
func trySend(c chan<- int, i int) bool {    
	select {    
		case c <- i:        return true    
		default:        return false    
	}
}
func consumer(c <-chan int) {    
	for {        
		i, ok := tryRecv(c)        
		if !ok {            
			fmt.Println("[consumer]: try to recv from channel, but the channel is empty")            
			time.Sleep(1 * time.Second)            
			continue        
		}        
		fmt.Printf("[consumer]: recv [%d] from channel\n", i)        
		if i >= 3 {            
			fmt.Println("[consumer]: exit")            
			return        
		}    
	}
}
func main() {    
	c := make(chan int, 3)    
	go producer(c)    
	go consumer(c)        
	select {} // 仅用于演示，临时用来阻塞主goroutine
}
```

+ 由于用到了select原语的default分支语义，当channel空的时候，tryRecv不会阻塞；当channel满的时候，trySend也不会阻塞。运行该示例：
`$go run go-channel-case-8.go              [consumer]: try to recv from channel, but the channel is empty[consumer]: try to recv from channel, but the channel is empty[producer]: send [1] to channel[consumer]: recv [1] from channel[consumer]: try to recv from channel, but the channel is empty[consumer]: try to recv from channel, but the channel is empty[producer]: send [2] to channel[consumer]: recv [2] from channel[consumer]: try to recv from channel, but the channel is empty[consumer]: try to recv from channel, but the channel is empty[producer]: send [3] to channel[consumer]: recv [3] from channel[consumer]: exit[producer]: send [4] to channel[producer]: send [5] to channel[producer]: send [6] to channel[producer]: try send [7], but channel is full[producer]: try send [7], but channel is full[producer]: try send [7], but channel is full`

>> 这种方法适合大多数场合，但有一个问题，那就是它改变了channel的状态：接收或发送了一个元素。有些时候我们不想这么做，而想在不改变channel状态的前提下单纯地侦测channel的状态，又不会因channel满或空阻塞在channel上。但很遗憾，目前没有一种方法既可以实现这样的功能又适用于所有场合。在特定的场景下，可以用len(channel)来实现。比如图34-2中的这两种场景。

>> 在图34-2中，a是一个多发送单接收的场景，即有多个发送者，但有且只有一个接收者。在这样的场景下，我们可以在接收者goroutine中根据len(channel)是否大于0来判断channel中是否有数据需要接收。
b是一个多接收单发送的场景，即有多个接收者，但有且只有一个发送者。在这样的场景下，我们可以在发送goroutine中根据len(channel)是否小于cap(channel)来判断是否可以执行向channel的发送操作。

>> 
图34-2　两种适合使用len(channel)侦测channel状态的场景


### 34.3 nil channel的妙用

+  对没有初始化的channel（nil channel）进行读写操作将会发生阻塞，比如下面这段代码：
`func main() {    var c chan int    <-c}`
或者
`func main() {    var c chan int    c<-1}`
上述无论哪段代码被执行，都将得到如下的错误信息：
`fatal error: all goroutines are asleep - deadlock!goroutine 1 [chan receive (nil chan)]:`
或者
goroutine 1 [chan send (nil chan)]:
main goroutine被阻塞在channel上，导致Go运行时认为出现deadlock状态并抛出panic。

+ 但nil channel并非一无是处，有些时候妙用nil channel可以达到事半功倍的效果。
```go
// chapter6/sources/go-channel-case-9.go 
func main() {    
	c1, c2 := make(chan int), make(chan int)    
	go func() {        
		time.Sleep(time.Second * 5)        
		c1 <- 5        
		close(c1)    
	}()        
	go func() {        
		time.Sleep(time.Second * 7)        
		c2 <- 7        
		close(c2)    
	}()        
	var ok1, ok2 bool    
	for {        
		select {        
			case x := <-c1:            ok1 = true            
			fmt.Println(x)        
			case x := <-c2:            ok2 = true            
			fmt.Println(x)        
		}                
		if ok1 && ok2 {            
			break        
		}    
	}    
	fmt.Println("program end")
}

```

在这个示例中，我们期望程序在接收完c1和c2两个channel上的数据后就退出。但实际的运行情况如下：$go run go-channel-case-9.go5000... //循环输出07program end我们期望上述程序在依次输出5和7这两个数字后退出，但实际的输出结果却是在输出5之后，程序输出了许多个0后才输出7并退出。简单分析一下上述代码的运行过程。1）前5s，select一直处于阻塞状态。2）第5s，c1返回一个5后被关闭，select语句的case x := <-c1分支被选出执行，程序输出5，回到for循环并开始新一轮select。3）c1被关闭，由于从一个已关闭的channel接收数据将永远不会被阻塞，所以新一轮select又将case x := <-c1这个分支选出并执行。c1处于关闭状态，从这个channel获取数据会得到该channel对应类型的零值，这里就是0，于是程序再次输出0。程序按这个逻辑循环执行，一直输出0值。4）2s后，c2被写入一个数值7，这样在某一轮select的过程中，分支case x := <-c2被选中并得以执行。程序在输出7之后满足退出条件，于是程序终止。

>> 怎么来改进一下这个程序，使之按照我们的预期输出呢？nil channel是时候登场了！改进后的示例代码如下：
```go
// chapter6/sources/go-channel-case-10.go 
func main() {    
	c1, c2 := make(chan int), make(chan int)    
	go func() {        
		time.Sleep(time.Second * 5)        
		c1 <- 5        
		close(c1)    
	}()        
	go func() {        
		time.Sleep(time.Second * 7)        
		c2 <- 7        
		close(c2)    
	}()        
	for {        
		select {        
			case x, ok := <-c1:            
			if !ok {                
				c1 = nil            
			} else {                
				fmt.Println(x)            
			}        
			case x, ok := <-c2:                
			if !ok {                    
				c2 = nil                
			} else {                    
				fmt.Println(x)                
			}        
		}        
		if c1 == nil && c2 == nil {            
			break        
		}    
	}    
	fmt.Println("program end")
}
```
改进后的示例程序的最关键变化是在判断c1或c2被关闭后，显式地将c1或c2置为nil。我们知道，对一个nil channel执行获取操作，该操作将被阻塞，因此已经被置为nil的c1或c2的分支将再也不会被select选中执行。上述改进后的示例的运行结果如下：`$go run go-channel-case-10.go 57program end`


### 34.4 与select结合使用的一些惯用法

1. 利用default分支避免阻塞select语句的default分支的语义是在其他分支均因通信未就绪而无法被选择的时候执行，这就为default分支赋予了一种“避免阻塞”的特性。

>> 无论是无缓冲channel还是带缓冲channel，trySend和tryRecv这两个函数均适用，并且不会阻塞在空channel或元素个数已经达到容量上限的channel上。在Go标准库中，这个惯用法也有应用，比如：
```go
// $GOROOT/src/time/sleep.go
func sendTime(c interface{}, seq uintptr) {    
	// 无阻塞地向c发送当前时间    
	// ...    
	select {        
		case c.(chan Time) <- Now():        
		default:    
	}
}
```

2. 实现超时机制

+ 带超时机制的select是Go语言中一种常见的select和channel的组合用法，通过超时事件，我们既可以避免长期陷入某种操作的等待中，也可以做一些异常处理工作。下面的示例代码实现了一次具有30s超时的select：
```go
func worker() {    
	select {    
		case <-c:        // ...    
		case <-time.After(30 *time.Second):        
		return    
	}
}
```

+ 在应用带有超时机制的select时，要特别注意timer使用后的释放，尤其是在大量创建timer时。Go语言标准库提供的timer实质上是由Go运行时自行维护的，而不是操作系统级的定时器资源。Go运行时启动了一个单独的goroutine，该goroutine执行了一个名为timerproc的函数，维护了一个“最小堆”。该goroutine会被定期唤醒并读取堆顶的timer对象，执行该timer对象对应的函数（向timer.C中发送一条数据，触发定时器），执行完毕后就会从最小堆中移除该timer对象。创建一个time.Timer实则就是在这个最小堆中添加一个timer对象实例，而调用timer.Stop方法则是从堆中删除对应的timer对象。作为time.Timer的使用者，我们要做的就是尽量减轻在使用Timer时对管理最小堆的goroutine和Go GC的压力，即要及时调用timer的Stop方法从最小堆中删除尚未到达过期时间的timer对象。

3. 实现心跳机制结合time包的Ticker，我们可以实现带有心跳机制的select。这种机制使我们可以在监听channel的同时，执行一些周期性的任务，比如下面这段代码：
```go
func worker() {    
	heartbeat := time.NewTicker(30 * time.Second)    
	defer heartbeat.Stop()    
	for {        
		select {        
			case <-c:            // ... 处理业务逻辑        
			case <- heartbeat.C:            //... 处理心跳        
		}    
	}
}
```
与timer一样，我们在使用完ticker之后，要记得调用其Stop方法停止ticker的运作，这样在heartbeat.C上就不会再持续产生心跳事件了。

### 小结
Go channel就像Go并发模型中的“胶水”，它将诸多并发执行单元连接起来，或者正是因为有channel的存在，Go并发模型才能迸发出强大的表达能力。

### 本条要点：
了解Go并发原语channel和select的基本语义；掌握无缓冲channel在信号传递、替代锁同步场景下的应用模式；掌握带缓冲channel在消息队列、计数信号量场景下的应用模式，了解在特定场景下利用len函数侦测带缓冲channel的状态；了解nil channel在特定场景下的用途；掌握select与channel结合使用的一些惯用法及注意事项。


## 第35条 了解sync包的正确用法

+ Go语言在提供CSP并发模型原语的同时，还通过标准库的sync包提供了针对传统基于共享内存并发模型的基本同步原语，包括互斥锁（sync.Mutex）、读写锁（sync.RWMutex）、条件变量（sync.Cond）等。


### 35.1 sync包还是channel

+ Go语言提倡“不要通过共享内存来通信，而应该通过通信来共享内存”。

（1）需要高性能的临界区同步机制场景

>> 下面是sync.Mutex和channel各自实现的临界区同步机制的一个简单性能对比。

```go
// part6/sources/go-sync-package-1_test.go 
var cs = 0 // 模拟临界区要保护的数据
var mu sync.Mutexvar c = make(chan struct{}, 1)
func criticalSectionSyncByMutex() {    
	mu.Lock()    
	cs++    
	mu.Unlock()
}
func criticalSectionSyncByChan() {    
	c <- struct{}{}    
	cs++    
	<-c
}
func BenchmarkCriticalSectionSyncByMutex(b *testing.B) {    
	for n := 0; n < b.N; n++ {        
		criticalSectionSyncByMutex()    
	}
}
func BenchmarkCriticalSectionSyncByChan(b *testing.B) {    
	for n := 0; n < b.N; n++ {        
		criticalSectionSyncByChan()    
	}
}
```
运行这个对比测试（Go 1.13.6）：
`$go test -bench . go-sync-package-1_test.go goos: darwingoarch: amd64BenchmarkCriticalSectionSyncByMutex-8           84364287                13.3 ns/opBenchmarkCriticalSectionSyncByChan-8            26449521 `               44.4 ns/opPASS我们看到在这个对比实验中，sync.Mutex实现的同步机制的性能要比channel实现的高出两倍多。

（2）不想转移结构体对象所有权，但又要保证结构体内部状态数据的同步访问的场景基于channel的并发设计的一个特点是，在goroutine间通过channel转移数据对象的所有权。只有拥有数据对象所有权（从channel接收到该数据）的goroutine才可以对该数据对象进行状态变更。如果你的设计中没有转移结构体对象所有权，但又要保证结构体内部状态数据能在多个goroutine之间同步访问，那么你可以使用sync包提供的低级同步原语来实现，比如最常用的sync.Mutex。


### 35.2 使用sync包的注意事项

+ 在$GOROOT/src/sync/mutex.go文件中，我们看到这样一行关于使用sync包的注意事项：// Values containing the types defined in this package should not be copied.// 不应复制那些包含了此包中类型的值在sync包的其他源文件中，我们还会看到如下的一些注释：// $GOROOT/src/sync/mutex.go// A Mutex must not be copied after first use. (禁止复制首次使用后的Mutex)// $GOROOT/src/sync/rwmutex.go// A RWMutex must not be copied after first use.(禁止复制首次使用后的RWMutex)// $GOROOT/src/sync/cond.go// A Cond must not be copied after first use.(禁止复制首次使用后的Cond)...

>> Go标准库中sync.Mutex的定义如下：
// $GOROOT/src/sync/mutex.gotype Mutex struct {        state int32        sema  uint32}
我们看到Mutex的定义非常简单，它由两个字段state和sema组成。
•  state：表示当前互斥锁的状态。
•  sema：用于控制锁状态的信号量。
对Mutex实例的复制即是对两个整型字段的复制。在初始状态下，Mutex实例处于Unlocked状态（state和sema均为0）。

>> g3创建时恰恰复制了处于Locked状态的Mutex实例（副本的state字段值亦为sync.mutexLocked），因此g3再对其实例副本调用Lock方法将会导致其进入阻塞状态（也是死锁状态，因为没有任何其他机会调用该副本的Unlock方法了，并且Go不支持递归锁）。

+ 通过上述示例我们直观地看到，那些sync包中类型的实例在首次使用后被复制得到的副本一旦再被使用将导致不可预期的结果，为此在使用sync包中类型时，推荐通过闭包方式或传递类型实例（或包裹该类型的类型实例）的地址或指针的方式进行，这是使用sync包最值得注意的事项。


### 35.3 互斥锁还是读写锁

+ sync包提供了两种用于临界区同步的原语：互斥锁（Mutex）和读写锁（RWMutex）。互斥锁是临界区同步原语的首选，它常被用来对结构体对象的内部状态、缓存等进行保护，是使用最为广泛的临界区同步原语。

•  在并发量较小的情况下，互斥锁性能更好；随着并发量增大，互斥锁的竞争激烈，导致加锁和解锁性能下降。
•  读写锁的读锁性能并未随并发量的增大而发生较大变化，性能始终恒定在40ns左右。
•  在并发量较大的情况下，读写锁的写锁性能比互斥锁、读写锁的读锁都差，并且随着并发量增大，其写锁性能有继续下降的趋势。

+ 读写锁适合应用在具有一定并发量且读多写少的场合


### 35.4 条件变量

+ sync.Cond是传统的条件变量原语概念在Go语言中的实现。一个条件变量可以理解为一个容器，这个容器中存放着一个或一组等待着某个条件成立的goroutine。当条件成立时，这些处于等待状态的goroutine将得到通知并被唤醒以继续后续的工作。这与百米飞人大战赛场上各位运动员等待裁判员的发令枪声十分类似。

+ 条件变量是同步原语的一种，如果没有条件变量，开发人员可能需要在goroutine中通过连续轮询的方式检查是否满足条件。连续轮询非常消耗资源，因为goroutine在这个过程中处于活动状态但其工作并无进展。下面就是一个用sync.Mutex实现对条件的轮询等待的例子：
```go
// chapter6/sources/go-sync-package-4.go
type signal struct{}
var ready boolfunc worker(i int) {    
	fmt.Printf("worker %d: is working...\n", i)    
	time.Sleep(1 * time.Second)    
	fmt.Printf("worker %d: works done\n", i)
}
func spawnGroup(f func(i int), num int, mu *sync.Mutex) <-chan signal {    
	c := make(chan signal)    
	var wg sync.WaitGroup        
	for i := 0; i < num; i++ {        
		wg.Add(1)        
		go func(i int) {            
			for {                
				mu.Lock()                
				if !ready {                    
					mu.Unlock()                    
					time.Sleep(100 * time.Millisecond)                    
					continue                
				}                
				mu.Unlock()                
				fmt.Printf("worker %d: start to work...\n", i)                
				f(i)                
				wg.Done()                
				return            
			}        
		}(i + 1)    
	}        
	go func() {        
		wg.Wait()        
		c <- signal(struct{}{})    
	}()    
	return c
}
func main() {    
	fmt.Println("start a group of workers...")    
	mu := &sync.Mutex{}    
	c := spawnGroup(worker, 5, mu)        
	time.Sleep(5 * time.Second) // 模拟ready前的准备工作    
	fmt.Println("the group of workers start to work...")        
	mu.Lock()    
	ready = true    
	mu.Unlock()        
	<-c    
	fmt.Println("the group of workers work done!")
}
```

>> sync.Cond为goroutine在上述场景下提供了另一种可选的、资源消耗更小、使用体验更佳的同步方式。使用条件变量原语，我们可以在实现相同目标的同时避免对条件的轮询。
用sync.Cond对上面的例子进行改造，改造后的代码如下：
```go
// chapter6/sources/go-sync-package-5.go   
type signal struct{}
var ready boolfunc worker(i int) {    
	fmt.Printf("worker %d: is working...\n", i)    
	time.Sleep(1 * time.Second)    
	fmt.Printf("worker %d: works done\n", i)
}
func spawnGroup(f func(i int), num int, groupSignal *sync.Cond) <-chan signal {    
	c := make(chan signal)    
	var wg sync.WaitGroup        
	for i := 0; i < num; i++ {        
		wg.Add(1)        
		go func(i int) {            
			groupSignal.L.Lock()            
			for !ready {                
				groupSignal.Wait()           
			}            
			groupSignal.L.Unlock()            
			fmt.Printf("worker %d: start to work...\n", i)            
			f(i)            
			wg.Done()        
		}(i + 1)    
	}        
	go func() {        
		wg.Wait()        
		c <- signal(struct{}{})    
	}()    
	return c
}
func main() {    
	fmt.Println("start a group of workers...")    
	groupSignal := sync.NewCond(&sync.Mutex{})    
	c := spawnGroup(worker, 5, groupSignal)        
	time.Sleep(5 * time.Second) // 模拟ready前的准备工作    
	fmt.Println("the group of workers start to work...")        
	groupSignal.L.Lock()    
	ready = true    
	groupSignal.Broadcast()    
	groupSignal.L.Unlock()        
	<-c    
	fmt.Println("the group of workers work done!")
}
```

>> sync.Cond实例的初始化需要一个满足实现了sync.Locker接口的类型实例，通常我们使用sync.Mutex。条件变量需要这个互斥锁来同步临界区，保护用作条件的数据。各个等待条件成立的goroutine在加锁后判断条件是否成立，如果不成立，则调用sync.Cond的Wait方法进入等待状态。Wait方法在goroutine挂起前会进行Unlock操作。

>> 在main goroutine将ready置为true并调用sync.Cond的Broadcast方法后，各个阻塞的goroutine将被唤醒并从Wait方法中返回。在Wait方法返回前，Wait方法会再次加锁让goroutine进入临界区。接下来goroutine会再次对条件数据进行判定，如果条件成立，则解锁并进入下一个工作阶段；如果条件依旧不成立，那么再次调用Wait方法挂起等待。


### 35.5 使用sync.Once实现单例模式

+ 程序运行期间只被执行一次且goroutine安全的函数只有每个包的init函数。sync包提供了另一种更为灵活的机制，可以保证任意一个函数在程序运行期间只被执行一次，这就是sync.Once。

+ 在Go标准库中，sync.Once的“仅执行一次”语义被一些包用于初始化和资源清理的过程中，以避免重复执行初始化或资源关闭操作。比如：
```go
// $GOROOT/src/mime/type.go
func TypeByExtension(ext string) string {    
	once.Do(initMime)    ...
}// $GOROOT/src/io/pipe.go
func (p *pipe) CloseRead(err error) error {    
	if err == nil {        
		err = ErrClosedPipe    
	}    
	p.rerr.Store(err)    
	p.once.Do(func() { 
		close(p.done) 
	})    
	return nil
}
```

+ sync.Once的语义十分适合实现单例（singleton）模式，并且实现起来十分简单，我们看下面的例子。注意：GetInstance利用sync.Once实现的单例模式本可以十分简单
```go
// chapter6/sources/go-sync-package-6.go
type Foo struct { }
var once sync.Oncevar instance *Foofunc GetInstance(id int) *Foo {    
	defer func() {        
		if e := recover(); e != nil {            
			log.Printf("goroutine-%d: caught a panic: %s", id, e)        
		}    
	}()    
	log.Printf("goroutine-%d: enter GetInstance\n", id)    
	once.Do(func() {        
		instance = &Foo{}        
		time.Sleep(3 * time.Second)        
		log.Printf("goroutine-%d: the addr of instance is %p\n", id, instance)        
		panic("panic in once.Do function")    
	})    
	return instance
}
func main() {    
	var wg sync.WaitGroup    
	for i := 0; i < 5; i++ {        
		wg.Add(1)        
		go func(i int) {            
			inst := GetInstance(i)            
			log.Printf("goroutine-%d: the addr of instance returned is %p\n", i, inst)            
			wg.Done()        
		}(i + 1)    
	}    
	time.Sleep(5 * time.Second)    
	inst := GetInstance(0)    
	log.Printf("goroutine-0: the addr of instance returned is %p\n", inst)        
	wg.Wait()    
	log.Printf("all goroutines exit\n")
}
```

>> 运行该示例：
`$go run go-sync-package-6.go2020/02/09 18:46:30 goroutine-1: enter GetInstance2020/02/09 18:46:30 goroutine-4: enter GetInstance2020/02/09 18:46:30 goroutine-5: enter GetInstance2020/02/09 18:46:30 goroutine-3: enter GetInstance2020/02/09 18:46:30 goroutine-2: enter GetInstance2020/02/09 18:46:33 goroutine-1: the addr of instance is 0x1199b182020/02/09 18:46:33 goroutine-1: caught a panic: panic in once.Do function2020/02/09 18:46:33 goroutine-1: the addr of instance returned is 0x02020/02/09 18:46:33 goroutine-4: the addr of instance returned is 0x1199b182020/02/09 18:46:33 goroutine-5: the addr of instance returned is 0x1199b182020/02/09 18:46:33 goroutine-3: the addr of instance returned is 0x1199b182020/02/09 18:46:33 goroutine-2: the addr of instance returned is 0x1199b182020/02/09 18:46:35 goroutine-0: enter GetInstance2020/02/09 18:46:35 goroutine-0: the addr of instance returned is 0x1199b182020/02/09 18:46:35 all goroutines exit`
通过上述例子，我们观察到：
•  once.Do会等待f执行完毕后才返回，这期间其他执行once.Do函数的goroutine（如上面运行结果中的goroutine 2~5）将会阻塞等待；
•  Do函数返回后，后续的goroutine再执行Do函数将不再执行f并立即返回（如上面运行结果中的goroutine 0）；
•  即便在函数f中出现panic，sync.Once原语也会认为once.Do执行完毕，后续对once.Do的调用将不再执行f。


## 35.6 使用sync.Pool减轻垃圾回收压力

•  它是goroutine并发安全的，可以被多个goroutine同时使用；
•  放入该缓存池中的数据对象的生命是暂时的，随时都可能被垃圾回收掉；
•  缓存池中的数据对象是可以重复利用的，这样可以在一定程度上降低数据对象重新分配的频度，减轻GC的压力；
•  sync.Pool为每个P（goroutine调度模型中的P）单独建立一个local缓存池，进一步降低高并发下对锁的争抢。

+ 使用sync.Pool分配数据对象与通过new等常规方法分配数据对象的对比示例：

```go
// chapter6/sources/go-sync-package-7_test.go 
var bufPool = sync.Pool{    
	New: func() interface{} {        
		return new(bytes.Buffer)    
	},
}
func writeBufFromPool(data string) {    
	b := bufPool.Get().(*bytes.Buffer)    
	b.Reset()    
	b.WriteString(data)    
	bufPool.Put(b)
}
func writeBufFromNew(data string) *bytes.Buffer {    
	b := new(bytes.Buffer)    
	b.WriteString(data)    
	return b
}
func BenchmarkWithoutPool(b *testing.B) {    
	b.ReportAllocs()    
	for i := 0; i < b.N; i++ {        
		writeBufFromNew("hello")    
	}
}
func BenchmarkWithPool(b *testing.B) {    
	b.ReportAllocs()    
	for i := 0; i < b.N; i++ {        
		writeBufFromPool("hello")    
	}
}
```
` $go test -bench . go-sync-package-7_test.go goos: darwingoarch: amd64BenchmarkWithoutPool-8          33605625                32.8 ns/op            64 B/op          1 allocs/opBenchmarkWithPool-8             53222953                22.8 ns/op             0 B/op          0 allocs/opPASS`
我们看到通过sync.Pool来复用数据对象的方式可以有效降低内存分配频率，减轻垃圾回收压力，从而提高处理性能。sync.Pool的一个典型应用就是建立像bytes.Buffer这样类型的临时缓存对象池：
```go
var bufPool = sync.Pool{
	New: func() interface{} {
		return new(bytes.Buffer)
	},
}
```

>> 但实践告诉我们，这么用很可能会产生一些问题[1]。由于sync.Pool的Get方法从缓存池中挑选bytes.Buffer数据对象时并未考虑该数据对象是否满足调用者的需求，因此一旦返回的Buffer对象是刚刚被“大数据”撑大后的，并且即将被长期用于处理一些“小数据”时，这个Buffer对象所占用的“大内存”将长时间得不到释放。一旦这类情况集中出现，将会给Go应用带来沉重的内存消耗负担。为此，目前的Go标准库采用两种方式来缓解这一问题。

（1）限制要放回缓存池中的数据对象大小

>> 在Go标准库fmt包的代码中，我们看到：
```go
// $GOROOT/src/fmt/print.go
func (p *pp) free() {
	// 要正确使用sync.Pool,要求每个条目具有大致相同的内存成本
	// 若缓存池中存储的类型具有可变大小的缓冲区
	// 对放回缓存池的对象增加一个最大缓冲区的硬限制(不能大于65 536字节)
	//
	// 参见https://golang.org/issue/23199
	if cap(p.buf) > 64<<10 {
		return
	}
	p.buf = p.buf[:0]
	p.arg = nil
	p.value = reflect.Value{}
	p.wrappedErr = nil
	ppFree.Put(p)
}
```
fmt包对于要放回缓存池的buffer对象做了一个限制性校验：如果buffer的容量大于64<<10，则不让其回到缓存池中，这样可以在一定程度上缓解处理小对象时重复利用大Buffer导致的内存占用问题。
（2）建立多级缓存池
标准库的http包在处理http2数据时，预先建立了多个不同大小的缓存池：
```go
// $GOROOT/src/net/http/h2_bundle.go 
var (
	http2dataChunkSizeClasses = []int{
		1 << 10,
		2 << 10,
		4 << 10,
		8 << 10,
		16 << 10,
	}
	http2dataChunkPools = [...]sync.Pool{
		{New: func() interface{} { return make([]byte, 1<<10) }},
		{New: func() interface{} { return make([]byte, 2<<10) }},
		{New: func() interface{} { return make([]byte, 4<<10) }},
		{New: func() interface{} { return make([]byte, 8<<10) }},
		{New: func() interface{} { return make([]byte, 16<<10) }},
	}
)

func http2getDataBufferChunk(size int64) []byte {
	i := 0
	for ; i < len(http2dataChunkSizeClasses)-1; i++ {
		if size <= int64(http2dataChunkSizeClasses[i]) {
			break
		}
	}
	return http2dataChunkPools[i].Get().([]byte)
}
func http2putDataBufferChunk(p []byte) {
	for i, n := range http2dataChunkSizeClasses {
		if len(p) == n {
			http2dataChunkPools[i].Put(p)
			return
		}
	}
	panic(fmt.Sprintf("unexpected buffer len=%v", len(p)))
}
```
>> 这样就可以根据要处理的数据的大小从最适合的缓存池中获取Buffer对象，并在完成数据处理后将对象归还到对应的池中，而池中的所有临时buffer对象的容量始终是保持一致的，从而尽量避免大材小用、浪费内存的情况。

### 小结
本条对Go语言通过sync包提供的针对共享内存并发模型的原语的使用方法尤其是注意事项做了细致说明。
### 本条要点：
•  明确sync包中原语应用的适用场景；
•  sync包内定义的结构体或包含这些类型的结构体在首次使用后禁止复制；
•  明确sync.RWMutex的适用场景；
•  掌握条件变量的应用场景和使用方法；
•  实现单例模式时优先考虑sync.Once；
•  了解sync.Pool的优点、使用中可能遇到的问题及解决方法。


## 第36条 使用atomic包实现伸缩性更好的并发读取


### 36.1 atomic包与原子操作

+ atomic包封装了CPU实现的部分原子操作指令，为用户层提供体验良好的原子操作函数，因此atomic包中提供的原语更接近硬件底层，也更为低级，它常被用于实现更为高级的并发同步技术（比如channel和sync包中的同步原语）。

+ 以atomic.SwapInt64函数在x86_64平台上的实现为例：
```go
// $GOROOT/src/sync/atomic/doc.go
func SwapInt64(addr *int64, new int64) (old int64)
// $GOROOT/src/sync/atomic/asm.sTEXT ·SwapInt64(SB),NOSPLIT,$0    JMP     runtime∕internal∕atomic·Xchg64(SB)
```
```go
// $GOROOT/src/runtime/internal/asm_amd64.s
TEXT runtime∕internal∕atomic·Xchg64(SB), NOSPLIT, $0-24    MOVQ    ptr+0(FP), BX    MOVQ    new+8(FP), AX    XCHGQ   AX, 0(BX)    MOVQ    AX, ret+16(FP)    RET
```
从上面函数SwapInt64的实现中可以看到，它基本就是对x86_64 CPU实现的原子操作指令XCHGQ的直接封装。
原子操作的特性使atomic包可以用作对共享数据的并发同步，那么在它与更为高级的channel及sync包中原语之间，我们究竟该如何选择呢？在正式揭晓答案之前，我们先来看看下面两个应用atomic包的场景。


## 36.2 对共享整型变量的无锁读写

+ atomic包提供了两大类原子操作接口：一类是针对整型变量的，包括有符号整型、无符号整型以及对应的指针类型；另一类是针对自定义类型的。第一类原子操作接口的存在让atomic包天然适合于实现某一个共享整型变量的并发同步。
```go
// chapter6/sources/go-atomic-package-1_test.go 
var n1 int64func addSyncByAtomic(delta int64) int64 {    
	return atomic.AddInt64(&n1, delta)
}
func readSyncByAtomic() int64 {    
	return atomic.LoadInt64(&n1)
}
var n2 int64var rwmu sync.RWMutexfunc addSyncByRWMutex(delta int64) {    
	rwmu.Lock()    
	n2 += delta    
	rwmu.Unlock()
}
func readSyncByRWMutex() int64 {    
	var n int64    
	rwmu.RLock()    
	n = n2    
	rwmu.RUnlock()    
	return n
}
func BenchmarkAddSyncByAtomic(b *testing.B) {    
	b.RunParallel(func(pb *testing.PB) {        
		for pb.Next() {            
			addSyncByAtomic(1)        
		}    
	})
}
func BenchmarkReadSyncByAtomic(b *testing.B) {    
	b.RunParallel(func(pb *testing.PB) {        
		for pb.Next() {            
			readSyncByAtomic()        
		}    
	})
}
func BenchmarkAddSyncByRWMutex(b *testing.B) {    
	b.RunParallel(func(pb *testing.PB) {        
		for pb.Next() {            
			addSyncByRWMutex(1)        
		}    
	})
}
func BenchmarkReadSyncByRWMutex(b *testing.B) {    
	b.RunParallel(func(pb *testing.PB) {        
		for pb.Next() {            
			readSyncByRWMutex()        
		}    
	})
}
```

•  读写锁的性能随着并发量增大的变化情况与前面讲解sync.RWMutex时的一致；
•  利用原子操作的无锁并发写的性能随着并发量增大几乎保持恒定；
•  利用原子操作的无锁并发读的性能随着并发量增大有持续提升的趋势，并且性能约为读锁的200倍。


### 36.3 对共享自定义类型变量的无锁读写

+ 我们再来看atomic包另一类函数的应用。如图36-2所示，atomic通过Value类型的装拆箱操作实现了对任意自定义类型的原子操作（Load和Store），从而实现对共享自定义类型变量无锁读写的支持。
```go
// chapter6/sources/go-atomic-package-2_test.go 
type Config struct {    
	sync.RWMutex    
	data string
}
func BenchmarkRWMutexSet(b *testing.B) {   
	 config := Config{}    
	 b.ReportAllocs()    
	 b.RunParallel(func(pb *testing.PB) {        
		for pb.Next() {            
			config.Lock()            
			config.data = "hello"            
			config.Unlock()        
		}    
	})
}
func BenchmarkRWMutexGet(b *testing.B) {    
	config := Config{data: "hello"}    
	b.ReportAllocs()    
	b.RunParallel(func(pb *testing.PB) {        
		for pb.Next() {            
			config.RLock()            
			_ = config.data            
			config.RUnlock()        
		}    
	})
}
func BenchmarkAtomicSet(b *testing.B) {    
	var config atomic.Value    
	c := Config{data: "hello"}    
	b.ReportAllocs()    
	b.RunParallel(func(pb *testing.PB) {        
		for pb.Next() {            
			config.Store(c)        
		}    
	})
}
func BenchmarkAtomicGet(b *testing.B) {    
	var config atomic.Value    
	config.Store(Config{data: "hello"})    
	b.ReportAllocs()    
	b.RunParallel(func(pb *testing.PB) {        
		for pb.Next() {            
			_ = config.Load().(Config)        
		}    
	})
}

```

•  利用原子操作的无锁并发写的性能随着并发量的增大而小幅下降；
•  利用原子操作的无锁并发读的性能随着并发量增大有持续提升的趋势，并且性能约为读锁的100倍。

### 小结
是时候揭晓答案了。由上面两类atomic包应用的例子可知，随着并发量提升，使用atomic实现的共享变量的并发读写性能表现更为稳定，尤其是原子读操作，这让atomic与sync包中的原语比起来表现出更好的伸缩性和更高的性能。由此可以看出atomic包更适合一些对性能十分敏感、并发量较大且读多写少的场合。
但atomic原子操作可用来同步的范围有较大限制，仅是一个整型变量或自定义类型变量。如果要对一个复杂的临界区数据进行同步，那么首选依旧是sync包中的原语。


# 第七部分 错误处理


## 第37条 了解错误处理的4种策略

>> Go语言没有像C++、Java、Python等主流编程语言那样提供基于异常（exception）的结构化try-catch-finally错误处理机制，Go的设计者们认为将异常耦合到程序控制结构中会导致代码混乱[2]，并且在那样的机制下，程序员会将大多常见错误（例如无法打开文件等）标记为异常，这与Go追求简单的价值观背道而驰。
Go语言设计者们选择了C语言家族的经典错误机制：错误就是值，而错误处理就是基于值比较后的决策。同时，Go结合函数/方法的多返回值机制避免了像C语言那样在单一函数返回值中承载多重信息的问题。

>> Go这种简单的基于错误值比较的错误处理机制使得每个Go开发人员必须显式地关注和处理每个错误，经过显式错误处理的代码会更为健壮，Go开发人员也会对这些代码更有信心。Go中的错误不是异常，它就是普通值，我们不需要额外的语言机制去处理它们，而只需利用已有的语言机制，像处理其他普通类型值一样去处理错误。这也决定了这样的错误处理机制让代码更容易调试（就像对待普通变量值那样），也更容易针对每个错误处理的决策分支进行测试覆盖；同时，没有try-catch-finally的异常处理机制也让Go代码的可读性更佳。

+ 要写出高质量的Go代码，我们需要始终想着错误处理。这些年来，Go核心开发团队与Go社区已经形成了4种惯用的Go错误处理策略。


### 37.1 构造错误值

+  在标准库中，Go提供了构造错误值的两种基本方法——errors.New和fmt.Errorf，示例如下：
```go
err := errors.New("your first demo error")
errWithCtx = fmt.Errorf("index %d is out of bounds", i)
wrapErr = fmt.Errorf("wrap error: %w", err) // 仅Go 1.13及后续版本可用
```

+ Go 1.13及后续版本中，当我们在格式化字符串中使用%w时，fmt.Errorf返回的错误值的底层类型为fmt.wrapError：
```go
 $GOROOT/src/fmt/errors.go (Go 1.13及后续版本)
 type wrapError struct {   
	msg string    
	err error
}
func (e *wrapError) Error() string {    
	return e.msg
}
func (e *wrapError) Unwrap() error {    
	return e.err
}
```
与errorString相比，wrapError多实现了Unwrap方法，这使得被wrapError类型包装的错误值在包装错误链中被检视（inspect）到
```go
var ErrFoo = errors.New("the underlying error")
err := fmt.Errorf("wrap err: %w", ErrFoo)
errors.Is(err, ErrFoo) // true (仅适用于Go 1.13及后续版本)
```

+ 我们看到，标准库中提供的构建错误值的方法虽方便有余，但给错误处理者提供的错误上下文（error context）则仅限于以字符串形式呈现的信息（Error方法返回的信息）。在一些场景下，错误处理者需要从错误值中提取出更多信息以帮助其选择错误处理路径，这时他们可以自定义错误类型来满足需求。比如：标准库中的net包就定义了一种携带额外错误上下文的错误类型。
```go
// $GOROOT/src/net/net.gotype
OpError struct {    
	Op string    
	Net string    
	Source Addr    
	Addr Addr    
	Err error
}
```

+ 这样错误处理者便可以根据这个类型的错误值提供的额外上下文信息做出错误处理路径的选择，相关代码如下：
```go
// $GOROOT/src/net/http/server.go
func isCommonNetReadError(err error) bool {    
	if err == io.EOF {        
		return true    
	}    
	if neterr, ok := err.(net.Error); ok && neterr.Timeout() {        
		return true    
	}    
	if oe, ok := err.(*net.OpError); ok && oe.Op == "read" {        
		return true    
	}    
	return false
}
```
error接口是错误值提供者与错误值检视者之间的契约。error接口的实现者负责提供错误上下文供负责错误处理的代码使用。这种错误上下文与error接口类型的分离体现了Go设计哲学中的“正交”理念。


### 37.2 透明错误处理策略

+ 最简单的错误策略莫过于完全不关心返回错误值携带的具体上下文信息，只要发生错误就进入唯一的错误处理执行路径。这也是Go语言中最常见的错误处理策略，80%以上的Go错误处理情形可以归类到这种策略下。
```go
err := doSomething()if err != nil {    
	// 不关心err变量底层错误值所携带的具体上下文信息    
	// 执行简单错误处理逻辑并返回    ...    
return err}
```

+ 在这种策略下由于错误处理方并不关心错误值的上下文，因此错误值的构造方（如上面的函数doSomething）可以直接使用Go标准库提供的两个基本错误值构造方法errors.New和fmt.Errorf构造错误值。这样构造出的错误值对错误处理方是透明的，因此这种策略被称为“透明错误处理策略”。

+ 透明错误处理策略最大限度地减少了错误处理方与错误值构造方之间的耦合关系，它们之间唯一的耦合就是error接口变量所规定的契约。


### 37.3 “哨兵”错误处理策略

+ Go标准库采用了定义导出的（exported）“哨兵”错误值的方式来辅助错误处理方检视错误值并做出错误处理分支的决策：

```go
// $GOROOT/src/bufio/bufio.govar (    
	ErrInvalidUnreadByte = errors.New("bufio: invalid use of UnreadByte")    
	ErrInvalidUnreadRune = errors.New("bufio: invalid use of UnreadRune")    
	ErrBufferFull        = errors.New("bufio: buffer full")    
	ErrNegativeCount     = errors.New("bufio: negative count"))
	// 错误处理代码
	data, err := b.Peek(1)
	if err != nil {    
		switch err {    
			case bufio.ErrNegativeCount:        
			// ...        
			return    
			case bufio.ErrBufferFull:        
			// ...        
			return    
			case bufio.ErrInvalidUnreadByte:        
			// ...        
			return    
			default:        
			// ...        
			return    
		}
	}
	// 或者
	if err := doSomething(); err == bufio.ErrBufferFull {    
		// 处理缓冲区满的错误情况    ...
	}
```

+ 一般“哨兵”错误值变量以ErrXXX格式命名。与透明错误策略相比，“哨兵”策略让错误处理方在有检视错误值的需求时有的放矢。不过对于API的开发者而言，暴露“哨兵”错误值意味着这些错误值和包的公共函数/方法一起成为API的一部分。一旦发布出去，开发者就要对其进行很好的维护。而“哨兵”错误值也让使用这些值的错误处理方对其产生了依赖。
从Go 1.13版本开始，标准库errors包提供了Is方法用于错误处理方对错误值进行检视。

+ 如果error类型变量的底层错误值是一个包装错误（wrap error），errors.Is方法会沿着该包装错误所在错误链（error chain）与链上所有被包装的错误（wrapped error）进行比较，直至找到一个匹配的错误。


### 37.4 错误值类型检视策略

+ 基于Go标准库提供的错误值构造方法构造的“哨兵”错误值除了让错误处理方可以有的放矢地进行值比较，并未提供其他有效的错误上下文信息。如果错误处理方需要错误值提供更多的错误上下文，上面的错误处理策略和错误值构造方式将无法满足。

+ 我们需要通过自定义错误类型的构造错误值的方式来提供更多的错误上下文信息，并且由于错误值均通过error接口变量统一呈现，要得到底层错误类型携带的错误上下文信息，错误处理方需要使用Go提供的类型断言机制（type assertion）或类型选择机制（type switch），这种错误处理笔者称之为错误值类型检视策略。我们来看一个标准库中的例子。
json包中自定义了一个UnmarshalTypeError的错误类型：
```go
// $GOROOT/src/encoding/json/decode.go
type UnmarshalTypeError struct {    
	Value  string           
	Type   reflect.Type    
	Offset int64            
	Struct string          
	Field  string       
}
```

+ 错误处理方可以通过错误类型检视策略获得更多错误值的错误上下文信息：
```go
// $GOROOT/src/encoding/json/decode_test.go
// 通过类型断言机制获取
func TestUnmarshalTypeError(t *testing.T) {    
	for _, item := range decodeTypeErrorTests {        
		err := Unmarshal([]byte(item.src), item.dest)        
		if _, ok := err.(*UnmarshalTypeError); !ok {            
			t.Errorf("expected type error for Unmarshal(%q, type %T): got %T",                    
			item.src, item.dest, err)        
		}    
	}
}
// $GOROOT/src/encoding/json/decode.go// 通过类型选择机制获取
func (d *decodeState) addErrorContext(err error) error {    
	if d.errorContext.Struct != nil || len(d.errorContext.FieldStack) > 0 {        
		switch err := err.(type) {        
			case *UnmarshalTypeError:            
			err.Struct = d.errorContext.Struct.Name()            
			err.Field = strings.Join(d.errorContext.FieldStack, ".")            
			return err        
		}    
	}    
return err
}
```
一般自定义导出的错误类型以XXXError的形式命名。与“哨兵”错误处理策略一样，由于错误值类型检视策略暴露了自定义的错误类型给错误处理方，因此这些错误类型也和包的公共函数/方法一起成为了API的一部分。一旦发布出去，开发者就要对其进行很好的维护。而它们也让借由这些类型进行检视的错误处理方对其产生了依赖。

+ 从Go 1.13版本开始，标准库errors包提供了As方法用于错误处理方对错误值进行检视。As方法类似于通过类型断言判断一个error类型变量是否为特定的自定义错误类型：
```go
// 类似 
if e, ok := err.(*MyError); ok { … }
var e *MyErrorif errors.As(err, &e) {    
	// 如果err类型为*MyError，变量e将被设置为对应的错误值
}
```
不同的是，如果error类型变量的底层错误值是一个包装错误，那么errors.As方法会沿着该包装错误所在错误链与链上所有被包装的错误的类型进行比较，直至找到一个匹配的错误类型。下面是As函数的一个应用。
```go
// chapter7/sources/go-error-handling-strategy-2.go
type MyError struct {    
	e string
}
func (e *MyError) Error() string {    
	return e.e
}
func main() {    
	var err = &MyError{"my error type"}    
	err1 := fmt.Errorf("wrap err1: %w", err)    
	err2 := fmt.Errorf("wrap err2: %w", err1)    
	var e *MyError    
	if errors.As(err2, &e) {        
		println("MyError is on the chain of err2 ")        
		println(e == err)        
		return    
	}        
	println("MyError is not on the chain of err2 ")
}
```
运行上述代码：
`$go run go-error-handling-strategy-2.go MyError is on the chain of err2 true`
我们看到，errors.As函数沿着err2所在错误链向上找到了被包装到最深处的错误值，并将err2与其类型*MyError成功匹配。
因此，如果你使用的是Go 1.13及后续版本，请尽量使用errors.As方法去检视某个错误值是不是某个自定义错误类型的实例。


### 37.5 错误行为特征检视策略

+ 到这里，我们需要思考一个问题：除了透明错误处理策略，是否还有手段可以降低错误处理方与错误值构造方的耦合？在Go标准库中，我们发现了这样一种错误处理方式：将某个包中的错误类型归类，统一提取出一些公共的错误行为特征（behaviour），并将这些错误行为特征放入一个公开的接口类型中。以标准库中的net包为例，它将包内的所有错误类型的公共行为特征抽象并放入net.Error这个接口中。而错误处理方仅需依赖这个公共接口即可检视具体错误值的错误行为特征信息，并根据这些信息做出后续错误处理分支选择的决策。
```go
// $GOROOT/src/net/net.go
type Error interface {    
	error    Timeout() bool   
	// 是超时类错误吗？    
	Temporary() bool 
	// 是临时性错误吗？
}
```
下面是http包使用错误行为特征检视策略进行错误处理的代码：
```go
// $GOROOT/src/net/http/server.go
func (srv *Server) Serve(l net.Listener) error {    ...    
	for {        
		rw, e := l.Accept()        
		if e != nil {            
			select {            
				case <-srv.getDoneChan():                
				return ErrServerClosed            
				default:            
			}            
			if ne, ok := e.(net.Error); ok && ne.Temporary() {                
				// 这里对临时性错误进行处理                ...                
				time.Sleep(tempDelay)                
				continue            
			}            
			return e        
		}        ...    
	}    ...
}
```
Accept方法实际上返回的错误类型为*OpError，它是net包中的一个自定义错误类型，实现了错误公共特征接口net.Error，因此可以被错误处理方通过net.Error接口的方法判断其行为是否满足Temporary或Timeout特征。
```go
// $GOROOT/src/net/net.go
type OpError struct {    ...    
// Err is the error that occurred during the operation.    Err error
}
type temporary interface {    
	Temporary() bool
}
func (e *OpError) Temporary() bool {    
	if ne, ok := e.Err.(*os.SyscallError); ok {        
		t, ok := ne.Err.(temporary)        
		return ok && t.Temporary()    
	}    
	t, ok := e.Err.(temporary)    
	return ok && t.Temporary()
}
```
### 小结
Go社区中关于如何进行错误处理的讨论有很多，但唯一正确的结论是没有哪一种错误处理策略适用于所有项目或场合。综合上述的构造错误值方法及错误处理策略，请记住如下几点：
•  尽量使用透明错误处理策略降低错误处理方与错误值构造方之间的耦合；
•  如果可以通过错误值类型的特征进行错误检视，那么尽量使用错误行为特征检视策略；
•  在上述两种策略无法实施的情况下，再用“哨兵”策略和错误值类型检视策略；
•  在Go 1.13及后续版本中，尽量用errors.Is和errors.As方法替换原先的错误检视比较语句。


## 第38条 尽量优化反复出现的if err != nil

+ C++、C#、Java和Python等支持异常处理的主流编程语言采用对隐式结果的隐式错误检查，与之不同的是，Go在最初设计时就有意识地选择了使用显式错误结果和显式错误检查。


### 38.1 两种观点

### 38.2 尽量优化

+ Lohuizen也对if err != nil的重复出现情况进行了研究。如图38-2所示，他发现代码所在栈帧越低（越接近于main函数栈帧），if err != nil就越不常见；反之，代码在栈中的位置越高（更接近于网络I/O操作或操作系统API调用），if err != nil就越常见

+ 不过该开发人员也认为，可以通过良好的设计减少或消除这类反复出现的错误检查。


### 38.3 优化思路

+ 优化反复出现的if err != nil代码块的根本目的是让错误检查和处理较少，不要干扰正常业务代码，让正常业务代码更具视觉连续性。大致有两个努力的方向。

1）改善代码的视觉呈现。

>> 这个优化方法就好比给开发人员施加了某种障眼法，使得错误处理代码在开发者眼中的视觉呈现更为优雅。

>> 提供一种改善代码视觉呈现的语法糖。

>> 如果待优化的代码像下面这样：
```go
func SomeFunc() error {    
	err := doStuff1()    
	if err != nil {        
		// 处理错误    
	}        
	err = doStuff2()    
	if err != nil {        
		// 处理错误    
	}        
	err = doStuff3()    
	if err != nil {        
		// 处理错误    
	}
}
```
那么经由try技术草案优化后的代码将大致变成这样（由于try提案被否决，因此我们无法真实实现下面的错误处理）：
```go
func SomeFunc() error {    
	defer func() {        
		if err != nil {            
			// 处理错误        
		}    
	}()    
	try(doStuff1())    
	try(doStuff2())    
	try(doStuff3())
}
```

2）降低if err != nil重复的次数。

 这其实是将该问题转换为降低函数/方法的复杂度了。


图38-4　if err != nil优化思路的四象限图

1. 视觉扁平化
Go支持将触发错误处理的语句与错误处理代码放在一行，比如上面的SomeFunc函数，可以将之等价重写为下面的代码：
```go
func SomeFunc() error {    
	if err := doStuff1(); err != nil { 
		// 处理错误 
	}    
	if err := doStuff2(); err != nil { 
		// 处理错误 
	}    
	if err := doStuff3(); err != nil { // 处理错误 
	}
}
```

>> 不过这种优化显然是有约束的，如果错误处理分支的语句不是简单的return err，而是复杂如下面的代码：
```go
if _, err = io.Copy(w, r); err != nil {   
	 return fmt.Errorf("copy %s %s: %v", src, dst, err)
}
```
那么“扁平化”会导致代码行过长，反倒降低了视觉呈现的优雅度。另外如果你使用goim-ports或gofmt工具对代码进行自动格式化，那么这些格式化工具会自动展开上述代码，这会让你困惑不已。

2. 重构：减少if err != nil的重复次数

>> 沿着降低复杂度的方向对待优化代码进行重构，以减少if err != nil代码片段的重复次数。

3. check/handle风格化

>> 上面位于第四象限的重构之法虽然减少了if err != nil代码片段的重复次数，但其视觉呈现依旧欠佳。Go2的check/handle技术草案的思路给了我们一些启发：可以利用panic和recover封装一套跳转机制，模拟实现一套check/handle机制。

>> 这样在降低复杂度的同时，也能在视觉呈现上有所改善。

```go
// chapter7/sources/go-if-error-check-optimize-2.go
func check(err error) {    
	if err != nil {        
		panic(err)    
	}
}
func CopyFile(src, dst string) (err error) {    
	var r, w *os.File        
	// 处理错误    
	defer func() {        
		if r != nil {            
			r.Close()        
		}        
		if w != nil {            
			w.Close()        
		}        
		if e := recover(); e != nil {            
			if w != nil {                
				os.Remove(dst)            
			}            
			err = fmt.Errorf("copy %s %s: %v", src, dst, err)        
		}    
	}()        
	r, err = os.Open(src)    
	check(err)        
	w, err = os.Create(dst)    
	check(err)        
	_, err = io.Copy(w, r)    
	check(err)        
	return nil
}
```
+ 不过这一优化方案也具有一定的约束，比如函数必须使用具名的error返回值，使用defer有额外的性能开销（在Go 1.14版本中，与不使用defer的性能差异微乎其微，可忽略不计），使用panic和recover也有额外的性能开销等。尤其是，panic和recover的性能要比正常函数返回的性能差很多

+ panic和recover让函数调用的性能降低了约90%。因此，我们在使用这种方案优化重复代码前，需要全面了解这些约束。

4. 封装：内置error状态

>> 在“Errors are values”[1]一文中，Rob Pike为我们呈现了在Go标准库中使用了避免if err != nil反复出现的一种代码设计思路。bufio包的Writer就是使用这个思路实现的，因此它可以像下面这样使用：
```go
b := bufio.NewWriter(fd)
b.Write(p0[a:b])
b.Write(p1[c:d])
b.Write(p2[e:f])
if b.Flush() != nil {    
	return b.Flush()
}
```

>> 上述代码中并没有判断三个b.Write的返回错误值，那么错误处理放在哪里了呢？打开$GOROOT/src/bufio/bufio.go可以看到下面的代码：
```go
// $GOROOT/src/bufio/bufio.go
type Writer struct {    
	err error    
	buf []byte    
	n   int    
	wr  io.Writer
}
func (b *Writer) Write(p []byte) (nn int, err error) {    
	for len(p) > b.Available() && b.err == nil {        
		...    
	}    
	if b.err != nil {        
		return nn, b.err    
	}    
	......    
	return nn, nil
}
```
可以看到，错误状态被封装在bufio.Writer结构的内部了，Writer定义了一个err字段作为内部错误状态值，它与Writer的实例绑定在了一起，并且在Write方法的入口判断是否为nil。一旦不为nil，Write什么都不做就会返回。

+ 这显然是消除if err != nil代码片段重复出现的理想方法。我们还是以CopyFile为例，看看使用这种“内置error状态”的新封装方法后，能得到什么样的代码：
```go
// chapter7/sources/go-if-error-check-optimize-3.go
type FileCopier struct {    
	w   *os.File    
	r   *os.File    
	err error
}
func (f *FileCopier) open(path string) (*os.File, error) {    
	if f.err != nil {        
		return nil, f.err    
	}        
	h, err := os.Open(path)    
	if err != nil {        
		f.err = err        
		return nil, err    
	}    
	return h, nil
}
func (f *FileCopier) openSrc(path string) {    
	if f.err != nil {        
		return    
	}        
	f.r, f.err = f.open(path)    
	return
}
func (f *FileCopier) createDst(path string) {    
	if f.err != nil {        
		return    
	}        
	f.w, f.err = os.Create(path)    
	return
}
func (f *FileCopier) copy() {    
	if f.err != nil {        
		return    
	}        
	if _, err := io.Copy(f.w, f.r); err != nil {        
		f.err = err    
	}
}

func (f *FileCopier) CopyFile(src, dst string) error {    
	if f.err != nil {        
		return f.err    
	}        
	defer func() {        
		if f.r != nil {            
			f.r.Close()        
		}        
		if f.w != nil {            
			f.w.Close()        
		}        
		if f.err != nil {            
			if f.w != nil {                
				os.Remove(dst)            
			}        
		}    
	}()        
	f.openSrc(src)    
	f.createDst(dst)    
	f.copy()    
	return f.err
}
func main() {    
	var fc FileCopier    
	err := fc.CopyFile("foo.txt", "bar.txt")    
	if err != nil {        
		fmt.Println("copy file error:", err)        
		return    
	}    
	fmt.Println("copy file ok")
}
```
这次的重构很彻底。我们将原CopyFile函数彻底抛弃，而重新将其逻辑封装到一个名为FileCopier结构的CopyFile方法中。FileCopier结构内置了一个err字段用于保存内部的错误状态，这样在其CopyFile方法中，我们只需按照正常业务逻辑，顺序执行openSrc、createDst和copy即可，正常业务逻辑的视觉连续性就这样被很好地实现了。同时该CopyFile方法的复杂度因if检查的“大量缺席”而变得很低。

### 小结
Go显式错误处理的设计既有其优势，也有其编写冗长的不足，至今针对Go错误处理尚未形成一致的改进意见。我们能做的就是尽可能对反复出现的if err != nil进行优化，本条给出了若干优化思路。
本条要点：
•  使用显式错误结果和显式的错误检查是Go语言成功的重要因素，也是if err != nil反复出现的根本原因；
•  了解关于改善Go错误处理的两种观点；
•  了解减少甚至消除if err != nil代码片段的两个优化方向，即改善视觉呈现与降低复杂度；
•  掌握错误处理代码优化的四种常见方法（位于三个不同象限中），并根据所处场景与约束灵活使用。


## 第39条 不要使用panic进行正常的错误处理

+ Go的正常错误处理与异常处理之间是泾渭分明的，这与其他主流编程语言使用结构化错误处理统一处理错误与异常是两种不同的理念。Go提供了panic专门用于处理异常，而我们建议不要使用panic进行正常的错误处理。


### 39.1 Go的panic不是Java的checked exception


>> Go语言初学者，尤其是那些来自Java语言阵营的程序员，在使用Go进行错误处理时，Java的那种基于try-catch-finally捕捉异常的错误处理思维惯性让他们更倾向于寻找与Java异常throw和catch相似的机制，而不是使用Go惯用的显式错误处理，于是Go语言提供的panic和recover机制似乎成为他们的“救命稻草”。但事情真的如这些初学者所愿吗？
熟悉Java语言的程序员都清楚：Java的错误处理是建构在整套异常处理机制之上的。Java中的异常有两种：checked exception和unchecked exception。如果一个API抛出checked exception，那么调用该API的外层代码就必须处理该checked exception（要么通过try-catch捕捉，要么重新抛给更上一层处理），否则代码无法通过编译。API的调用者还可以通过API方法原型中的throws语句显式了解到该API可能会抛出哪些checked exception。
那么Go的panic是否真的可以像Java的checked exception一样用于正常的错误处理呢？我们要看看两者在语义和语言机制上面是否真的相似。

1. checked exception实质是错误，而panic是异常
查看Java标准类库，我们可以看到Java已预定义好的一些checked exception类，较为常见的有IOException、TimeoutException、EOFException、FileNotFoundException等。一个深谙Go标准库的Gopher看到这些后肯定会感叹：这和Go标准库预定义的哨兵错误，比如io.EOF、os.ErrNotExist等是如此相似。
Java程序员还可以根据多变的业务场景自定义checked exception类（继承自java.lang.Exception），用来满足该场景下错误处理的需要，比如：
```java
// chapter7/sources/JavaDemoHeightException/HeightOutOfBound.java
package demo;  
public class HeightOutOfBound extends Exception {    
	public String toString() {        
		return "the height is out of the human's height bound";    
	}
}
// chapter7/sources/JavaDemoHeightException/HeightInput.java
package demo;  
public class HeightInput {    
	public static void checkHeight(int height) throws HeightOutOfBound {        
		if(height>20 && height<300){            
			System.out.print("ok");        
		}else{            
			throw new HeightOutOfBound();        
		}    
	}
}
// chapter7/sources/JavaDemoHeightException/Demo.java
package demo;  
public class Demo {    
	public static void main(String[] args) {        
		int height = 300;        
		try {            
			HeightInput.checkHeight(height);        
		} catch (HeightOutOfBound e) {             
			System.out.printf("%s %s\n", "Are you a real human?", e);        
		}    
	}
}
```
以上是一个校验人身高范围的场景。这里自定义了一个HeightOutOfBound类，如果身高不在合理范围内，则checkHeight方法将抛出该自定义checked exception：HeightOutOfBound类的实例。

>> 这种自定义的checked exception 与Go中使用errors.New、fmt.Errorf定义的error接口的实现类型十分类似。因此我们可以明确：Java的checked exception用于一些可预见的、常会发生的错误场景，针对checked exception的所谓异常处理就是针对这些场景的错误处理预案。也可以说对checked exception的使用、捕获、自定义等行为均是“有意而为之”。如果非要与Go中的某种语法对应，它对应的也应该是Go的正常错误处理，即基于显式error模型的显式错误处理。因此，对checked exception处理的本质是错误处理，虽然其名字中带有exception（异常）字样。
而panic又是什么呢？Go官方博客上的文章“Defer, Panic, and Recover”[1]是这么介绍引发panic的panic函数的：
panic是一个Go内置函数，它用来停止当前常规控制流并启动panicking过程。当函数F调用panic函数时，函数F的执行停止，函数F中已进行了求值的defer函数都将得到正常执行，然后函数F将控制权返还给其调用者。对于函数F的调用者而言，函数F之后的行为就如同调用者调用的函数是panic一样，该panicking过程将继续在栈上进行下去，直到当前goroutine中的所有函数都返回为止，此时程序将崩溃退出。panic可以通过直接调用panic函数来引发，它们也可能是由运行时错误引起，例如越界数组访问。

+ 和Java中checked exception的“有意而为之”相反，在Go中，panic则是“不得已而为之”，即所有引发panic的情形，无论是显式的（我们主动调用panic函数引发的）还是隐式的（Go运行时检测到违法情况而引发的），都是我们不期望看到的。对这些引发的panic，我们很少有预案应对，更多的是让程序快速崩溃掉。因此一旦发生panic，就意味着我们的代码很大可能出现了bug。因此，Go中的panic更接近于Java的RuntimeException+Error，而不是checked exception。
2. API调用者没有义务处理panic
前面提到过Java的checked exception是必须被上层代码处理的，要么捕获处理，要么重新抛给更上层。但是在Go中，我们通常会导入大量第三方包，但不知道这些第三方包API中是否会引发panic（目前也没有现成的工具去发现），因此上层代码，即API调用者根本不会逐一了解API是否会引发panic，也没有义务去处理引发的panic。一旦你像使用checked exception那样将panic作为正常错误处理的手段，而在你编写的API中将引发的panic当作错误，那么你就会给你的API调用者带去大麻烦！

3. 未被捕获的panic意味着“游戏结束”
如果API抛出checked exception，那么Java编译器将严格要求上层代码对这个checked exception进行处理。但一旦你在Go API中引发panic，就像上面提到的，API的调用者并没有义务处理该panic，因此该panic就会沿着调用函数栈向上“蔓延”，直到所有函数都返回，调用该API的goroutine将携带着panic信息退出。但事情并没有就此打住，一旦panic没有被捕获（recover），它导致的可不只是一个goroutine的退出，而是整个Go程序的“游戏结束” —— 崩溃退出！

+ 综上，Go panic不应被当作Java的checked exception来进行正常的错误处理。使用错误 （error）和多返回值的显式错误处理方式才符合Go的错误处理哲学。

>> [1]https://blog.golang.org/defer-panic-and-recover


### 39.2 panic的典型应用

>> 如果你的业务代码中没有自行调用panic引发异常，那么至少说明除了Go运行时panic外，你的代码对任何“不正常”的情况都是可以明确告知上层代码准备处理预案的（有准备的正常错误处理逻辑）。我们要尽可能少用panic，避免给上层带去它们也无法处理的情况。不过，少用不代表不用，关于如何更好地使用panic，Go标准库对panic的使用给了我们一些启示。

1. 充当断言角色，提示潜在bug

>> 使用C编写代码时，我们经常在一些代码执行路径上使用断言（assert宏）来表达这段执行路径上某种条件一定为真的信心。断言为真，则程序处于正确运行状态，否则就是出现了意料之外的问题，而这个问题很可能就是一个潜在的bug，这时我们可以借助断言信息快速定位到问题所在。
Go语言标准库没有提供断言（虽然我们可以自己实现一个），我们可以使用panic来部分模拟断言的潜在bug提示的功能。下面是标准库encoding/json包中关于panic消息的一段注释：
// $GOROOT/src/encoding/json/decode.go...// 当一些本不该发生的事情导致我们结束处理时，phasePanicMsg将被用作panic消息// 它可以指示JSON解码器中有bug// 或者在解码器执行时还有其他代码正在修改数据切片const phasePanicMsg = "JSON decoder out of sync - data changing underfoot?"

>> 在valueQuoted这个方法中，如果程序执行流进入了default case，该方法会引发panic，该panic将提示开发人员：这里很可能是一个bug。

>> 一旦触发“断言”，这很可能就是一个潜在bug。我们看到：去掉这行代码不会对resolve方法的逻辑造成任何影响，但真正出现问题时，开发人员就缺少了“断言”潜在bug提醒的辅助了。在Go标准库中，大多数panic是充当类似断言的作用的。

2. 用于简化错误处理控制结构

>> panic的语义机制决定了它可以在函数栈间游走，直到被某函数栈上的defer函数中的recover捕获，因此它在一定程度上可以用于简化错误处理的控制结构。在上一条中，我们在介绍check/handle风格化这个方法时就利用了panic的这个特性

>> 在Go标准库中，我们也看到了这种利用panic辅助简化错误处理控制结构，减少if err != nil重复出现的例子。我们来看一下fmt包中的这个例子：
```go
// $GOROOT/src/fmt/scan.go
type scanError struct {    
	err error
}
func (s *ss) error(err error) {    
	panic(scanError{err})
}
func (s *ss) Token(skipSpace bool, f func(rune) bool) (tok []byte, err error) {    
	defer func() {        
		if e := recover(); e != nil {            
			if se, ok := e.(scanError); ok {                
				err = se.err            
			} else {                
				panic(e)            
			}        
		}    
	}()    
	if f == nil {        
		f = notSpace    
	}    
	s.buf = s.buf[:0]    
	tok = s.token(skipSpace, f)    
	return
}
func (s *ss) token(skipSpace bool, f func(rune) bool) []byte {   
	if skipSpace {        
		s.SkipSpace()    
	}    
	for {        
		r := s.getRune()        
		if r == eof {            
			break        
		}        
		if !f(r) {            
			s.UnreadRune()            
			break        
		}        
		s.buf.writeRune(r)    
	}    
	return s.buf}func (s *ss) getRune() (r rune) {    
		r, _, err := s.ReadRune()    
		if err != nil {        
			if err == io.EOF {            
				return eof        
			}        
		s.error(err)    
	}    
	return
}
```
>> 我们看到Token方法调用的token方法、token方法调用的getRune方法都没有使用错误返回值，这使这两个方法可以专注于业务逻辑而非错误处理。当getRune方法内部要将错误返回到上层函数时，它使用了包装了panic的error方法。最外层的Token方法使用recover捕获panic，并对panic携带的error类型进行检查：如果是scanError类型错误，则返回该错误，实现了错误值的传递；否则将再次抛出该panic。

3. 使用recover捕获panic，防止goroutine意外退出

>> 前面提到了panic的“危害”：无论在哪个goroutine中发生未被捕获的panic，整个程序都将崩溃退出。在有些场景下我们必须抑制这种“危害”，保证程序的健壮性。在这方面，标准库中的http server就是一个典型的代表：
```go
// $GOROOT/src/net/http/server.go
func (c *conn) serve(ctx context.Context) {   
	c.remoteAddr = c.rwc.RemoteAddr().String()   
	ctx = context.WithValue(
		ctx, LocalAddrContextKey, c.rwc.LocalAddr())   
		defer func() {       
			if err := recover(); err != nil && err != ErrAbortHandler {           
				const size = 64 << 10           
				buf := make([]byte, size)           
				buf = buf[:runtime.Stack(buf, false)]           
				c.server.logf("http: panic serving %v: %v\n%s", c.remoteAddr, err, buf)       
			}       
			if !c.hijacked() {           
				c.close()           
				c.setState(c.rwc, StateClosed)       
			}   
		}()   ...
}
```

+ 针对每个连接，http包都会启动一个单独的goroutine运行用户传入的handler函数。如果处理某个连接的goroutine引发panic，我们需要保证应用程序本身以及处理其他连接的goroutine仍然是可正常运行的。因此，标准库在每个连接对应的goroutine处理函数（serve）中使用recover来捕获该goroutine可能引发的panic，使其“破坏”不会蔓延到整个程序。


### 39.3 理解panic的输出信息

+ 由前面的描述可以知道，在Go标准库中，大多数panic是充当类似断言的作用的。每次因panic导致程序崩溃后，程序都会输出大量信息，这些信息可以辅助程序员快速定位bug。那么如何理解这些信息呢？这里我们通过一个真实发生的例子中输出的panic信息来说明一下。
下面是某程序发生panic时真实输出的异常信息摘录：
`panic: runtime error: invalid memory address or nil pointer dereference[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x8ca449]goroutine 266900 [running]:pkg.tonybai.com/smspush/vendor/github.com/bigwhite/gocmpp.(*Client).Connect(0xc42040c7f0, 0xc4203d29c0, 0x11, 0xc420423256, 0x6, 0xc420423260, 0x8, 0x37e11d600, 0x0, 0x0)        /root/.go/src/pkg.tonybai.com/smspush/vendor/github.com/bigwhite/gocmpp/client.go:79 +0x239pkg.tonybai.com/smspush/pkg/pushd/pusher.cmpp2Login(0xc4203d29c0, 0x11, 0xc420423256, 0x6, 0xc420423260, 0x8, 0x37e11d600, 0xc4203d29c0, 0x11, 0x73)        /root/.go/src/pkg.tonybai.com/smspush/pkg/pushd/pusher/cmpp2_handler.go:25 +0x9apkg.tonybai.com/smspush/pkg/pushd/pusher.newCMPP2Loop(0xc42071f800, 0x4, 0xaaecd8)        /root/.go/src/pkg.tonybai.com/smspush/pkg/pushd/pusher/cmpp2_handler.go:65 +0x226pkg.tonybai.com/smspush/pkg/pushd/pusher.(*tchanSession).Run(0xc42071f800, 0xaba7c3, 0x17)        /root/.go/src/pkg.tonybai.com/smspush/pkg/pushd/pusher/session.go:52 +0x98pkg.tonybai.com/smspush/pkg/pushd/pusher.(*gateway).addSession.func1(0xc4200881a0,     0xc42071f800, 0xc42040c700)        /root/.go/src/pkg.tonybai.com/smspush/pkg/pushd/pusher/gateway.go:61 +0x11ecreated by pkg.tonybai.com/smspush/pkg/pushd/pusher.(*gateway).addSession        /root/.go/src/pkg.tonybai.com/smspush/pkg/pushd/pusher/gateway.go:58 +0x350`

>> 对于panic导致的程序崩溃，我们首先检查位于栈顶的栈跟踪信息，并定位到直接引发panic的那一行代码

>> /root/.go/src/pkg.tonybai.com/smspush/vendor/github.com/bigwhite/gocmpp/client.go:79 +0x239
图39-1所示为client.go这个源文件第79行周围的代码片段。

图39-1　panic实例代码片段
多数情况下，通过这行代码即可直接揪出导致问题的“元凶”。
如果没能做到，接下来，我们将继续调查panic输出的函数调用栈中参数是否正确。要想知道函数调用栈中参数传递是否有问题，我们就要知晓发生panic后输出的栈帧信息是什么，比如下面panic信息中参数中的各种数值分别代表什么。
gocmpp.(*Client).Connect(0xc42040c7f0, 0xc4203d29c0, 0x11, 0xc420423256, 0x6, 0xc420423260, 0x8, 0x37e11d600, 0x0, 0x0)pusher.cmpp2Login(0xc4203d29c0, 0x11, 0xc420423256, 0x6, 0xc420423260, 0x8, 0x37e11d600, 0xc4203d29c0, 0x11, 0x73)pusher.newCMPP2Loop(0xc42071f800, 0x4, 0xaaecd8)

+ 关于发生panic后输出的栈跟踪信息（stack trace）的识别，总体可遵循以下几个要点。
•  栈跟踪信息中每个函数/方法后面的“参数数值”个数与函数/方法原型的参数个数不是一一对应的。
•  栈跟踪信息中每个函数/方法后面的“参数数值”是按照函数/方法原型参数列表中从左到右的参数类型的内存布局逐一展开的，每个数值占用一个字（word，64位平台下为8字节）。
•  如果是方法，则第一个参数是receiver自身。如果receiver是指针类型，则第一个参数数值就是一个指针地址；如果是非指针的实例，则栈跟踪信息会按照其内存布局输出。
•  函数/方法返回值放在栈跟踪信息的“参数数值”列表的后面；如果有多个返回值，则同样按从左到右的顺序，按照返回值类型的内存布局输出。
•  指针类型参数：占用栈跟踪信息的“参数数值”列表的一个位置；数值表示指针值，也是指针指向的对象的地址。
•  string类型参数：由于string在内存中由两个字表示（第一个字是数据指针，第二个字是string的长度），因此在栈跟踪信息的“参数数值”列表中将占用两个位置。
•  slice类型参数：由于slice类型在内存中由三个字表示（第一个字是数据指针，第二个字是len，第三个字是cap），因此在栈跟踪信息的“参数数值”列表中将占用三个位置。
•  内建整型（int、rune、byte）：由于按字逐个输出，对于类型长度不足一个字的参数，会进行合并处理。比如，一个函数有5个int16类型的参数，那么在栈跟踪信息中这5个参数将占用“参数数值”列表中的两个位置：第一个位置是前4个参数的“合体”，第二个位置则是最后那个int16类型的参数值。
•  struct类型参数：会按照struct中字段的内存布局顺序在栈跟踪信息中展开。
•  interface类型参数：由于interface类型在内存中由两部分组成（一部分是接口类型的参数指针，另一部分是接口值的参数指针），因此interface类型参数将使用“参数数值”列表中的两个位置。
•  栈跟踪输出的信息是在函数调用过程中的“快照”信息，因此一些输出数值虽然看似不合理，但由于其并不是最终值，问题也不一定发生在它们身上，比如返回值参数。

+ 结合上面要点、函数/方法原型及栈跟踪的输出，我们来定位一下上述栈跟踪输出的各个参数的含义。cmpp2Login和Connect的函数/方法原型及调用关系如下：
```go
func cmpp2Login(dstAddr, user, password string, connectTimeout time.Duration) (*cmpp.Client, error)
func (cli *Client) Connect(servAddr, user, password string, timeout     time.Duration) error
func cmpp2Login(dstAddr, user, password string, connectTimeout time.Duration) (*cmpp.Client, error) {    
	c := cmpp.NewClient(cmpp.V21)    
	return c, c.Connect(dstAddr, user, password, connectTimeout)
}
```
将上述原型与栈跟踪信息中的参数对照后，我们得出下面的对应关系：
```go
pusher.cmpp2Login(    
	0xc4203d29c0,  // dstAddr string的数据指针    
0x11,          // dstAddr string的length    
0xc420423256,  // user string的数据指针    
0x6,           // user string的length    
0xc420423260,  // password string的数据指针   
0x8,           // password string的length    
0x37e11d600,   // connectTimeout (64位整型)    
0xc4203d29c0,  // 返回值：Client的指针    
0x11,          // 返回值：error接口的类型指针    
0x73)          // 返回值：error接口的数据指针
gocmpp.(*Client).Connect(    
	0xc42040c7f0,  // cli的指针    
	0xc4203d29c0,  // servAddr string的数据指针   
	 0x11,          // servAddr string的length    
	 0xc420423256,  // user string的数据指针    
	 0x6,           // user string的length    
	 0xc420423260,  // password string的数据指针    
	 0x8,           // password string的length    
	 0x37e11d600,   // timeout    
	 0x0,           // 返回值：error接口的类型指针    
	 0x0)           // 返回值：error接口的数据指针
```

>> 在这里，cmpp2Login的dstAddr、user、password、connectTimeout这些输入参数值都非常正常；看起来不正常的两个返回值在栈帧中的值其实意义不大，因为connect没有返回，这些值处于“非最终态”；而Connect执行到第79行发生panic，其返回值error的两个值也处于“中间状态”。从这个例子中我们读懂了panic输出的栈跟踪信息，虽然这些信息并没有给予我们多少解题提示，但这种分析至少让我们确信发生panic位置之前的函数栈都是未被污染过的。
而导致这个真实案例发生panic的“元凶”是图39-1中的第78行。这行中使用了类型断言（type assertion），但却没有对类型断言返回的ok值进行有效性判断就使用了类型断言返回的rsp变量。由于类型断言失败，rsp为nil，这就是发生panic的真实原因。

+ 在Go 1.11及以后版本中，Go编译器得到更深入的优化，很多简单的函数或方法会被自动内联（inline）。函数一旦内联化，我们就无法在栈跟踪信息中看到栈帧信息了，栈帧信息都变成了省略号，如下面的代码示例那样：
`$go run go-panic-stacktrace.go panic: panic in bazgoroutine 1 [running]:main.(*Y).baz(...)    /Users/tonybai/.../go-panic-stacktrace.go:32main.main()    /Users/tonybai/.../go-panic-stacktrace.go:51 +0x39exit status 2`

+ 要想看到栈跟踪信息中的栈帧数据，我们需要使用-gcflags="-l"来告诉编译器不要执行内联优化，就像下面的代码这样：
`$ go run -gcflags="-l" go-panic-stacktrace.gopanic: panic in bazgoroutine 1 [running]:main.(*Y).baz(0xc00006cf30, 0xc00006cf28, 0x5, 0x10ccd43, 0x5, 0xc00006cf60, 0xe000d000c000b, 0xc00010000f, 0xc00006cf48, 0x103d29a)    /Users/tonybai/.../go-panic-stacktrace.go:32 +0x39main.main()    /Users/tonybai/.../go-panic-stacktrace.go:51 +0xffexit status 2`

### 小结
在这一条中，我们首先将Go panic与Java的结构化处理机制进行了对比，指出了panic与本质上为错误处理的Java checked exception的不同，明确了Go panic仅可用于异常处理。之后，我们结合Go标准库中对panic的应用，梳理出了panic的几种常见应用场景和使用方法，并给出了理解和分析panic异常输出信息的方法。
本条要点：
•  深入理解不要使用panic进行正常错误处理的原因。
•  Go标准库中panic的常见使用场景。
•  理解程序发生panic时输出的栈帧信息有助于快速定位bug，找出“元凶”。


